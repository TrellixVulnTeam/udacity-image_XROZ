{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 图像分类\n",
    "\n",
    "在此项目中，你将对 [CIFAR-10 数据集](https://www.cs.toronto.edu/~kriz/cifar.html) 中的图片进行分类。该数据集包含飞机、猫狗和其他物体。你需要预处理这些图片，然后用所有样本训练一个卷积神经网络。图片需要标准化（normalized），标签需要采用 one-hot 编码。你需要应用所学的知识构建卷积的、最大池化（max pooling）、丢弃（dropout）和完全连接（fully connected）的层。最后，你需要在样本图片上看到神经网络的预测结果。\n",
    "\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "请运行以下单元，以下载 [CIFAR-10 数据集（Python版）](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CIFAR-10 Dataset: 171MB [1:38:55, 14.5KB/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据\n",
    "\n",
    "该数据集分成了几部分／批次（batches），以免你的机器在计算时内存不足。CIFAR-10 数据集包含 5 个部分，名称分别为 `data_batch_1`、`data_batch_2`，以此类推。每个部分都包含以下某个类别的标签和图片：\n",
    "\n",
    "* 飞机\n",
    "* 汽车\n",
    "* 鸟类\n",
    "* 猫\n",
    "* 鹿\n",
    "* 狗\n",
    "* 青蛙\n",
    "* 马\n",
    "* 船只\n",
    "* 卡车\n",
    "\n",
    "了解数据集也是对数据进行预测的必经步骤。你可以通过更改 `batch_id` 和 `sample_id` 探索下面的代码单元。`batch_id` 是数据集一个部分的 ID（1 到 5）。`sample_id` 是该部分中图片和标签对（label pair）的 ID。\n",
    "\n",
    "问问你自己：“可能的标签有哪些？”、“图片数据的值范围是多少？”、“标签是按顺序排列，还是随机排列的？”。思考类似的问题，有助于你预处理数据，并使预测结果更准确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4a5c0d6160>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 2:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 984, 1: 1007, 2: 1010, 3: 995, 4: 1010, 5: 988, 6: 1008, 7: 1026, 8: 987, 9: 985}\n",
      "First 20 Labels: [1, 6, 6, 8, 8, 3, 4, 6, 0, 6, 0, 3, 6, 6, 5, 4, 8, 3, 2, 6]\n",
      "\n",
      "Example of Image 1:\n",
      "Image - Min Value: 2 Max Value: 247\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 6 Name: frog\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmKIHgML+H2mNv660C5tZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4a4c51b390>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explore the dataset\n",
    "batch_id = 2\n",
    "sample_id = 1\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现预处理函数\n",
    "\n",
    "### 标准化\n",
    "\n",
    "在下面的单元中，实现 `normalize` 函数，传入图片数据 `x`，并返回标准化 Numpy 数组。值应该在 0 到 1 的范围内（含 0 和 1）。返回对象应该和 `x` 的形状一样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return x / 255\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot 编码\n",
    "\n",
    "和之前的代码单元一样，你将为预处理实现一个函数。这次，你将实现 `one_hot_encode` 函数。输入，也就是 `x`，是一个标签列表。实现该函数，以返回为 one_hot 编码的 Numpy 数组的标签列表。标签的可能值为 0 到 9。每次调用 `one_hot_encode` 时，对于每个值，one_hot 编码函数应该返回相同的编码。确保将编码映射保存到该函数外面。\n",
    "\n",
    "提示：不要重复发明轮子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import preprocessing\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit([0,1,2,3,4,5,6,7,8,9])\n",
    "    return lb.transform(x)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机化数据\n",
    "\n",
    "之前探索数据时，你已经了解到，样本的顺序是随机的。再随机化一次也不会有什么关系，但是对于这个数据集没有必要。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理所有数据并保存\n",
    "\n",
    "运行下方的代码单元，将预处理所有 CIFAR-10 数据，并保存到文件中。下面的代码还使用了 10% 的训练数据，用来验证。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "这是你的第一个检查点。如果你什么时候决定再回到该记事本，或需要重新启动该记事本，你可以从这里开始。预处理的数据已保存到本地。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "对于该神经网络，你需要将每层都构建为一个函数。你看到的大部分代码都位于函数外面。要更全面地测试你的代码，我们需要你将每层放入一个函数中。这样使我们能够提供更好的反馈，并使用我们的统一测试检测简单的错误，然后再提交项目。\n",
    "\n",
    ">**注意**：如果你觉得每周很难抽出足够的时间学习这门课程，我们为此项目提供了一个小捷径。对于接下来的几个问题，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 程序包中的类来构建每个层级，但是“卷积和最大池化层级”部分的层级除外。TF Layers 和 Keras 及 TFLearn 层级类似，因此很容易学会。\n",
    "\n",
    ">但是，如果你想充分利用这门课程，请尝试自己解决所有问题，不使用 TF Layers 程序包中的任何类。你依然可以使用其他程序包中的类，这些类和你在 TF Layers 中的类名称是一样的！例如，你可以使用 TF Neural Network 版本的 `conv2d` 类 [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)，而不是 TF Layers 版本的 `conv2d` 类 [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)。\n",
    "\n",
    "我们开始吧！\n",
    "\n",
    "\n",
    "### 输入\n",
    "\n",
    "神经网络需要读取图片数据、one-hot 编码标签和丢弃保留概率（dropout keep probability）。请实现以下函数：\n",
    "\n",
    "* 实现 `neural_net_image_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `image_shape` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"x\" 命名\n",
    "* 实现 `neural_net_label_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `n_classes` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"y\" 命名\n",
    "* 实现 `neural_net_keep_prob_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)，用于丢弃保留概率\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"keep_prob\" 命名\n",
    "\n",
    "这些名称将在项目结束时，用于加载保存的模型。\n",
    "\n",
    "注意：TensorFlow 中的 `None` 表示形状可以是动态大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, image_shape[0], image_shape[1], image_shape[2]], name=\"x\")\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32,  [None, n_classes], name=\"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积和最大池化层\n",
    "\n",
    "卷积层级适合处理图片。对于此代码单元，你应该实现函数 `conv2d_maxpool` 以便应用卷积然后进行最大池化：\n",
    "\n",
    "* 使用 `conv_ksize`、`conv_num_outputs` 和 `x_tensor` 的形状创建权重（weight）和偏置（bias）。\n",
    "* 使用权重和 `conv_strides` 对 `x_tensor` 应用卷积。\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "* 添加偏置\n",
    "* 向卷积中添加非线性激活（nonlinear activation）\n",
    "* 使用 `pool_ksize` 和 `pool_strides` 应用最大池化\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "\n",
    "**注意**：对于**此层**，**请勿使用** [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers)，但是仍然可以使用 TensorFlow 的 [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) 包。对于所有**其他层**，你依然可以使用快捷方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    channel = x_tensor.get_shape().as_list()[-1]\n",
    "    w = tf.Variable(tf.truncated_normal([conv_ksize[0], conv_ksize[1], channel, conv_num_outputs], stddev=0.1))\n",
    "    b = tf.Variable(tf.zeros([conv_num_outputs]))\n",
    "    x_tensor = tf.nn.conv2d(x_tensor, w, strides=[1, conv_strides[0], conv_strides[1], 1], padding='SAME')\n",
    "    x_tensor = tf.nn.bias_add(x_tensor, b)\n",
    "    x_tensor = tf.nn.relu(x_tensor)\n",
    "    x_tensor = tf.nn.max_pool(x_tensor, ksize=[1, pool_ksize[0], pool_ksize[1], 1], strides=[1, pool_strides[0], pool_strides[1], 1], padding='SAME')\n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扁平化层\n",
    "\n",
    "实现 `flatten` 函数，将 `x_tensor` 的维度从四维张量（4-D tensor）变成二维张量。输出应该是形状（*部分大小（Batch Size）*，*扁平化图片大小（Flattened Image Size）*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    tensor_size = x_tensor.get_shape().as_list()[1:]\n",
    "    flatten_size = 1\n",
    "    for x in tensor_size:\n",
    "        flatten_size *= x\n",
    "    x_tensor = tf.reshape(x_tensor, [-1, flatten_size])\n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层\n",
    "\n",
    "实现 `fully_conn` 函数，以向 `x_tensor` 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    channel = x_tensor.get_shape().as_list()[-1]\n",
    "    w = tf.Variable(tf.truncated_normal([channel, num_outputs], stddev=0.1))\n",
    "    b = tf.Variable(tf.zeros([num_outputs]))\n",
    "    x_tensor = tf.add(tf.matmul(x_tensor, w), b)\n",
    "    x_tensor = tf.nn.relu(x_tensor)\n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出层\n",
    "\n",
    "实现 `output` 函数，向 x_tensor 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n",
    "\n",
    "**注意**：该层级不应应用 Activation、softmax 或交叉熵（cross entropy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    channel = x_tensor.get_shape().as_list()[1]\n",
    "    w = tf.Variable(tf.truncated_normal([channel, num_outputs], stddev=0.1))\n",
    "    b = tf.Variable(tf.zeros([num_outputs]))\n",
    "    x_tensor = tf.add(tf.matmul(x_tensor, w), b)\n",
    "    return x_tensor\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积模型\n",
    "\n",
    "实现函数 `conv_net`， 创建卷积神经网络模型。该函数传入一批图片 `x`，并输出对数（logits）。使用你在上方创建的层创建此模型：\n",
    "\n",
    "* 应用 1、2 或 3 个卷积和最大池化层（Convolution and Max Pool layers）\n",
    "* 应用一个扁平层（Flatten Layer）\n",
    "* 应用 1、2 或 3 个完全连接层（Fully Connected Layers）\n",
    "* 应用一个输出层（Output Layer）\n",
    "* 返回输出\n",
    "* 使用 `keep_prob` 向模型中的一个或多个层应用 [TensorFlow 的 Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    c1 = conv2d_maxpool(x, 16, (3, 3), (1, 1), (2, 2), (2, 2))\n",
    "    c2 = conv2d_maxpool(c1, 32, (3, 3), (1, 1), (2, 2), (2, 2))\n",
    "    c3 = conv2d_maxpool(c2, 64, (3, 3), (1, 1), (2, 2), (2, 2))\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    f0 = flatten(c3)\n",
    "    \n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    f1 = fully_conn(f0, 128)\n",
    "    f1 = tf.nn.dropout(f1, keep_prob)\n",
    "    f2 = fully_conn(f1, 64)\n",
    "    \n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    out = output(f2, 10)\n",
    "    \n",
    "    \n",
    "    # TODO: return output\n",
    "    return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络\n",
    "\n",
    "### 单次优化\n",
    "\n",
    "实现函数 `train_neural_network` 以进行单次优化（single optimization）。该优化应该使用 `optimizer` 优化 `session`，其中 `feed_dict` 具有以下参数：\n",
    "\n",
    "* `x` 表示图片输入\n",
    "* `y` 表示标签\n",
    "* `keep_prob` 表示丢弃的保留率\n",
    "\n",
    "每个部分都会调用该函数，所以 `tf.global_variables_initializer()` 已经被调用。\n",
    "\n",
    "注意：不需要返回任何内容。该函数只是用来优化神经网络。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示数据\n",
    "\n",
    "实现函数 `print_stats` 以输出损失和验证准确率。使用全局变量 `valid_features` 和 `valid_labels` 计算验证准确率。使用保留率 `1.0` 计算损失和验证准确率（loss and validation accuracy）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={x:feature_batch, y:label_batch, keep_prob:1.})\n",
    "    valid_acc = session.run(accuracy, feed_dict={x:valid_features, y:valid_labels, keep_prob:1.})\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数\n",
    "\n",
    "调试以下超参数：\n",
    "* 设置 `epochs` 表示神经网络停止学习或开始过拟合的迭代次数\n",
    "* 设置 `batch_size`，表示机器内存允许的部分最大体积。大部分人设为以下常见内存大小：\n",
    "\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* 设置 `keep_probability` 表示使用丢弃时保留节点的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 200\n",
    "batch_size = 256\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在单个 CIFAR-10 部分上训练\n",
    "\n",
    "我们先用单个部分，而不是用所有的 CIFAR-10 批次训练神经网络。这样可以节省时间，并对模型进行迭代，以提高准确率。最终验证准确率达到 50% 或以上之后，在下一部分对所有数据运行模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.1155 Validation Accuracy: 0.263000\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.0631 Validation Accuracy: 0.326400\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     1.9157 Validation Accuracy: 0.376000\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.8945 Validation Accuracy: 0.376600\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.7319 Validation Accuracy: 0.436400\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.6879 Validation Accuracy: 0.439400\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.4842 Validation Accuracy: 0.464200\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     1.4206 Validation Accuracy: 0.459000\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.3608 Validation Accuracy: 0.468200\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.2022 Validation Accuracy: 0.494800\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     1.1103 Validation Accuracy: 0.501000\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.0419 Validation Accuracy: 0.507200\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.0033 Validation Accuracy: 0.516400\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     0.9068 Validation Accuracy: 0.525200\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     0.8463 Validation Accuracy: 0.526800\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     0.8257 Validation Accuracy: 0.537600\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     0.7211 Validation Accuracy: 0.550400\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     0.6892 Validation Accuracy: 0.548400\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     0.6351 Validation Accuracy: 0.545400\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     0.6102 Validation Accuracy: 0.559400\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     0.5964 Validation Accuracy: 0.542600\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     0.5368 Validation Accuracy: 0.547000\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     0.4809 Validation Accuracy: 0.562400\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     0.4648 Validation Accuracy: 0.554000\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     0.4380 Validation Accuracy: 0.559400\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     0.4027 Validation Accuracy: 0.567400\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     0.3696 Validation Accuracy: 0.565400\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     0.3525 Validation Accuracy: 0.572000\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     0.2929 Validation Accuracy: 0.573200\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     0.3035 Validation Accuracy: 0.563400\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     0.2486 Validation Accuracy: 0.581000\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     0.2667 Validation Accuracy: 0.570800\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     0.2286 Validation Accuracy: 0.579200\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     0.2211 Validation Accuracy: 0.584000\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     0.1807 Validation Accuracy: 0.584600\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     0.1665 Validation Accuracy: 0.586600\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     0.1629 Validation Accuracy: 0.588800\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     0.1545 Validation Accuracy: 0.593000\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     0.1585 Validation Accuracy: 0.594800\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     0.1423 Validation Accuracy: 0.598400\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     0.1432 Validation Accuracy: 0.585600\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     0.1368 Validation Accuracy: 0.587200\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     0.1236 Validation Accuracy: 0.585400\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     0.1187 Validation Accuracy: 0.567400\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     0.1162 Validation Accuracy: 0.579200\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     0.1214 Validation Accuracy: 0.578200\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     0.0840 Validation Accuracy: 0.588000\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     0.1004 Validation Accuracy: 0.583400\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     0.0952 Validation Accuracy: 0.576600\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     0.0797 Validation Accuracy: 0.586200\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     0.0921 Validation Accuracy: 0.591400\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     0.0693 Validation Accuracy: 0.605600\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     0.0687 Validation Accuracy: 0.603000\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     0.0650 Validation Accuracy: 0.603800\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     0.0526 Validation Accuracy: 0.597200\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     0.0562 Validation Accuracy: 0.591800\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     0.0431 Validation Accuracy: 0.609600\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     0.0460 Validation Accuracy: 0.600400\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     0.0412 Validation Accuracy: 0.600200\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     0.0374 Validation Accuracy: 0.608000\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     0.0401 Validation Accuracy: 0.603200\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     0.0353 Validation Accuracy: 0.596600\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     0.0364 Validation Accuracy: 0.585400\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     0.0363 Validation Accuracy: 0.607600\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     0.0319 Validation Accuracy: 0.606600\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     0.0272 Validation Accuracy: 0.601400\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     0.0282 Validation Accuracy: 0.608800\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     0.0296 Validation Accuracy: 0.590200\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     0.0189 Validation Accuracy: 0.597000\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     0.0242 Validation Accuracy: 0.597600\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     0.0166 Validation Accuracy: 0.614800\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     0.0135 Validation Accuracy: 0.605600\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     0.0177 Validation Accuracy: 0.597400\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     0.0203 Validation Accuracy: 0.598000\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     0.0110 Validation Accuracy: 0.604800\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:     0.0106 Validation Accuracy: 0.609600\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:     0.0134 Validation Accuracy: 0.610200\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:     0.0185 Validation Accuracy: 0.608200\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:     0.0159 Validation Accuracy: 0.595600\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:     0.0131 Validation Accuracy: 0.597800\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:     0.0077 Validation Accuracy: 0.601000\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:     0.0065 Validation Accuracy: 0.604200\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:     0.0071 Validation Accuracy: 0.601200\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:     0.0060 Validation Accuracy: 0.609800\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:     0.0061 Validation Accuracy: 0.606600\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:     0.0047 Validation Accuracy: 0.607600\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:     0.0040 Validation Accuracy: 0.606200\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:     0.0066 Validation Accuracy: 0.608600\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:     0.0059 Validation Accuracy: 0.604200\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:     0.0058 Validation Accuracy: 0.602200\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:     0.0049 Validation Accuracy: 0.597600\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:     0.0042 Validation Accuracy: 0.596600\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:     0.0053 Validation Accuracy: 0.591200\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:     0.0047 Validation Accuracy: 0.592000\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:     0.0033 Validation Accuracy: 0.596200\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:     0.0091 Validation Accuracy: 0.576800\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:     0.0070 Validation Accuracy: 0.587400\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:     0.0349 Validation Accuracy: 0.560400\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:     0.0088 Validation Accuracy: 0.578400\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:     0.0042 Validation Accuracy: 0.591800\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss:     0.0109 Validation Accuracy: 0.581000\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss:     0.0032 Validation Accuracy: 0.577000\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss:     0.0045 Validation Accuracy: 0.591600\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss:     0.0049 Validation Accuracy: 0.586600\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss:     0.0034 Validation Accuracy: 0.591000\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss:     0.0020 Validation Accuracy: 0.601000\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss:     0.0040 Validation Accuracy: 0.598400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108, CIFAR-10 Batch 1:  Loss:     0.0020 Validation Accuracy: 0.608600\n",
      "Epoch 109, CIFAR-10 Batch 1:  Loss:     0.0018 Validation Accuracy: 0.597000\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss:     0.0015 Validation Accuracy: 0.593400\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss:     0.0041 Validation Accuracy: 0.598400\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss:     0.0023 Validation Accuracy: 0.592600\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss:     0.0021 Validation Accuracy: 0.590000\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss:     0.0015 Validation Accuracy: 0.593600\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss:     0.0008 Validation Accuracy: 0.601200\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss:     0.0013 Validation Accuracy: 0.599600\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss:     0.0018 Validation Accuracy: 0.590000\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss:     0.0014 Validation Accuracy: 0.595200\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss:     0.0005 Validation Accuracy: 0.599200\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss:     0.0017 Validation Accuracy: 0.601600\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss:     0.0014 Validation Accuracy: 0.600000\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss:     0.0008 Validation Accuracy: 0.600000\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss:     0.0010 Validation Accuracy: 0.593000\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss:     0.0011 Validation Accuracy: 0.593800\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss:     0.0012 Validation Accuracy: 0.595600\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss:     0.0006 Validation Accuracy: 0.593200\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss:     0.0005 Validation Accuracy: 0.590600\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss:     0.0011 Validation Accuracy: 0.595400\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss:     0.0008 Validation Accuracy: 0.589400\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss:     0.0030 Validation Accuracy: 0.584000\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss:     0.0014 Validation Accuracy: 0.577400\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss:     0.0006 Validation Accuracy: 0.587600\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss:     0.0015 Validation Accuracy: 0.585000\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss:     0.0008 Validation Accuracy: 0.595200\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss:     0.0011 Validation Accuracy: 0.586000\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss:     0.0004 Validation Accuracy: 0.596200\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss:     0.0003 Validation Accuracy: 0.581600\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss:     0.0006 Validation Accuracy: 0.582800\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss:     0.0004 Validation Accuracy: 0.581000\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss:     0.0006 Validation Accuracy: 0.580800\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss:     0.0004 Validation Accuracy: 0.592400\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss:     0.0003 Validation Accuracy: 0.585600\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss:     0.0010 Validation Accuracy: 0.591200\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss:     0.0009 Validation Accuracy: 0.593400\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss:     0.0003 Validation Accuracy: 0.591400\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss:     0.0003 Validation Accuracy: 0.594800\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss:     0.0002 Validation Accuracy: 0.592200\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss:     0.0005 Validation Accuracy: 0.598600\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss:     0.0002 Validation Accuracy: 0.590000\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss:     0.0003 Validation Accuracy: 0.600000\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.600000\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.602600\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.600200\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss:     0.0002 Validation Accuracy: 0.593200\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss:     0.0002 Validation Accuracy: 0.597000\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.595600\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss:     0.0002 Validation Accuracy: 0.592600\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss:     0.0002 Validation Accuracy: 0.591400\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.594400\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.603200\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss:     0.0005 Validation Accuracy: 0.592200\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss:     0.0002 Validation Accuracy: 0.591200\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss:     0.0003 Validation Accuracy: 0.601400\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss:     0.0002 Validation Accuracy: 0.601000\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.590200\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss:     0.0003 Validation Accuracy: 0.595000\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.601600\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss:     0.0002 Validation Accuracy: 0.597400\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.599200\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.593200\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.600000\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss:     0.0002 Validation Accuracy: 0.600000\n",
      "Epoch 173, CIFAR-10 Batch 1:  Loss:     0.0002 Validation Accuracy: 0.605600\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.603400\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.601400\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss:     0.0002 Validation Accuracy: 0.599800\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss:     0.0004 Validation Accuracy: 0.603800\n",
      "Epoch 178, CIFAR-10 Batch 1:  Loss:     0.0002 Validation Accuracy: 0.603800\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.593200\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss:     0.0000 Validation Accuracy: 0.595600\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss:     0.0000 Validation Accuracy: 0.599200\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss:     0.0000 Validation Accuracy: 0.602600\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.596400\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss:     0.0006 Validation Accuracy: 0.590200\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss:     0.0002 Validation Accuracy: 0.600800\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss:     0.0000 Validation Accuracy: 0.594800\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss:     0.0002 Validation Accuracy: 0.598400\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.604400\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss:     0.0011 Validation Accuracy: 0.605000\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.600200\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.601800\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.600000\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.598400\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.608400\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.609000\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.594600\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss:     0.0000 Validation Accuracy: 0.604600\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.602600\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.598000\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss:     0.0001 Validation Accuracy: 0.606600\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全训练模型\n",
    "\n",
    "现在，单个 CIFAR-10 部分的准确率已经不错了，试试所有五个部分吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.1627 Validation Accuracy: 0.233200\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     2.0062 Validation Accuracy: 0.319600\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     1.6702 Validation Accuracy: 0.349600\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     1.6768 Validation Accuracy: 0.397600\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     1.6058 Validation Accuracy: 0.426800\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     1.7832 Validation Accuracy: 0.443400\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     1.6621 Validation Accuracy: 0.450000\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     1.2165 Validation Accuracy: 0.463800\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     1.4302 Validation Accuracy: 0.482400\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     1.4182 Validation Accuracy: 0.488800\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     1.5842 Validation Accuracy: 0.486600\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     1.3858 Validation Accuracy: 0.512800\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     1.0432 Validation Accuracy: 0.496400\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     1.1958 Validation Accuracy: 0.516000\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     1.2642 Validation Accuracy: 0.527600\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.3688 Validation Accuracy: 0.529000\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     1.2293 Validation Accuracy: 0.532200\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     0.9748 Validation Accuracy: 0.515600\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     1.1107 Validation Accuracy: 0.550000\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     1.1040 Validation Accuracy: 0.560000\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.2452 Validation Accuracy: 0.550400\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     1.0425 Validation Accuracy: 0.564400\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     0.8476 Validation Accuracy: 0.561400\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     0.9932 Validation Accuracy: 0.580400\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     1.0468 Validation Accuracy: 0.562600\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.1117 Validation Accuracy: 0.584200\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     0.9177 Validation Accuracy: 0.581400\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     0.7566 Validation Accuracy: 0.588200\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     0.8654 Validation Accuracy: 0.603600\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     0.9038 Validation Accuracy: 0.595200\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.0077 Validation Accuracy: 0.596400\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     0.7937 Validation Accuracy: 0.597400\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     0.7000 Validation Accuracy: 0.595800\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     0.8423 Validation Accuracy: 0.614800\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     0.8154 Validation Accuracy: 0.610600\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     0.9194 Validation Accuracy: 0.619000\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     0.6991 Validation Accuracy: 0.614800\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     0.5927 Validation Accuracy: 0.628600\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     0.8011 Validation Accuracy: 0.622800\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     0.7249 Validation Accuracy: 0.632800\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     0.8315 Validation Accuracy: 0.629200\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     0.6278 Validation Accuracy: 0.637800\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     0.5294 Validation Accuracy: 0.625200\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     0.7046 Validation Accuracy: 0.639000\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     0.6090 Validation Accuracy: 0.640600\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     0.7886 Validation Accuracy: 0.626800\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     0.6037 Validation Accuracy: 0.650200\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:     0.4783 Validation Accuracy: 0.653200\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     0.6668 Validation Accuracy: 0.646000\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:     0.5173 Validation Accuracy: 0.657200\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     0.7204 Validation Accuracy: 0.641000\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:     0.5925 Validation Accuracy: 0.652800\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:     0.4482 Validation Accuracy: 0.654800\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:     0.6112 Validation Accuracy: 0.658600\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:     0.4931 Validation Accuracy: 0.664200\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     0.6451 Validation Accuracy: 0.661400\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:     0.5335 Validation Accuracy: 0.661600\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:     0.3822 Validation Accuracy: 0.670200\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:     0.6014 Validation Accuracy: 0.659000\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:     0.4364 Validation Accuracy: 0.666600\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     0.5812 Validation Accuracy: 0.665400\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:     0.4473 Validation Accuracy: 0.675600\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:     0.3291 Validation Accuracy: 0.672800\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:     0.5978 Validation Accuracy: 0.661000\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:     0.3861 Validation Accuracy: 0.675000\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     0.5441 Validation Accuracy: 0.681600\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:     0.4191 Validation Accuracy: 0.676200\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:     0.3053 Validation Accuracy: 0.675000\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:     0.5152 Validation Accuracy: 0.680400\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:     0.3618 Validation Accuracy: 0.682200\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     0.5440 Validation Accuracy: 0.660400\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:     0.3819 Validation Accuracy: 0.675200\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:     0.2607 Validation Accuracy: 0.676000\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:     0.4573 Validation Accuracy: 0.677800\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:     0.3172 Validation Accuracy: 0.686400\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     0.4696 Validation Accuracy: 0.678200\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:     0.3098 Validation Accuracy: 0.676800\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:     0.2498 Validation Accuracy: 0.683600\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:     0.3986 Validation Accuracy: 0.689200\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:     0.2973 Validation Accuracy: 0.683400\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     0.4205 Validation Accuracy: 0.697000\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:     0.3277 Validation Accuracy: 0.696800\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:     0.2285 Validation Accuracy: 0.685400\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:     0.3930 Validation Accuracy: 0.677800\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:     0.2666 Validation Accuracy: 0.675200\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     0.4104 Validation Accuracy: 0.676800\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:     0.3405 Validation Accuracy: 0.705000\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:     0.2261 Validation Accuracy: 0.688200\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:     0.3648 Validation Accuracy: 0.705800\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:     0.2483 Validation Accuracy: 0.681200\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     0.3727 Validation Accuracy: 0.693800\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:     0.2938 Validation Accuracy: 0.701400\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:     0.1987 Validation Accuracy: 0.704800\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:     0.3259 Validation Accuracy: 0.701800\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:     0.2220 Validation Accuracy: 0.695800\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     0.3487 Validation Accuracy: 0.695800\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:     0.2862 Validation Accuracy: 0.709600\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:     0.1887 Validation Accuracy: 0.704800\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:     0.2647 Validation Accuracy: 0.708800\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:     0.2377 Validation Accuracy: 0.679400\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     0.3329 Validation Accuracy: 0.694800\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:     0.2483 Validation Accuracy: 0.710600\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:     0.1793 Validation Accuracy: 0.697600\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:     0.2860 Validation Accuracy: 0.696600\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:     0.2046 Validation Accuracy: 0.695800\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     0.3012 Validation Accuracy: 0.691400\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:     0.2351 Validation Accuracy: 0.711800\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:     0.1651 Validation Accuracy: 0.699600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, CIFAR-10 Batch 4:  Loss:     0.2467 Validation Accuracy: 0.712000\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:     0.1771 Validation Accuracy: 0.693600\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     0.2645 Validation Accuracy: 0.693800\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:     0.2196 Validation Accuracy: 0.710400\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:     0.1500 Validation Accuracy: 0.703600\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:     0.2328 Validation Accuracy: 0.705400\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:     0.1614 Validation Accuracy: 0.703800\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     0.2544 Validation Accuracy: 0.710400\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:     0.2077 Validation Accuracy: 0.707000\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:     0.1501 Validation Accuracy: 0.705400\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:     0.2290 Validation Accuracy: 0.709600\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:     0.1457 Validation Accuracy: 0.715200\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     0.2377 Validation Accuracy: 0.718600\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:     0.1914 Validation Accuracy: 0.713000\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:     0.1219 Validation Accuracy: 0.713000\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:     0.1930 Validation Accuracy: 0.711200\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:     0.1362 Validation Accuracy: 0.709600\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     0.2320 Validation Accuracy: 0.719800\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:     0.1541 Validation Accuracy: 0.711200\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:     0.1404 Validation Accuracy: 0.711000\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:     0.1810 Validation Accuracy: 0.718800\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:     0.1203 Validation Accuracy: 0.718600\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     0.2223 Validation Accuracy: 0.711400\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:     0.1520 Validation Accuracy: 0.718400\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:     0.1342 Validation Accuracy: 0.707400\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:     0.1572 Validation Accuracy: 0.709400\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:     0.1267 Validation Accuracy: 0.712000\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     0.2118 Validation Accuracy: 0.706400\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:     0.1489 Validation Accuracy: 0.713400\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:     0.1781 Validation Accuracy: 0.681200\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:     0.1624 Validation Accuracy: 0.714600\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:     0.1048 Validation Accuracy: 0.714000\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     0.1954 Validation Accuracy: 0.703800\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:     0.1453 Validation Accuracy: 0.717200\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:     0.1176 Validation Accuracy: 0.698600\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:     0.1717 Validation Accuracy: 0.709600\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:     0.1168 Validation Accuracy: 0.712400\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     0.2060 Validation Accuracy: 0.722000\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:     0.1345 Validation Accuracy: 0.713800\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:     0.1098 Validation Accuracy: 0.701200\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:     0.1520 Validation Accuracy: 0.719000\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:     0.0890 Validation Accuracy: 0.710800\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     0.1783 Validation Accuracy: 0.713400\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:     0.1598 Validation Accuracy: 0.701800\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:     0.0821 Validation Accuracy: 0.719400\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:     0.1381 Validation Accuracy: 0.718600\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:     0.0860 Validation Accuracy: 0.711600\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     0.1732 Validation Accuracy: 0.713600\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:     0.1380 Validation Accuracy: 0.698800\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:     0.0921 Validation Accuracy: 0.714400\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:     0.1479 Validation Accuracy: 0.720800\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:     0.0791 Validation Accuracy: 0.716200\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     0.1535 Validation Accuracy: 0.716800\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:     0.1147 Validation Accuracy: 0.709000\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:     0.0798 Validation Accuracy: 0.726000\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:     0.1535 Validation Accuracy: 0.719800\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:     0.0769 Validation Accuracy: 0.719600\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     0.1553 Validation Accuracy: 0.716400\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:     0.1104 Validation Accuracy: 0.716000\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:     0.0747 Validation Accuracy: 0.724000\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:     0.1294 Validation Accuracy: 0.718000\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:     0.0610 Validation Accuracy: 0.713800\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     0.1424 Validation Accuracy: 0.719600\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:     0.0994 Validation Accuracy: 0.714000\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:     0.0775 Validation Accuracy: 0.725000\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:     0.1380 Validation Accuracy: 0.717000\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:     0.0607 Validation Accuracy: 0.713600\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     0.1345 Validation Accuracy: 0.729000\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:     0.1146 Validation Accuracy: 0.707600\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:     0.0687 Validation Accuracy: 0.726200\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:     0.1404 Validation Accuracy: 0.711400\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:     0.0600 Validation Accuracy: 0.719400\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     0.1240 Validation Accuracy: 0.723400\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:     0.1035 Validation Accuracy: 0.702800\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:     0.0578 Validation Accuracy: 0.718200\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:     0.1502 Validation Accuracy: 0.721800\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:     0.0729 Validation Accuracy: 0.720800\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     0.1437 Validation Accuracy: 0.709200\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:     0.1091 Validation Accuracy: 0.700000\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:     0.0581 Validation Accuracy: 0.722400\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:     0.1156 Validation Accuracy: 0.723400\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:     0.0630 Validation Accuracy: 0.717800\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     0.1128 Validation Accuracy: 0.715200\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:     0.0816 Validation Accuracy: 0.712200\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:     0.0538 Validation Accuracy: 0.720800\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:     0.1176 Validation Accuracy: 0.713200\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:     0.0604 Validation Accuracy: 0.709800\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     0.1287 Validation Accuracy: 0.712800\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:     0.0896 Validation Accuracy: 0.714400\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:     0.0476 Validation Accuracy: 0.723800\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:     0.1266 Validation Accuracy: 0.719800\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:     0.0515 Validation Accuracy: 0.709000\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     0.1676 Validation Accuracy: 0.696800\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:     0.1069 Validation Accuracy: 0.707000\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:     0.0695 Validation Accuracy: 0.708800\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:     0.1201 Validation Accuracy: 0.720200\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:     0.0581 Validation Accuracy: 0.715200\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     0.1355 Validation Accuracy: 0.707000\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:     0.1012 Validation Accuracy: 0.713000\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:     0.0446 Validation Accuracy: 0.724200\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:     0.1111 Validation Accuracy: 0.714600\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:     0.0546 Validation Accuracy: 0.718800\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     0.1281 Validation Accuracy: 0.711200\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:     0.0762 Validation Accuracy: 0.712600\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:     0.0472 Validation Accuracy: 0.718800\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:     0.0840 Validation Accuracy: 0.723800\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss:     0.0383 Validation Accuracy: 0.714600\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     0.1347 Validation Accuracy: 0.717400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, CIFAR-10 Batch 2:  Loss:     0.1107 Validation Accuracy: 0.717400\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:     0.0474 Validation Accuracy: 0.725600\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:     0.0798 Validation Accuracy: 0.726200\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:     0.0477 Validation Accuracy: 0.711600\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     0.1392 Validation Accuracy: 0.698200\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:     0.0798 Validation Accuracy: 0.720200\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:     0.0552 Validation Accuracy: 0.720600\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:     0.0771 Validation Accuracy: 0.724800\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:     0.0374 Validation Accuracy: 0.712600\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     0.1186 Validation Accuracy: 0.710400\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:     0.0706 Validation Accuracy: 0.720800\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:     0.0327 Validation Accuracy: 0.727600\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:     0.0871 Validation Accuracy: 0.723000\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:     0.0344 Validation Accuracy: 0.722000\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     0.1043 Validation Accuracy: 0.708800\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:     0.0604 Validation Accuracy: 0.713800\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:     0.0348 Validation Accuracy: 0.725400\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:     0.0769 Validation Accuracy: 0.725000\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:     0.0332 Validation Accuracy: 0.717000\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     0.0958 Validation Accuracy: 0.721400\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:     0.0499 Validation Accuracy: 0.711000\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:     0.0325 Validation Accuracy: 0.720400\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:     0.0714 Validation Accuracy: 0.725200\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:     0.0314 Validation Accuracy: 0.720800\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     0.0938 Validation Accuracy: 0.714000\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:     0.0497 Validation Accuracy: 0.718200\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:     0.0279 Validation Accuracy: 0.730200\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:     0.0577 Validation Accuracy: 0.726600\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:     0.0304 Validation Accuracy: 0.701400\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     0.1102 Validation Accuracy: 0.709000\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:     0.0575 Validation Accuracy: 0.711600\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:     0.0286 Validation Accuracy: 0.718600\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:     0.0474 Validation Accuracy: 0.727800\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:     0.0336 Validation Accuracy: 0.708200\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     0.0831 Validation Accuracy: 0.711800\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:     0.0573 Validation Accuracy: 0.699000\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:     0.0388 Validation Accuracy: 0.713400\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:     0.0467 Validation Accuracy: 0.720800\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:     0.0269 Validation Accuracy: 0.712600\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     0.0812 Validation Accuracy: 0.715000\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:     0.0750 Validation Accuracy: 0.705000\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:     0.0307 Validation Accuracy: 0.723000\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:     0.0515 Validation Accuracy: 0.720200\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:     0.0356 Validation Accuracy: 0.702200\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     0.0846 Validation Accuracy: 0.712000\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:     0.0551 Validation Accuracy: 0.702600\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:     0.0314 Validation Accuracy: 0.723000\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:     0.0515 Validation Accuracy: 0.717000\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:     0.0351 Validation Accuracy: 0.711600\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     0.0745 Validation Accuracy: 0.709400\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:     0.0577 Validation Accuracy: 0.704400\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:     0.0450 Validation Accuracy: 0.722000\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:     0.0505 Validation Accuracy: 0.719800\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:     0.0252 Validation Accuracy: 0.712400\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     0.0607 Validation Accuracy: 0.714800\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:     0.0582 Validation Accuracy: 0.709600\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:     0.0374 Validation Accuracy: 0.716600\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:     0.0584 Validation Accuracy: 0.719600\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:     0.0392 Validation Accuracy: 0.704000\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     0.0764 Validation Accuracy: 0.712600\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:     0.0589 Validation Accuracy: 0.709200\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:     0.0290 Validation Accuracy: 0.722600\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:     0.0580 Validation Accuracy: 0.720000\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:     0.0273 Validation Accuracy: 0.704400\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     0.0613 Validation Accuracy: 0.719400\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:     0.0561 Validation Accuracy: 0.721000\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:     0.0290 Validation Accuracy: 0.715600\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:     0.0685 Validation Accuracy: 0.716800\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:     0.0304 Validation Accuracy: 0.721800\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     0.0474 Validation Accuracy: 0.708200\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:     0.0378 Validation Accuracy: 0.706800\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:     0.0338 Validation Accuracy: 0.706400\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:     0.0436 Validation Accuracy: 0.729200\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:     0.0260 Validation Accuracy: 0.726200\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     0.0626 Validation Accuracy: 0.725600\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:     0.0377 Validation Accuracy: 0.719600\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:     0.0286 Validation Accuracy: 0.709400\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:     0.0473 Validation Accuracy: 0.717400\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:     0.0244 Validation Accuracy: 0.724600\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     0.0545 Validation Accuracy: 0.709400\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:     0.0316 Validation Accuracy: 0.715000\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:     0.0264 Validation Accuracy: 0.705400\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:     0.0604 Validation Accuracy: 0.722400\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:     0.0294 Validation Accuracy: 0.713600\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     0.0563 Validation Accuracy: 0.723200\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:     0.0351 Validation Accuracy: 0.715800\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:     0.0268 Validation Accuracy: 0.697600\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:     0.0437 Validation Accuracy: 0.723000\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:     0.0311 Validation Accuracy: 0.716000\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     0.0549 Validation Accuracy: 0.710600\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:     0.0378 Validation Accuracy: 0.725200\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:     0.0268 Validation Accuracy: 0.702200\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:     0.0384 Validation Accuracy: 0.724000\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:     0.0201 Validation Accuracy: 0.708400\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     0.0445 Validation Accuracy: 0.721800\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:     0.0368 Validation Accuracy: 0.719000\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:     0.0188 Validation Accuracy: 0.715400\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:     0.0325 Validation Accuracy: 0.730200\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:     0.0330 Validation Accuracy: 0.708600\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     0.0405 Validation Accuracy: 0.720600\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:     0.0349 Validation Accuracy: 0.722200\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:     0.0328 Validation Accuracy: 0.711800\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:     0.0297 Validation Accuracy: 0.726200\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:     0.0154 Validation Accuracy: 0.716400\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     0.0489 Validation Accuracy: 0.717000\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss:     0.0361 Validation Accuracy: 0.719800\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:     0.0276 Validation Accuracy: 0.718000\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:     0.0343 Validation Accuracy: 0.718000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65, CIFAR-10 Batch 5:  Loss:     0.0224 Validation Accuracy: 0.721200\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     0.0562 Validation Accuracy: 0.722200\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:     0.0288 Validation Accuracy: 0.719400\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:     0.0175 Validation Accuracy: 0.708200\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:     0.0575 Validation Accuracy: 0.713800\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:     0.0190 Validation Accuracy: 0.700800\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     0.0586 Validation Accuracy: 0.704200\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:     0.0278 Validation Accuracy: 0.719400\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:     0.0211 Validation Accuracy: 0.707600\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss:     0.0453 Validation Accuracy: 0.714800\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:     0.0182 Validation Accuracy: 0.706400\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     0.0406 Validation Accuracy: 0.714600\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:     0.0339 Validation Accuracy: 0.718400\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:     0.0183 Validation Accuracy: 0.702200\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:     0.0386 Validation Accuracy: 0.711800\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:     0.0224 Validation Accuracy: 0.710000\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     0.0387 Validation Accuracy: 0.722000\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:     0.0166 Validation Accuracy: 0.729400\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:     0.0152 Validation Accuracy: 0.716400\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:     0.0533 Validation Accuracy: 0.715600\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:     0.0195 Validation Accuracy: 0.721000\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     0.0384 Validation Accuracy: 0.713200\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:     0.0197 Validation Accuracy: 0.726000\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:     0.0148 Validation Accuracy: 0.714200\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:     0.0373 Validation Accuracy: 0.718400\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:     0.0169 Validation Accuracy: 0.725200\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     0.0364 Validation Accuracy: 0.703000\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss:     0.0199 Validation Accuracy: 0.720600\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss:     0.0103 Validation Accuracy: 0.717400\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss:     0.0381 Validation Accuracy: 0.721800\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss:     0.0143 Validation Accuracy: 0.723200\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     0.0342 Validation Accuracy: 0.709000\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss:     0.0144 Validation Accuracy: 0.726800\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss:     0.0095 Validation Accuracy: 0.715600\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss:     0.0440 Validation Accuracy: 0.708000\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss:     0.0274 Validation Accuracy: 0.719600\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     0.0434 Validation Accuracy: 0.713600\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss:     0.0222 Validation Accuracy: 0.719600\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss:     0.0243 Validation Accuracy: 0.710800\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss:     0.0303 Validation Accuracy: 0.726800\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss:     0.0179 Validation Accuracy: 0.717200\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     0.0423 Validation Accuracy: 0.702600\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss:     0.0111 Validation Accuracy: 0.719400\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss:     0.0125 Validation Accuracy: 0.713600\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss:     0.0303 Validation Accuracy: 0.716800\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss:     0.0132 Validation Accuracy: 0.717800\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     0.0359 Validation Accuracy: 0.705800\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss:     0.0136 Validation Accuracy: 0.722600\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss:     0.0092 Validation Accuracy: 0.720200\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss:     0.0487 Validation Accuracy: 0.714800\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss:     0.0193 Validation Accuracy: 0.709800\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:     0.0226 Validation Accuracy: 0.717800\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss:     0.0184 Validation Accuracy: 0.714400\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss:     0.0124 Validation Accuracy: 0.717400\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss:     0.0212 Validation Accuracy: 0.724400\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss:     0.0174 Validation Accuracy: 0.715000\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:     0.0236 Validation Accuracy: 0.719400\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss:     0.0152 Validation Accuracy: 0.723800\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss:     0.0083 Validation Accuracy: 0.710600\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss:     0.0302 Validation Accuracy: 0.703800\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss:     0.0186 Validation Accuracy: 0.717000\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:     0.0241 Validation Accuracy: 0.716800\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss:     0.0109 Validation Accuracy: 0.727800\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss:     0.0068 Validation Accuracy: 0.722600\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss:     0.0297 Validation Accuracy: 0.715400\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss:     0.0120 Validation Accuracy: 0.718600\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:     0.0287 Validation Accuracy: 0.714800\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss:     0.0102 Validation Accuracy: 0.721600\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss:     0.0060 Validation Accuracy: 0.723200\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss:     0.0240 Validation Accuracy: 0.718400\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss:     0.0128 Validation Accuracy: 0.708800\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:     0.0267 Validation Accuracy: 0.706000\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss:     0.0118 Validation Accuracy: 0.730600\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss:     0.0059 Validation Accuracy: 0.721400\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss:     0.0206 Validation Accuracy: 0.723400\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss:     0.0097 Validation Accuracy: 0.706600\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:     0.0260 Validation Accuracy: 0.707600\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss:     0.0151 Validation Accuracy: 0.717200\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss:     0.0097 Validation Accuracy: 0.724400\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss:     0.0196 Validation Accuracy: 0.724600\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss:     0.0104 Validation Accuracy: 0.714400\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:     0.0220 Validation Accuracy: 0.714400\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss:     0.0143 Validation Accuracy: 0.725000\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss:     0.0070 Validation Accuracy: 0.720600\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss:     0.0242 Validation Accuracy: 0.720200\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss:     0.0074 Validation Accuracy: 0.716000\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:     0.0127 Validation Accuracy: 0.715400\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss:     0.0128 Validation Accuracy: 0.719800\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss:     0.0063 Validation Accuracy: 0.721800\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss:     0.0207 Validation Accuracy: 0.726400\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss:     0.0115 Validation Accuracy: 0.709800\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:     0.0182 Validation Accuracy: 0.711800\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss:     0.0242 Validation Accuracy: 0.716000\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss:     0.0070 Validation Accuracy: 0.717200\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss:     0.0233 Validation Accuracy: 0.727800\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss:     0.0126 Validation Accuracy: 0.721600\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:     0.0205 Validation Accuracy: 0.716200\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss:     0.0156 Validation Accuracy: 0.723800\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss:     0.0053 Validation Accuracy: 0.713400\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss:     0.0139 Validation Accuracy: 0.721600\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss:     0.0079 Validation Accuracy: 0.703600\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:     0.0195 Validation Accuracy: 0.712600\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss:     0.0124 Validation Accuracy: 0.715000\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss:     0.0084 Validation Accuracy: 0.723200\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss:     0.0112 Validation Accuracy: 0.729000\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss:     0.0122 Validation Accuracy: 0.716000\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:     0.0174 Validation Accuracy: 0.719800\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss:     0.0210 Validation Accuracy: 0.721200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87, CIFAR-10 Batch 3:  Loss:     0.0097 Validation Accuracy: 0.715800\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss:     0.0134 Validation Accuracy: 0.721400\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss:     0.0132 Validation Accuracy: 0.714200\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:     0.0232 Validation Accuracy: 0.717200\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss:     0.0288 Validation Accuracy: 0.714200\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss:     0.0084 Validation Accuracy: 0.718000\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss:     0.0110 Validation Accuracy: 0.724800\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss:     0.0128 Validation Accuracy: 0.723200\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:     0.0147 Validation Accuracy: 0.718800\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss:     0.0135 Validation Accuracy: 0.720000\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss:     0.0071 Validation Accuracy: 0.717200\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss:     0.0133 Validation Accuracy: 0.720200\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss:     0.0156 Validation Accuracy: 0.720200\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:     0.0241 Validation Accuracy: 0.711400\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss:     0.0225 Validation Accuracy: 0.713400\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss:     0.0090 Validation Accuracy: 0.715000\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss:     0.0163 Validation Accuracy: 0.709200\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss:     0.0256 Validation Accuracy: 0.710800\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:     0.0128 Validation Accuracy: 0.715000\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss:     0.0130 Validation Accuracy: 0.718600\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss:     0.0066 Validation Accuracy: 0.713000\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss:     0.0158 Validation Accuracy: 0.714000\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss:     0.0172 Validation Accuracy: 0.710400\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:     0.0157 Validation Accuracy: 0.713800\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss:     0.0108 Validation Accuracy: 0.708200\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss:     0.0115 Validation Accuracy: 0.711600\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss:     0.0348 Validation Accuracy: 0.713200\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss:     0.0114 Validation Accuracy: 0.713600\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:     0.0207 Validation Accuracy: 0.707800\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss:     0.0111 Validation Accuracy: 0.712000\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss:     0.0160 Validation Accuracy: 0.706200\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss:     0.0263 Validation Accuracy: 0.705200\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss:     0.0121 Validation Accuracy: 0.710000\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:     0.0141 Validation Accuracy: 0.717400\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss:     0.0117 Validation Accuracy: 0.712600\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss:     0.0187 Validation Accuracy: 0.706000\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss:     0.0166 Validation Accuracy: 0.706000\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss:     0.0147 Validation Accuracy: 0.703800\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:     0.0125 Validation Accuracy: 0.717600\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss:     0.0198 Validation Accuracy: 0.712400\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss:     0.0166 Validation Accuracy: 0.705400\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss:     0.0219 Validation Accuracy: 0.705600\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss:     0.0145 Validation Accuracy: 0.711400\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:     0.0185 Validation Accuracy: 0.712400\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss:     0.0153 Validation Accuracy: 0.707200\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss:     0.0059 Validation Accuracy: 0.716800\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss:     0.0162 Validation Accuracy: 0.704000\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss:     0.0141 Validation Accuracy: 0.712600\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:     0.0138 Validation Accuracy: 0.716200\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss:     0.0113 Validation Accuracy: 0.707000\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss:     0.0067 Validation Accuracy: 0.717800\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss:     0.0123 Validation Accuracy: 0.703800\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss:     0.0119 Validation Accuracy: 0.711200\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:     0.0116 Validation Accuracy: 0.722000\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss:     0.0106 Validation Accuracy: 0.698000\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss:     0.0081 Validation Accuracy: 0.717200\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss:     0.0137 Validation Accuracy: 0.707400\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss:     0.0144 Validation Accuracy: 0.713800\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:     0.0176 Validation Accuracy: 0.719000\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss:     0.0120 Validation Accuracy: 0.708200\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss:     0.0090 Validation Accuracy: 0.712200\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss:     0.0097 Validation Accuracy: 0.715000\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss:     0.0115 Validation Accuracy: 0.716400\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:     0.0128 Validation Accuracy: 0.716800\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss:     0.0166 Validation Accuracy: 0.700800\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss:     0.0054 Validation Accuracy: 0.725200\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss:     0.0128 Validation Accuracy: 0.698200\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss:     0.0140 Validation Accuracy: 0.712000\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss:     0.0125 Validation Accuracy: 0.712200\n",
      "Epoch 101, CIFAR-10 Batch 2:  Loss:     0.0135 Validation Accuracy: 0.707600\n",
      "Epoch 101, CIFAR-10 Batch 3:  Loss:     0.0038 Validation Accuracy: 0.718800\n",
      "Epoch 101, CIFAR-10 Batch 4:  Loss:     0.0115 Validation Accuracy: 0.701400\n",
      "Epoch 101, CIFAR-10 Batch 5:  Loss:     0.0179 Validation Accuracy: 0.717000\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss:     0.0075 Validation Accuracy: 0.706200\n",
      "Epoch 102, CIFAR-10 Batch 2:  Loss:     0.0144 Validation Accuracy: 0.707400\n",
      "Epoch 102, CIFAR-10 Batch 3:  Loss:     0.0059 Validation Accuracy: 0.717400\n",
      "Epoch 102, CIFAR-10 Batch 4:  Loss:     0.0070 Validation Accuracy: 0.714400\n",
      "Epoch 102, CIFAR-10 Batch 5:  Loss:     0.0111 Validation Accuracy: 0.712800\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss:     0.0229 Validation Accuracy: 0.715600\n",
      "Epoch 103, CIFAR-10 Batch 2:  Loss:     0.0111 Validation Accuracy: 0.706400\n",
      "Epoch 103, CIFAR-10 Batch 3:  Loss:     0.0049 Validation Accuracy: 0.719800\n",
      "Epoch 103, CIFAR-10 Batch 4:  Loss:     0.0123 Validation Accuracy: 0.710800\n",
      "Epoch 103, CIFAR-10 Batch 5:  Loss:     0.0184 Validation Accuracy: 0.711800\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss:     0.0110 Validation Accuracy: 0.720000\n",
      "Epoch 104, CIFAR-10 Batch 2:  Loss:     0.0126 Validation Accuracy: 0.689000\n",
      "Epoch 104, CIFAR-10 Batch 3:  Loss:     0.0032 Validation Accuracy: 0.717800\n",
      "Epoch 104, CIFAR-10 Batch 4:  Loss:     0.0078 Validation Accuracy: 0.717000\n",
      "Epoch 104, CIFAR-10 Batch 5:  Loss:     0.0120 Validation Accuracy: 0.714600\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss:     0.0155 Validation Accuracy: 0.715000\n",
      "Epoch 105, CIFAR-10 Batch 2:  Loss:     0.0124 Validation Accuracy: 0.702000\n",
      "Epoch 105, CIFAR-10 Batch 3:  Loss:     0.0046 Validation Accuracy: 0.716600\n",
      "Epoch 105, CIFAR-10 Batch 4:  Loss:     0.0130 Validation Accuracy: 0.709000\n",
      "Epoch 105, CIFAR-10 Batch 5:  Loss:     0.0051 Validation Accuracy: 0.719400\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss:     0.0103 Validation Accuracy: 0.714800\n",
      "Epoch 106, CIFAR-10 Batch 2:  Loss:     0.0124 Validation Accuracy: 0.703400\n",
      "Epoch 106, CIFAR-10 Batch 3:  Loss:     0.0063 Validation Accuracy: 0.721200\n",
      "Epoch 106, CIFAR-10 Batch 4:  Loss:     0.0105 Validation Accuracy: 0.691000\n",
      "Epoch 106, CIFAR-10 Batch 5:  Loss:     0.0103 Validation Accuracy: 0.718200\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss:     0.0141 Validation Accuracy: 0.713200\n",
      "Epoch 107, CIFAR-10 Batch 2:  Loss:     0.0066 Validation Accuracy: 0.712000\n",
      "Epoch 107, CIFAR-10 Batch 3:  Loss:     0.0030 Validation Accuracy: 0.720600\n",
      "Epoch 107, CIFAR-10 Batch 4:  Loss:     0.0116 Validation Accuracy: 0.712200\n",
      "Epoch 107, CIFAR-10 Batch 5:  Loss:     0.0123 Validation Accuracy: 0.715000\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss:     0.0101 Validation Accuracy: 0.717000\n",
      "Epoch 108, CIFAR-10 Batch 2:  Loss:     0.0087 Validation Accuracy: 0.708200\n",
      "Epoch 108, CIFAR-10 Batch 3:  Loss:     0.0058 Validation Accuracy: 0.717400\n",
      "Epoch 108, CIFAR-10 Batch 4:  Loss:     0.0055 Validation Accuracy: 0.710800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108, CIFAR-10 Batch 5:  Loss:     0.0109 Validation Accuracy: 0.722400\n",
      "Epoch 109, CIFAR-10 Batch 1:  Loss:     0.0113 Validation Accuracy: 0.711600\n",
      "Epoch 109, CIFAR-10 Batch 2:  Loss:     0.0144 Validation Accuracy: 0.695000\n",
      "Epoch 109, CIFAR-10 Batch 3:  Loss:     0.0047 Validation Accuracy: 0.715000\n",
      "Epoch 109, CIFAR-10 Batch 4:  Loss:     0.0067 Validation Accuracy: 0.718800\n",
      "Epoch 109, CIFAR-10 Batch 5:  Loss:     0.0059 Validation Accuracy: 0.721200\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss:     0.0114 Validation Accuracy: 0.716800\n",
      "Epoch 110, CIFAR-10 Batch 2:  Loss:     0.0070 Validation Accuracy: 0.710400\n",
      "Epoch 110, CIFAR-10 Batch 3:  Loss:     0.0051 Validation Accuracy: 0.714800\n",
      "Epoch 110, CIFAR-10 Batch 4:  Loss:     0.0048 Validation Accuracy: 0.710000\n",
      "Epoch 110, CIFAR-10 Batch 5:  Loss:     0.0066 Validation Accuracy: 0.715800\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss:     0.0131 Validation Accuracy: 0.716200\n",
      "Epoch 111, CIFAR-10 Batch 2:  Loss:     0.0049 Validation Accuracy: 0.706800\n",
      "Epoch 111, CIFAR-10 Batch 3:  Loss:     0.0056 Validation Accuracy: 0.719000\n",
      "Epoch 111, CIFAR-10 Batch 4:  Loss:     0.0097 Validation Accuracy: 0.719600\n",
      "Epoch 111, CIFAR-10 Batch 5:  Loss:     0.0047 Validation Accuracy: 0.712800\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss:     0.0088 Validation Accuracy: 0.714200\n",
      "Epoch 112, CIFAR-10 Batch 2:  Loss:     0.0051 Validation Accuracy: 0.713400\n",
      "Epoch 112, CIFAR-10 Batch 3:  Loss:     0.0033 Validation Accuracy: 0.718800\n",
      "Epoch 112, CIFAR-10 Batch 4:  Loss:     0.0113 Validation Accuracy: 0.692600\n",
      "Epoch 112, CIFAR-10 Batch 5:  Loss:     0.0052 Validation Accuracy: 0.713000\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss:     0.0177 Validation Accuracy: 0.712400\n",
      "Epoch 113, CIFAR-10 Batch 2:  Loss:     0.0110 Validation Accuracy: 0.712600\n",
      "Epoch 113, CIFAR-10 Batch 3:  Loss:     0.0060 Validation Accuracy: 0.719000\n",
      "Epoch 113, CIFAR-10 Batch 4:  Loss:     0.0094 Validation Accuracy: 0.709800\n",
      "Epoch 113, CIFAR-10 Batch 5:  Loss:     0.0031 Validation Accuracy: 0.721400\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss:     0.0096 Validation Accuracy: 0.714600\n",
      "Epoch 114, CIFAR-10 Batch 2:  Loss:     0.0080 Validation Accuracy: 0.710400\n",
      "Epoch 114, CIFAR-10 Batch 3:  Loss:     0.0037 Validation Accuracy: 0.720200\n",
      "Epoch 114, CIFAR-10 Batch 4:  Loss:     0.0051 Validation Accuracy: 0.710400\n",
      "Epoch 114, CIFAR-10 Batch 5:  Loss:     0.0051 Validation Accuracy: 0.719800\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss:     0.0067 Validation Accuracy: 0.721000\n",
      "Epoch 115, CIFAR-10 Batch 2:  Loss:     0.0148 Validation Accuracy: 0.703000\n",
      "Epoch 115, CIFAR-10 Batch 3:  Loss:     0.0074 Validation Accuracy: 0.713400\n",
      "Epoch 115, CIFAR-10 Batch 4:  Loss:     0.0070 Validation Accuracy: 0.710000\n",
      "Epoch 115, CIFAR-10 Batch 5:  Loss:     0.0111 Validation Accuracy: 0.710600\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss:     0.0073 Validation Accuracy: 0.715000\n",
      "Epoch 116, CIFAR-10 Batch 2:  Loss:     0.0138 Validation Accuracy: 0.714200\n",
      "Epoch 116, CIFAR-10 Batch 3:  Loss:     0.0026 Validation Accuracy: 0.718400\n",
      "Epoch 116, CIFAR-10 Batch 4:  Loss:     0.0099 Validation Accuracy: 0.718400\n",
      "Epoch 116, CIFAR-10 Batch 5:  Loss:     0.0078 Validation Accuracy: 0.721200\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss:     0.0102 Validation Accuracy: 0.707600\n",
      "Epoch 117, CIFAR-10 Batch 2:  Loss:     0.0088 Validation Accuracy: 0.705800\n",
      "Epoch 117, CIFAR-10 Batch 3:  Loss:     0.0044 Validation Accuracy: 0.714200\n",
      "Epoch 117, CIFAR-10 Batch 4:  Loss:     0.0059 Validation Accuracy: 0.711600\n",
      "Epoch 117, CIFAR-10 Batch 5:  Loss:     0.0062 Validation Accuracy: 0.722000\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss:     0.0111 Validation Accuracy: 0.714400\n",
      "Epoch 118, CIFAR-10 Batch 2:  Loss:     0.0094 Validation Accuracy: 0.702200\n",
      "Epoch 118, CIFAR-10 Batch 3:  Loss:     0.0083 Validation Accuracy: 0.708200\n",
      "Epoch 118, CIFAR-10 Batch 4:  Loss:     0.0119 Validation Accuracy: 0.710800\n",
      "Epoch 118, CIFAR-10 Batch 5:  Loss:     0.0094 Validation Accuracy: 0.719400\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss:     0.0102 Validation Accuracy: 0.716400\n",
      "Epoch 119, CIFAR-10 Batch 2:  Loss:     0.0090 Validation Accuracy: 0.707600\n",
      "Epoch 119, CIFAR-10 Batch 3:  Loss:     0.0026 Validation Accuracy: 0.721400\n",
      "Epoch 119, CIFAR-10 Batch 4:  Loss:     0.0056 Validation Accuracy: 0.716200\n",
      "Epoch 119, CIFAR-10 Batch 5:  Loss:     0.0042 Validation Accuracy: 0.719600\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss:     0.0135 Validation Accuracy: 0.715000\n",
      "Epoch 120, CIFAR-10 Batch 2:  Loss:     0.0079 Validation Accuracy: 0.713200\n",
      "Epoch 120, CIFAR-10 Batch 3:  Loss:     0.0050 Validation Accuracy: 0.719800\n",
      "Epoch 120, CIFAR-10 Batch 4:  Loss:     0.0107 Validation Accuracy: 0.716000\n",
      "Epoch 120, CIFAR-10 Batch 5:  Loss:     0.0065 Validation Accuracy: 0.718400\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss:     0.0081 Validation Accuracy: 0.712400\n",
      "Epoch 121, CIFAR-10 Batch 2:  Loss:     0.0115 Validation Accuracy: 0.716800\n",
      "Epoch 121, CIFAR-10 Batch 3:  Loss:     0.0032 Validation Accuracy: 0.714800\n",
      "Epoch 121, CIFAR-10 Batch 4:  Loss:     0.0084 Validation Accuracy: 0.707800\n",
      "Epoch 121, CIFAR-10 Batch 5:  Loss:     0.0030 Validation Accuracy: 0.723400\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss:     0.0094 Validation Accuracy: 0.715000\n",
      "Epoch 122, CIFAR-10 Batch 2:  Loss:     0.0080 Validation Accuracy: 0.708600\n",
      "Epoch 122, CIFAR-10 Batch 3:  Loss:     0.0034 Validation Accuracy: 0.716600\n",
      "Epoch 122, CIFAR-10 Batch 4:  Loss:     0.0112 Validation Accuracy: 0.715000\n",
      "Epoch 122, CIFAR-10 Batch 5:  Loss:     0.0039 Validation Accuracy: 0.720200\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss:     0.0094 Validation Accuracy: 0.716000\n",
      "Epoch 123, CIFAR-10 Batch 2:  Loss:     0.0070 Validation Accuracy: 0.717000\n",
      "Epoch 123, CIFAR-10 Batch 3:  Loss:     0.0041 Validation Accuracy: 0.715600\n",
      "Epoch 123, CIFAR-10 Batch 4:  Loss:     0.0132 Validation Accuracy: 0.712400\n",
      "Epoch 123, CIFAR-10 Batch 5:  Loss:     0.0067 Validation Accuracy: 0.715400\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss:     0.0102 Validation Accuracy: 0.699000\n",
      "Epoch 124, CIFAR-10 Batch 2:  Loss:     0.0090 Validation Accuracy: 0.718400\n",
      "Epoch 124, CIFAR-10 Batch 3:  Loss:     0.0032 Validation Accuracy: 0.718600\n",
      "Epoch 124, CIFAR-10 Batch 4:  Loss:     0.0202 Validation Accuracy: 0.711800\n",
      "Epoch 124, CIFAR-10 Batch 5:  Loss:     0.0048 Validation Accuracy: 0.717400\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss:     0.0067 Validation Accuracy: 0.710200\n",
      "Epoch 125, CIFAR-10 Batch 2:  Loss:     0.0061 Validation Accuracy: 0.720200\n",
      "Epoch 125, CIFAR-10 Batch 3:  Loss:     0.0074 Validation Accuracy: 0.716000\n",
      "Epoch 125, CIFAR-10 Batch 4:  Loss:     0.0067 Validation Accuracy: 0.716400\n",
      "Epoch 125, CIFAR-10 Batch 5:  Loss:     0.0054 Validation Accuracy: 0.714600\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss:     0.0038 Validation Accuracy: 0.711000\n",
      "Epoch 126, CIFAR-10 Batch 2:  Loss:     0.0033 Validation Accuracy: 0.712800\n",
      "Epoch 126, CIFAR-10 Batch 3:  Loss:     0.0046 Validation Accuracy: 0.710000\n",
      "Epoch 126, CIFAR-10 Batch 4:  Loss:     0.0047 Validation Accuracy: 0.715200\n",
      "Epoch 126, CIFAR-10 Batch 5:  Loss:     0.0100 Validation Accuracy: 0.725200\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss:     0.0063 Validation Accuracy: 0.713000\n",
      "Epoch 127, CIFAR-10 Batch 2:  Loss:     0.0066 Validation Accuracy: 0.715600\n",
      "Epoch 127, CIFAR-10 Batch 3:  Loss:     0.0035 Validation Accuracy: 0.719600\n",
      "Epoch 127, CIFAR-10 Batch 4:  Loss:     0.0078 Validation Accuracy: 0.721800\n",
      "Epoch 127, CIFAR-10 Batch 5:  Loss:     0.0144 Validation Accuracy: 0.717400\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss:     0.0043 Validation Accuracy: 0.711200\n",
      "Epoch 128, CIFAR-10 Batch 2:  Loss:     0.0044 Validation Accuracy: 0.722400\n",
      "Epoch 128, CIFAR-10 Batch 3:  Loss:     0.0073 Validation Accuracy: 0.712000\n",
      "Epoch 128, CIFAR-10 Batch 4:  Loss:     0.0066 Validation Accuracy: 0.722800\n",
      "Epoch 128, CIFAR-10 Batch 5:  Loss:     0.0068 Validation Accuracy: 0.709600\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss:     0.0056 Validation Accuracy: 0.716000\n",
      "Epoch 129, CIFAR-10 Batch 2:  Loss:     0.0067 Validation Accuracy: 0.719200\n",
      "Epoch 129, CIFAR-10 Batch 3:  Loss:     0.0107 Validation Accuracy: 0.713400\n",
      "Epoch 129, CIFAR-10 Batch 4:  Loss:     0.0042 Validation Accuracy: 0.712200\n",
      "Epoch 129, CIFAR-10 Batch 5:  Loss:     0.0097 Validation Accuracy: 0.696000\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss:     0.0055 Validation Accuracy: 0.718800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130, CIFAR-10 Batch 2:  Loss:     0.0137 Validation Accuracy: 0.714400\n",
      "Epoch 130, CIFAR-10 Batch 3:  Loss:     0.0044 Validation Accuracy: 0.708400\n",
      "Epoch 130, CIFAR-10 Batch 4:  Loss:     0.0049 Validation Accuracy: 0.713200\n",
      "Epoch 130, CIFAR-10 Batch 5:  Loss:     0.0047 Validation Accuracy: 0.718000\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss:     0.0061 Validation Accuracy: 0.710400\n",
      "Epoch 131, CIFAR-10 Batch 2:  Loss:     0.0055 Validation Accuracy: 0.716400\n",
      "Epoch 131, CIFAR-10 Batch 3:  Loss:     0.0042 Validation Accuracy: 0.713400\n",
      "Epoch 131, CIFAR-10 Batch 4:  Loss:     0.0137 Validation Accuracy: 0.715200\n",
      "Epoch 131, CIFAR-10 Batch 5:  Loss:     0.0076 Validation Accuracy: 0.716400\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss:     0.0057 Validation Accuracy: 0.719400\n",
      "Epoch 132, CIFAR-10 Batch 2:  Loss:     0.0052 Validation Accuracy: 0.715800\n",
      "Epoch 132, CIFAR-10 Batch 3:  Loss:     0.0036 Validation Accuracy: 0.713800\n",
      "Epoch 132, CIFAR-10 Batch 4:  Loss:     0.0083 Validation Accuracy: 0.709200\n",
      "Epoch 132, CIFAR-10 Batch 5:  Loss:     0.0046 Validation Accuracy: 0.716200\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss:     0.0070 Validation Accuracy: 0.710200\n",
      "Epoch 133, CIFAR-10 Batch 2:  Loss:     0.0059 Validation Accuracy: 0.724200\n",
      "Epoch 133, CIFAR-10 Batch 3:  Loss:     0.0020 Validation Accuracy: 0.719000\n",
      "Epoch 133, CIFAR-10 Batch 4:  Loss:     0.0067 Validation Accuracy: 0.712000\n",
      "Epoch 133, CIFAR-10 Batch 5:  Loss:     0.0045 Validation Accuracy: 0.707200\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss:     0.0046 Validation Accuracy: 0.711200\n",
      "Epoch 134, CIFAR-10 Batch 2:  Loss:     0.0118 Validation Accuracy: 0.713400\n",
      "Epoch 134, CIFAR-10 Batch 3:  Loss:     0.0040 Validation Accuracy: 0.713200\n",
      "Epoch 134, CIFAR-10 Batch 4:  Loss:     0.0059 Validation Accuracy: 0.714400\n",
      "Epoch 134, CIFAR-10 Batch 5:  Loss:     0.0095 Validation Accuracy: 0.709000\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss:     0.0079 Validation Accuracy: 0.704200\n",
      "Epoch 135, CIFAR-10 Batch 2:  Loss:     0.0039 Validation Accuracy: 0.716200\n",
      "Epoch 135, CIFAR-10 Batch 3:  Loss:     0.0027 Validation Accuracy: 0.715800\n",
      "Epoch 135, CIFAR-10 Batch 4:  Loss:     0.0063 Validation Accuracy: 0.714200\n",
      "Epoch 135, CIFAR-10 Batch 5:  Loss:     0.0087 Validation Accuracy: 0.705600\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss:     0.0082 Validation Accuracy: 0.713400\n",
      "Epoch 136, CIFAR-10 Batch 2:  Loss:     0.0075 Validation Accuracy: 0.727200\n",
      "Epoch 136, CIFAR-10 Batch 3:  Loss:     0.0034 Validation Accuracy: 0.713400\n",
      "Epoch 136, CIFAR-10 Batch 4:  Loss:     0.0121 Validation Accuracy: 0.711400\n",
      "Epoch 136, CIFAR-10 Batch 5:  Loss:     0.0066 Validation Accuracy: 0.701400\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss:     0.0091 Validation Accuracy: 0.709000\n",
      "Epoch 137, CIFAR-10 Batch 2:  Loss:     0.0063 Validation Accuracy: 0.719000\n",
      "Epoch 137, CIFAR-10 Batch 3:  Loss:     0.0051 Validation Accuracy: 0.713000\n",
      "Epoch 137, CIFAR-10 Batch 4:  Loss:     0.0063 Validation Accuracy: 0.712400\n",
      "Epoch 137, CIFAR-10 Batch 5:  Loss:     0.0046 Validation Accuracy: 0.705400\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss:     0.0070 Validation Accuracy: 0.712600\n",
      "Epoch 138, CIFAR-10 Batch 2:  Loss:     0.0069 Validation Accuracy: 0.717600\n",
      "Epoch 138, CIFAR-10 Batch 3:  Loss:     0.0028 Validation Accuracy: 0.718400\n",
      "Epoch 138, CIFAR-10 Batch 4:  Loss:     0.0067 Validation Accuracy: 0.720400\n",
      "Epoch 138, CIFAR-10 Batch 5:  Loss:     0.0070 Validation Accuracy: 0.706600\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss:     0.0070 Validation Accuracy: 0.706800\n",
      "Epoch 139, CIFAR-10 Batch 2:  Loss:     0.0042 Validation Accuracy: 0.713000\n",
      "Epoch 139, CIFAR-10 Batch 3:  Loss:     0.0039 Validation Accuracy: 0.715400\n",
      "Epoch 139, CIFAR-10 Batch 4:  Loss:     0.0064 Validation Accuracy: 0.717000\n",
      "Epoch 139, CIFAR-10 Batch 5:  Loss:     0.0034 Validation Accuracy: 0.710400\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss:     0.0054 Validation Accuracy: 0.711200\n",
      "Epoch 140, CIFAR-10 Batch 2:  Loss:     0.0047 Validation Accuracy: 0.719200\n",
      "Epoch 140, CIFAR-10 Batch 3:  Loss:     0.0031 Validation Accuracy: 0.713000\n",
      "Epoch 140, CIFAR-10 Batch 4:  Loss:     0.0084 Validation Accuracy: 0.712600\n",
      "Epoch 140, CIFAR-10 Batch 5:  Loss:     0.0188 Validation Accuracy: 0.701400\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss:     0.0075 Validation Accuracy: 0.715000\n",
      "Epoch 141, CIFAR-10 Batch 2:  Loss:     0.0058 Validation Accuracy: 0.717200\n",
      "Epoch 141, CIFAR-10 Batch 3:  Loss:     0.0060 Validation Accuracy: 0.716800\n",
      "Epoch 141, CIFAR-10 Batch 4:  Loss:     0.0168 Validation Accuracy: 0.707000\n",
      "Epoch 141, CIFAR-10 Batch 5:  Loss:     0.0071 Validation Accuracy: 0.704800\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss:     0.0157 Validation Accuracy: 0.712800\n",
      "Epoch 142, CIFAR-10 Batch 2:  Loss:     0.0030 Validation Accuracy: 0.707400\n",
      "Epoch 142, CIFAR-10 Batch 3:  Loss:     0.0048 Validation Accuracy: 0.711800\n",
      "Epoch 142, CIFAR-10 Batch 4:  Loss:     0.0075 Validation Accuracy: 0.716000\n",
      "Epoch 142, CIFAR-10 Batch 5:  Loss:     0.0095 Validation Accuracy: 0.702600\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss:     0.0060 Validation Accuracy: 0.710400\n",
      "Epoch 143, CIFAR-10 Batch 2:  Loss:     0.0103 Validation Accuracy: 0.721800\n",
      "Epoch 143, CIFAR-10 Batch 3:  Loss:     0.0068 Validation Accuracy: 0.715400\n",
      "Epoch 143, CIFAR-10 Batch 4:  Loss:     0.0020 Validation Accuracy: 0.711200\n",
      "Epoch 143, CIFAR-10 Batch 5:  Loss:     0.0158 Validation Accuracy: 0.701000\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss:     0.0063 Validation Accuracy: 0.707400\n",
      "Epoch 144, CIFAR-10 Batch 2:  Loss:     0.0046 Validation Accuracy: 0.715600\n",
      "Epoch 144, CIFAR-10 Batch 3:  Loss:     0.0030 Validation Accuracy: 0.716800\n",
      "Epoch 144, CIFAR-10 Batch 4:  Loss:     0.0047 Validation Accuracy: 0.711200\n",
      "Epoch 144, CIFAR-10 Batch 5:  Loss:     0.0043 Validation Accuracy: 0.706800\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss:     0.0063 Validation Accuracy: 0.708600\n",
      "Epoch 145, CIFAR-10 Batch 2:  Loss:     0.0060 Validation Accuracy: 0.718000\n",
      "Epoch 145, CIFAR-10 Batch 3:  Loss:     0.0008 Validation Accuracy: 0.713400\n",
      "Epoch 145, CIFAR-10 Batch 4:  Loss:     0.0057 Validation Accuracy: 0.708600\n",
      "Epoch 145, CIFAR-10 Batch 5:  Loss:     0.0055 Validation Accuracy: 0.701000\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss:     0.0062 Validation Accuracy: 0.711600\n",
      "Epoch 146, CIFAR-10 Batch 2:  Loss:     0.0044 Validation Accuracy: 0.710000\n",
      "Epoch 146, CIFAR-10 Batch 3:  Loss:     0.0022 Validation Accuracy: 0.715600\n",
      "Epoch 146, CIFAR-10 Batch 4:  Loss:     0.0056 Validation Accuracy: 0.709600\n",
      "Epoch 146, CIFAR-10 Batch 5:  Loss:     0.0070 Validation Accuracy: 0.702200\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss:     0.0056 Validation Accuracy: 0.707600\n",
      "Epoch 147, CIFAR-10 Batch 2:  Loss:     0.0043 Validation Accuracy: 0.715400\n",
      "Epoch 147, CIFAR-10 Batch 3:  Loss:     0.0022 Validation Accuracy: 0.715200\n",
      "Epoch 147, CIFAR-10 Batch 4:  Loss:     0.0074 Validation Accuracy: 0.713200\n",
      "Epoch 147, CIFAR-10 Batch 5:  Loss:     0.0018 Validation Accuracy: 0.709000\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss:     0.0048 Validation Accuracy: 0.706800\n",
      "Epoch 148, CIFAR-10 Batch 2:  Loss:     0.0037 Validation Accuracy: 0.717400\n",
      "Epoch 148, CIFAR-10 Batch 3:  Loss:     0.0051 Validation Accuracy: 0.716800\n",
      "Epoch 148, CIFAR-10 Batch 4:  Loss:     0.0086 Validation Accuracy: 0.709600\n",
      "Epoch 148, CIFAR-10 Batch 5:  Loss:     0.0031 Validation Accuracy: 0.709600\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss:     0.0060 Validation Accuracy: 0.710200\n",
      "Epoch 149, CIFAR-10 Batch 2:  Loss:     0.0055 Validation Accuracy: 0.713800\n",
      "Epoch 149, CIFAR-10 Batch 3:  Loss:     0.0014 Validation Accuracy: 0.716000\n",
      "Epoch 149, CIFAR-10 Batch 4:  Loss:     0.0058 Validation Accuracy: 0.709200\n",
      "Epoch 149, CIFAR-10 Batch 5:  Loss:     0.0022 Validation Accuracy: 0.716000\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss:     0.0069 Validation Accuracy: 0.706200\n",
      "Epoch 150, CIFAR-10 Batch 2:  Loss:     0.0041 Validation Accuracy: 0.720400\n",
      "Epoch 150, CIFAR-10 Batch 3:  Loss:     0.0020 Validation Accuracy: 0.715000\n",
      "Epoch 150, CIFAR-10 Batch 4:  Loss:     0.0025 Validation Accuracy: 0.714600\n",
      "Epoch 150, CIFAR-10 Batch 5:  Loss:     0.0034 Validation Accuracy: 0.709800\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss:     0.0069 Validation Accuracy: 0.709400\n",
      "Epoch 151, CIFAR-10 Batch 2:  Loss:     0.0033 Validation Accuracy: 0.714400\n",
      "Epoch 151, CIFAR-10 Batch 3:  Loss:     0.0015 Validation Accuracy: 0.717400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151, CIFAR-10 Batch 4:  Loss:     0.0083 Validation Accuracy: 0.712000\n",
      "Epoch 151, CIFAR-10 Batch 5:  Loss:     0.0037 Validation Accuracy: 0.705200\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss:     0.0048 Validation Accuracy: 0.709200\n",
      "Epoch 152, CIFAR-10 Batch 2:  Loss:     0.0065 Validation Accuracy: 0.718800\n",
      "Epoch 152, CIFAR-10 Batch 3:  Loss:     0.0015 Validation Accuracy: 0.713400\n",
      "Epoch 152, CIFAR-10 Batch 4:  Loss:     0.0095 Validation Accuracy: 0.711800\n",
      "Epoch 152, CIFAR-10 Batch 5:  Loss:     0.0034 Validation Accuracy: 0.701000\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss:     0.0064 Validation Accuracy: 0.712800\n",
      "Epoch 153, CIFAR-10 Batch 2:  Loss:     0.0031 Validation Accuracy: 0.715400\n",
      "Epoch 153, CIFAR-10 Batch 3:  Loss:     0.0030 Validation Accuracy: 0.717000\n",
      "Epoch 153, CIFAR-10 Batch 4:  Loss:     0.0061 Validation Accuracy: 0.710200\n",
      "Epoch 153, CIFAR-10 Batch 5:  Loss:     0.0032 Validation Accuracy: 0.705200\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss:     0.0032 Validation Accuracy: 0.707600\n",
      "Epoch 154, CIFAR-10 Batch 2:  Loss:     0.0062 Validation Accuracy: 0.711600\n",
      "Epoch 154, CIFAR-10 Batch 3:  Loss:     0.0016 Validation Accuracy: 0.717800\n",
      "Epoch 154, CIFAR-10 Batch 4:  Loss:     0.0072 Validation Accuracy: 0.711600\n",
      "Epoch 154, CIFAR-10 Batch 5:  Loss:     0.0032 Validation Accuracy: 0.702200\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss:     0.0041 Validation Accuracy: 0.713200\n",
      "Epoch 155, CIFAR-10 Batch 2:  Loss:     0.0039 Validation Accuracy: 0.714800\n",
      "Epoch 155, CIFAR-10 Batch 3:  Loss:     0.0009 Validation Accuracy: 0.716600\n",
      "Epoch 155, CIFAR-10 Batch 4:  Loss:     0.0077 Validation Accuracy: 0.711400\n",
      "Epoch 155, CIFAR-10 Batch 5:  Loss:     0.0027 Validation Accuracy: 0.714200\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss:     0.0032 Validation Accuracy: 0.710200\n",
      "Epoch 156, CIFAR-10 Batch 2:  Loss:     0.0038 Validation Accuracy: 0.716400\n",
      "Epoch 156, CIFAR-10 Batch 3:  Loss:     0.0020 Validation Accuracy: 0.721200\n",
      "Epoch 156, CIFAR-10 Batch 4:  Loss:     0.0041 Validation Accuracy: 0.714000\n",
      "Epoch 156, CIFAR-10 Batch 5:  Loss:     0.0028 Validation Accuracy: 0.707400\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss:     0.0024 Validation Accuracy: 0.711600\n",
      "Epoch 157, CIFAR-10 Batch 2:  Loss:     0.0132 Validation Accuracy: 0.708200\n",
      "Epoch 157, CIFAR-10 Batch 3:  Loss:     0.0019 Validation Accuracy: 0.719200\n",
      "Epoch 157, CIFAR-10 Batch 4:  Loss:     0.0066 Validation Accuracy: 0.709400\n",
      "Epoch 157, CIFAR-10 Batch 5:  Loss:     0.0048 Validation Accuracy: 0.706800\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss:     0.0084 Validation Accuracy: 0.711400\n",
      "Epoch 158, CIFAR-10 Batch 2:  Loss:     0.0114 Validation Accuracy: 0.708600\n",
      "Epoch 158, CIFAR-10 Batch 3:  Loss:     0.0013 Validation Accuracy: 0.716200\n",
      "Epoch 158, CIFAR-10 Batch 4:  Loss:     0.0033 Validation Accuracy: 0.712200\n",
      "Epoch 158, CIFAR-10 Batch 5:  Loss:     0.0019 Validation Accuracy: 0.706000\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss:     0.0047 Validation Accuracy: 0.710200\n",
      "Epoch 159, CIFAR-10 Batch 2:  Loss:     0.0062 Validation Accuracy: 0.714000\n",
      "Epoch 159, CIFAR-10 Batch 3:  Loss:     0.0006 Validation Accuracy: 0.718200\n",
      "Epoch 159, CIFAR-10 Batch 4:  Loss:     0.0074 Validation Accuracy: 0.711200\n",
      "Epoch 159, CIFAR-10 Batch 5:  Loss:     0.0064 Validation Accuracy: 0.715400\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss:     0.0068 Validation Accuracy: 0.711400\n",
      "Epoch 160, CIFAR-10 Batch 2:  Loss:     0.0046 Validation Accuracy: 0.707000\n",
      "Epoch 160, CIFAR-10 Batch 3:  Loss:     0.0019 Validation Accuracy: 0.717800\n",
      "Epoch 160, CIFAR-10 Batch 4:  Loss:     0.0092 Validation Accuracy: 0.718200\n",
      "Epoch 160, CIFAR-10 Batch 5:  Loss:     0.0025 Validation Accuracy: 0.701800\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss:     0.0054 Validation Accuracy: 0.713600\n",
      "Epoch 161, CIFAR-10 Batch 2:  Loss:     0.0029 Validation Accuracy: 0.710200\n",
      "Epoch 161, CIFAR-10 Batch 3:  Loss:     0.0017 Validation Accuracy: 0.710800\n",
      "Epoch 161, CIFAR-10 Batch 4:  Loss:     0.0032 Validation Accuracy: 0.707600\n",
      "Epoch 161, CIFAR-10 Batch 5:  Loss:     0.0040 Validation Accuracy: 0.703800\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss:     0.0073 Validation Accuracy: 0.713000\n",
      "Epoch 162, CIFAR-10 Batch 2:  Loss:     0.0050 Validation Accuracy: 0.709000\n",
      "Epoch 162, CIFAR-10 Batch 3:  Loss:     0.0019 Validation Accuracy: 0.715800\n",
      "Epoch 162, CIFAR-10 Batch 4:  Loss:     0.0043 Validation Accuracy: 0.714400\n",
      "Epoch 162, CIFAR-10 Batch 5:  Loss:     0.0007 Validation Accuracy: 0.717600\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss:     0.0075 Validation Accuracy: 0.713800\n",
      "Epoch 163, CIFAR-10 Batch 2:  Loss:     0.0038 Validation Accuracy: 0.712800\n",
      "Epoch 163, CIFAR-10 Batch 3:  Loss:     0.0032 Validation Accuracy: 0.715800\n",
      "Epoch 163, CIFAR-10 Batch 4:  Loss:     0.0021 Validation Accuracy: 0.715000\n",
      "Epoch 163, CIFAR-10 Batch 5:  Loss:     0.0021 Validation Accuracy: 0.703200\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss:     0.0068 Validation Accuracy: 0.706800\n",
      "Epoch 164, CIFAR-10 Batch 2:  Loss:     0.0066 Validation Accuracy: 0.707400\n",
      "Epoch 164, CIFAR-10 Batch 3:  Loss:     0.0040 Validation Accuracy: 0.713200\n",
      "Epoch 164, CIFAR-10 Batch 4:  Loss:     0.0034 Validation Accuracy: 0.714800\n",
      "Epoch 164, CIFAR-10 Batch 5:  Loss:     0.0102 Validation Accuracy: 0.709600\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss:     0.0077 Validation Accuracy: 0.713800\n",
      "Epoch 165, CIFAR-10 Batch 2:  Loss:     0.0044 Validation Accuracy: 0.710000\n",
      "Epoch 165, CIFAR-10 Batch 3:  Loss:     0.0010 Validation Accuracy: 0.716000\n",
      "Epoch 165, CIFAR-10 Batch 4:  Loss:     0.0036 Validation Accuracy: 0.712200\n",
      "Epoch 165, CIFAR-10 Batch 5:  Loss:     0.0032 Validation Accuracy: 0.716000\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss:     0.0054 Validation Accuracy: 0.712600\n",
      "Epoch 166, CIFAR-10 Batch 2:  Loss:     0.0040 Validation Accuracy: 0.703200\n",
      "Epoch 166, CIFAR-10 Batch 3:  Loss:     0.0053 Validation Accuracy: 0.705000\n",
      "Epoch 166, CIFAR-10 Batch 4:  Loss:     0.0030 Validation Accuracy: 0.712600\n",
      "Epoch 166, CIFAR-10 Batch 5:  Loss:     0.0053 Validation Accuracy: 0.706400\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss:     0.0042 Validation Accuracy: 0.713200\n",
      "Epoch 167, CIFAR-10 Batch 2:  Loss:     0.0096 Validation Accuracy: 0.714400\n",
      "Epoch 167, CIFAR-10 Batch 3:  Loss:     0.0025 Validation Accuracy: 0.715400\n",
      "Epoch 167, CIFAR-10 Batch 4:  Loss:     0.0022 Validation Accuracy: 0.710200\n",
      "Epoch 167, CIFAR-10 Batch 5:  Loss:     0.0038 Validation Accuracy: 0.709200\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss:     0.0057 Validation Accuracy: 0.705600\n",
      "Epoch 168, CIFAR-10 Batch 2:  Loss:     0.0067 Validation Accuracy: 0.702600\n",
      "Epoch 168, CIFAR-10 Batch 3:  Loss:     0.0021 Validation Accuracy: 0.714600\n",
      "Epoch 168, CIFAR-10 Batch 4:  Loss:     0.0025 Validation Accuracy: 0.712000\n",
      "Epoch 168, CIFAR-10 Batch 5:  Loss:     0.0025 Validation Accuracy: 0.710200\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss:     0.0037 Validation Accuracy: 0.707600\n",
      "Epoch 169, CIFAR-10 Batch 2:  Loss:     0.0058 Validation Accuracy: 0.712600\n",
      "Epoch 169, CIFAR-10 Batch 3:  Loss:     0.0016 Validation Accuracy: 0.707000\n",
      "Epoch 169, CIFAR-10 Batch 4:  Loss:     0.0043 Validation Accuracy: 0.707000\n",
      "Epoch 169, CIFAR-10 Batch 5:  Loss:     0.0024 Validation Accuracy: 0.711800\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss:     0.0073 Validation Accuracy: 0.706000\n",
      "Epoch 170, CIFAR-10 Batch 2:  Loss:     0.0104 Validation Accuracy: 0.711200\n",
      "Epoch 170, CIFAR-10 Batch 3:  Loss:     0.0039 Validation Accuracy: 0.708600\n",
      "Epoch 170, CIFAR-10 Batch 4:  Loss:     0.0045 Validation Accuracy: 0.710400\n",
      "Epoch 170, CIFAR-10 Batch 5:  Loss:     0.0019 Validation Accuracy: 0.710600\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss:     0.0024 Validation Accuracy: 0.710400\n",
      "Epoch 171, CIFAR-10 Batch 2:  Loss:     0.0113 Validation Accuracy: 0.707400\n",
      "Epoch 171, CIFAR-10 Batch 3:  Loss:     0.0021 Validation Accuracy: 0.716800\n",
      "Epoch 171, CIFAR-10 Batch 4:  Loss:     0.0022 Validation Accuracy: 0.717800\n",
      "Epoch 171, CIFAR-10 Batch 5:  Loss:     0.0020 Validation Accuracy: 0.712400\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss:     0.0033 Validation Accuracy: 0.709800\n",
      "Epoch 172, CIFAR-10 Batch 2:  Loss:     0.0069 Validation Accuracy: 0.717600\n",
      "Epoch 172, CIFAR-10 Batch 3:  Loss:     0.0021 Validation Accuracy: 0.714800\n",
      "Epoch 172, CIFAR-10 Batch 4:  Loss:     0.0047 Validation Accuracy: 0.714200\n",
      "Epoch 172, CIFAR-10 Batch 5:  Loss:     0.0013 Validation Accuracy: 0.716000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173, CIFAR-10 Batch 1:  Loss:     0.0024 Validation Accuracy: 0.720000\n",
      "Epoch 173, CIFAR-10 Batch 2:  Loss:     0.0042 Validation Accuracy: 0.718000\n",
      "Epoch 173, CIFAR-10 Batch 3:  Loss:     0.0033 Validation Accuracy: 0.719000\n",
      "Epoch 173, CIFAR-10 Batch 4:  Loss:     0.0025 Validation Accuracy: 0.715800\n",
      "Epoch 173, CIFAR-10 Batch 5:  Loss:     0.0028 Validation Accuracy: 0.721200\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss:     0.0027 Validation Accuracy: 0.716600\n",
      "Epoch 174, CIFAR-10 Batch 2:  Loss:     0.0050 Validation Accuracy: 0.714800\n",
      "Epoch 174, CIFAR-10 Batch 3:  Loss:     0.0018 Validation Accuracy: 0.712200\n",
      "Epoch 174, CIFAR-10 Batch 4:  Loss:     0.0055 Validation Accuracy: 0.718600\n",
      "Epoch 174, CIFAR-10 Batch 5:  Loss:     0.0018 Validation Accuracy: 0.712600\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss:     0.0016 Validation Accuracy: 0.717400\n",
      "Epoch 175, CIFAR-10 Batch 2:  Loss:     0.0050 Validation Accuracy: 0.718200\n",
      "Epoch 175, CIFAR-10 Batch 3:  Loss:     0.0022 Validation Accuracy: 0.711000\n",
      "Epoch 175, CIFAR-10 Batch 4:  Loss:     0.0020 Validation Accuracy: 0.715600\n",
      "Epoch 175, CIFAR-10 Batch 5:  Loss:     0.0060 Validation Accuracy: 0.713200\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss:     0.0047 Validation Accuracy: 0.703000\n",
      "Epoch 176, CIFAR-10 Batch 2:  Loss:     0.0036 Validation Accuracy: 0.718400\n",
      "Epoch 176, CIFAR-10 Batch 3:  Loss:     0.0043 Validation Accuracy: 0.710400\n",
      "Epoch 176, CIFAR-10 Batch 4:  Loss:     0.0105 Validation Accuracy: 0.712000\n",
      "Epoch 176, CIFAR-10 Batch 5:  Loss:     0.0021 Validation Accuracy: 0.720800\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss:     0.0031 Validation Accuracy: 0.718000\n",
      "Epoch 177, CIFAR-10 Batch 2:  Loss:     0.0048 Validation Accuracy: 0.717200\n",
      "Epoch 177, CIFAR-10 Batch 3:  Loss:     0.0034 Validation Accuracy: 0.713800\n",
      "Epoch 177, CIFAR-10 Batch 4:  Loss:     0.0033 Validation Accuracy: 0.713400\n",
      "Epoch 177, CIFAR-10 Batch 5:  Loss:     0.0028 Validation Accuracy: 0.712600\n",
      "Epoch 178, CIFAR-10 Batch 1:  Loss:     0.0044 Validation Accuracy: 0.716200\n",
      "Epoch 178, CIFAR-10 Batch 2:  Loss:     0.0028 Validation Accuracy: 0.713800\n",
      "Epoch 178, CIFAR-10 Batch 3:  Loss:     0.0022 Validation Accuracy: 0.717000\n",
      "Epoch 178, CIFAR-10 Batch 4:  Loss:     0.0034 Validation Accuracy: 0.715600\n",
      "Epoch 178, CIFAR-10 Batch 5:  Loss:     0.0036 Validation Accuracy: 0.721000\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss:     0.0028 Validation Accuracy: 0.714200\n",
      "Epoch 179, CIFAR-10 Batch 2:  Loss:     0.0018 Validation Accuracy: 0.715400\n",
      "Epoch 179, CIFAR-10 Batch 3:  Loss:     0.0041 Validation Accuracy: 0.707400\n",
      "Epoch 179, CIFAR-10 Batch 4:  Loss:     0.0040 Validation Accuracy: 0.713600\n",
      "Epoch 179, CIFAR-10 Batch 5:  Loss:     0.0011 Validation Accuracy: 0.709000\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss:     0.0023 Validation Accuracy: 0.711800\n",
      "Epoch 180, CIFAR-10 Batch 2:  Loss:     0.0019 Validation Accuracy: 0.713800\n",
      "Epoch 180, CIFAR-10 Batch 3:  Loss:     0.0057 Validation Accuracy: 0.715000\n",
      "Epoch 180, CIFAR-10 Batch 4:  Loss:     0.0078 Validation Accuracy: 0.713400\n",
      "Epoch 180, CIFAR-10 Batch 5:  Loss:     0.0072 Validation Accuracy: 0.716000\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss:     0.0022 Validation Accuracy: 0.714400\n",
      "Epoch 181, CIFAR-10 Batch 2:  Loss:     0.0042 Validation Accuracy: 0.704600\n",
      "Epoch 181, CIFAR-10 Batch 3:  Loss:     0.0123 Validation Accuracy: 0.722400\n",
      "Epoch 181, CIFAR-10 Batch 4:  Loss:     0.0025 Validation Accuracy: 0.717800\n",
      "Epoch 181, CIFAR-10 Batch 5:  Loss:     0.0020 Validation Accuracy: 0.712600\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss:     0.0023 Validation Accuracy: 0.707800\n",
      "Epoch 182, CIFAR-10 Batch 2:  Loss:     0.0026 Validation Accuracy: 0.711000\n",
      "Epoch 182, CIFAR-10 Batch 3:  Loss:     0.0036 Validation Accuracy: 0.705200\n",
      "Epoch 182, CIFAR-10 Batch 4:  Loss:     0.0017 Validation Accuracy: 0.712800\n",
      "Epoch 182, CIFAR-10 Batch 5:  Loss:     0.0019 Validation Accuracy: 0.719600\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss:     0.0023 Validation Accuracy: 0.716800\n",
      "Epoch 183, CIFAR-10 Batch 2:  Loss:     0.0031 Validation Accuracy: 0.713200\n",
      "Epoch 183, CIFAR-10 Batch 3:  Loss:     0.0017 Validation Accuracy: 0.710600\n",
      "Epoch 183, CIFAR-10 Batch 4:  Loss:     0.0029 Validation Accuracy: 0.716200\n",
      "Epoch 183, CIFAR-10 Batch 5:  Loss:     0.0014 Validation Accuracy: 0.714600\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss:     0.0027 Validation Accuracy: 0.710800\n",
      "Epoch 184, CIFAR-10 Batch 2:  Loss:     0.0049 Validation Accuracy: 0.713000\n",
      "Epoch 184, CIFAR-10 Batch 3:  Loss:     0.0018 Validation Accuracy: 0.716000\n",
      "Epoch 184, CIFAR-10 Batch 4:  Loss:     0.0024 Validation Accuracy: 0.719000\n",
      "Epoch 184, CIFAR-10 Batch 5:  Loss:     0.0010 Validation Accuracy: 0.715400\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss:     0.0027 Validation Accuracy: 0.709400\n",
      "Epoch 185, CIFAR-10 Batch 2:  Loss:     0.0126 Validation Accuracy: 0.710600\n",
      "Epoch 185, CIFAR-10 Batch 3:  Loss:     0.0009 Validation Accuracy: 0.717200\n",
      "Epoch 185, CIFAR-10 Batch 4:  Loss:     0.0032 Validation Accuracy: 0.720600\n",
      "Epoch 185, CIFAR-10 Batch 5:  Loss:     0.0037 Validation Accuracy: 0.720400\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss:     0.0037 Validation Accuracy: 0.709800\n",
      "Epoch 186, CIFAR-10 Batch 2:  Loss:     0.0041 Validation Accuracy: 0.710400\n",
      "Epoch 186, CIFAR-10 Batch 3:  Loss:     0.0025 Validation Accuracy: 0.713200\n",
      "Epoch 186, CIFAR-10 Batch 4:  Loss:     0.0032 Validation Accuracy: 0.718200\n",
      "Epoch 186, CIFAR-10 Batch 5:  Loss:     0.0023 Validation Accuracy: 0.723600\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss:     0.0045 Validation Accuracy: 0.709200\n",
      "Epoch 187, CIFAR-10 Batch 2:  Loss:     0.0022 Validation Accuracy: 0.718200\n",
      "Epoch 187, CIFAR-10 Batch 3:  Loss:     0.0025 Validation Accuracy: 0.717600\n",
      "Epoch 187, CIFAR-10 Batch 4:  Loss:     0.0026 Validation Accuracy: 0.714600\n",
      "Epoch 187, CIFAR-10 Batch 5:  Loss:     0.0055 Validation Accuracy: 0.725600\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss:     0.0030 Validation Accuracy: 0.706800\n",
      "Epoch 188, CIFAR-10 Batch 2:  Loss:     0.0039 Validation Accuracy: 0.711800\n",
      "Epoch 188, CIFAR-10 Batch 3:  Loss:     0.0038 Validation Accuracy: 0.722200\n",
      "Epoch 188, CIFAR-10 Batch 4:  Loss:     0.0030 Validation Accuracy: 0.720200\n",
      "Epoch 188, CIFAR-10 Batch 5:  Loss:     0.0017 Validation Accuracy: 0.721600\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss:     0.0050 Validation Accuracy: 0.703600\n",
      "Epoch 189, CIFAR-10 Batch 2:  Loss:     0.0039 Validation Accuracy: 0.712400\n",
      "Epoch 189, CIFAR-10 Batch 3:  Loss:     0.0019 Validation Accuracy: 0.718000\n",
      "Epoch 189, CIFAR-10 Batch 4:  Loss:     0.0039 Validation Accuracy: 0.711800\n",
      "Epoch 189, CIFAR-10 Batch 5:  Loss:     0.0022 Validation Accuracy: 0.718400\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss:     0.0023 Validation Accuracy: 0.709000\n",
      "Epoch 190, CIFAR-10 Batch 2:  Loss:     0.0051 Validation Accuracy: 0.712600\n",
      "Epoch 190, CIFAR-10 Batch 3:  Loss:     0.0031 Validation Accuracy: 0.717600\n",
      "Epoch 190, CIFAR-10 Batch 4:  Loss:     0.0030 Validation Accuracy: 0.716400\n",
      "Epoch 190, CIFAR-10 Batch 5:  Loss:     0.0026 Validation Accuracy: 0.717400\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss:     0.0034 Validation Accuracy: 0.710400\n",
      "Epoch 191, CIFAR-10 Batch 2:  Loss:     0.0051 Validation Accuracy: 0.715800\n",
      "Epoch 191, CIFAR-10 Batch 3:  Loss:     0.0018 Validation Accuracy: 0.716600\n",
      "Epoch 191, CIFAR-10 Batch 4:  Loss:     0.0060 Validation Accuracy: 0.715200\n",
      "Epoch 191, CIFAR-10 Batch 5:  Loss:     0.0063 Validation Accuracy: 0.716400\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss:     0.0035 Validation Accuracy: 0.710200\n",
      "Epoch 192, CIFAR-10 Batch 2:  Loss:     0.0071 Validation Accuracy: 0.719800\n",
      "Epoch 192, CIFAR-10 Batch 3:  Loss:     0.0035 Validation Accuracy: 0.716600\n",
      "Epoch 192, CIFAR-10 Batch 4:  Loss:     0.0057 Validation Accuracy: 0.711600\n",
      "Epoch 192, CIFAR-10 Batch 5:  Loss:     0.0024 Validation Accuracy: 0.718800\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss:     0.0038 Validation Accuracy: 0.711200\n",
      "Epoch 193, CIFAR-10 Batch 2:  Loss:     0.0062 Validation Accuracy: 0.718400\n",
      "Epoch 193, CIFAR-10 Batch 3:  Loss:     0.0020 Validation Accuracy: 0.717000\n",
      "Epoch 193, CIFAR-10 Batch 4:  Loss:     0.0036 Validation Accuracy: 0.716800\n",
      "Epoch 193, CIFAR-10 Batch 5:  Loss:     0.0032 Validation Accuracy: 0.725400\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss:     0.0025 Validation Accuracy: 0.720200\n",
      "Epoch 194, CIFAR-10 Batch 2:  Loss:     0.0064 Validation Accuracy: 0.707800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194, CIFAR-10 Batch 3:  Loss:     0.0019 Validation Accuracy: 0.719000\n",
      "Epoch 194, CIFAR-10 Batch 4:  Loss:     0.0058 Validation Accuracy: 0.710200\n",
      "Epoch 194, CIFAR-10 Batch 5:  Loss:     0.0031 Validation Accuracy: 0.718800\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss:     0.0015 Validation Accuracy: 0.717600\n",
      "Epoch 195, CIFAR-10 Batch 2:  Loss:     0.0040 Validation Accuracy: 0.712800\n",
      "Epoch 195, CIFAR-10 Batch 3:  Loss:     0.0011 Validation Accuracy: 0.715800\n",
      "Epoch 195, CIFAR-10 Batch 4:  Loss:     0.0061 Validation Accuracy: 0.719000\n",
      "Epoch 195, CIFAR-10 Batch 5:  Loss:     0.0038 Validation Accuracy: 0.717200\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss:     0.0020 Validation Accuracy: 0.718400\n",
      "Epoch 196, CIFAR-10 Batch 2:  Loss:     0.0031 Validation Accuracy: 0.712800\n",
      "Epoch 196, CIFAR-10 Batch 3:  Loss:     0.0044 Validation Accuracy: 0.714600\n",
      "Epoch 196, CIFAR-10 Batch 4:  Loss:     0.0048 Validation Accuracy: 0.712800\n",
      "Epoch 196, CIFAR-10 Batch 5:  Loss:     0.0021 Validation Accuracy: 0.722600\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss:     0.0026 Validation Accuracy: 0.716200\n",
      "Epoch 197, CIFAR-10 Batch 2:  Loss:     0.0044 Validation Accuracy: 0.717000\n",
      "Epoch 197, CIFAR-10 Batch 3:  Loss:     0.0015 Validation Accuracy: 0.718000\n",
      "Epoch 197, CIFAR-10 Batch 4:  Loss:     0.0019 Validation Accuracy: 0.711800\n",
      "Epoch 197, CIFAR-10 Batch 5:  Loss:     0.0014 Validation Accuracy: 0.724000\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss:     0.0022 Validation Accuracy: 0.721200\n",
      "Epoch 198, CIFAR-10 Batch 2:  Loss:     0.0080 Validation Accuracy: 0.701600\n",
      "Epoch 198, CIFAR-10 Batch 3:  Loss:     0.0060 Validation Accuracy: 0.715400\n",
      "Epoch 198, CIFAR-10 Batch 4:  Loss:     0.0061 Validation Accuracy: 0.718600\n",
      "Epoch 198, CIFAR-10 Batch 5:  Loss:     0.0026 Validation Accuracy: 0.717000\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss:     0.0022 Validation Accuracy: 0.725200\n",
      "Epoch 199, CIFAR-10 Batch 2:  Loss:     0.0046 Validation Accuracy: 0.704400\n",
      "Epoch 199, CIFAR-10 Batch 3:  Loss:     0.0024 Validation Accuracy: 0.716200\n",
      "Epoch 199, CIFAR-10 Batch 4:  Loss:     0.0028 Validation Accuracy: 0.713000\n",
      "Epoch 199, CIFAR-10 Batch 5:  Loss:     0.0017 Validation Accuracy: 0.718200\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss:     0.0015 Validation Accuracy: 0.716000\n",
      "Epoch 200, CIFAR-10 Batch 2:  Loss:     0.0019 Validation Accuracy: 0.716200\n",
      "Epoch 200, CIFAR-10 Batch 3:  Loss:     0.0012 Validation Accuracy: 0.720200\n",
      "Epoch 200, CIFAR-10 Batch 4:  Loss:     0.0013 Validation Accuracy: 0.722200\n",
      "Epoch 200, CIFAR-10 Batch 5:  Loss:     0.0010 Validation Accuracy: 0.721800\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "模型已保存到本地。\n",
    "\n",
    "## 测试模型\n",
    "\n",
    "利用测试数据集测试你的模型。这将是最终的准确率。你的准确率应该高于 50%。如果没达到，请继续调整模型结构和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.7052734375\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAWJQAAFiUBSVIk8AAAIABJREFUeJzs3Xd8ZFd5//HPoy6ttrus+xrbYINNM7YBg0sgNBM6pgRi\nww8COPQSSoAYCCWEH5heQohD7+UXWkxbbDq4xN3gIpe1vd6u1arPPL8/njNzr+6OpNFqpJG03/fr\nNTuae88990zZmTPPPOccc3dERERERARamt0AEREREZGFQp1jEREREZFEnWMRERERkUSdYxERERGR\nRJ1jEREREZFEnWMRERERkUSdYxERERGRRJ1jEREREZFEnWMRERERkUSdYxERERGRRJ1jEREREZFE\nnWMRERERkUSdYxERERGRRJ1jEREREZFEneMmM7MjzOxpZvYyM3uzmb3JzF5hZs80s4eYWW+z2zgZ\nM2sxsyeb2VfN7EYz6zczz12+2+w2iiw0Zra+8P/k/EaUXajM7IzCfTi32W0SEZlKW7MbsC8yszXA\ny4AXA0dMU7xsZtcClwA/AH7m7sNz3MRppfvwTeDMZrdF5p+ZXQicM02xcWAHsAW4jHgNf8Xdd85t\n60RERPaeIsfzzMyeCFwL/AvTd4whnqPjic7094FnzF3rZuTzzKBjrOjRPqkN2A84Fngu8Elgo5md\nb2b6Yr6IFP7vXtjs9oiIzCV9QM0jMzsb+Ap7finpB64C7gZGgNXA4cBxNco2nZk9FDgrt+lW4B3A\nn4Bdue2D89kuWRSWAf8MnGZmj3f3kWY3SEREJE+d43liZkcR0dZ8Z/dq4J+AH7r7eI1jeoHTgWcC\nTwVWzENT6/G0wu0nu/v/NqUlslC8gUizyWsDDgQeAZxHfOGrOJOIJL9wXlonIiJSJ3WO58+7gc7c\n7Z8CT3L3ockOcPcBIs/4B2b2CuBFRHS52U7M/d2njrEAW9y9r8b2G4Ffm9lHgS8SX/IqzjWzj7j7\nFfPRwMUoPabW7HbMhrtvYJHfBxHZtyy4n+yXIjPrBp6U2zQGnDNVx7jI3Xe5+4fc/acNb+DMHZD7\n+86mtUIWDXcfBP4W+HNuswEvbU6LREREalPneH48GOjO3f6Nuy/mTmV+ermxprVCFpX0ZfBDhc2P\nakZbREREJqO0ivmxrnB743ye3MxWAI8EDgHWEoPmNgG/d/fb9qbKBjavIczsXkS6x6FAB9AH/MLd\n75nmuEOJnNjDiPt1Vzrujlm05RDgfsC9gFVp8zbgNuC3+/hUZj8r3D7KzFrdvTSTSszseOC+wEHE\nIL8+d/9yHcd1AA8D1hO/gJSBe4ArG5EeZGbHACcDBwPDwB3AH9x9Xv/P12jXvYEHAvsTr8lB4rV+\nNXCtu5eb2LxpmdlhwEOJHPblxP+nO4FL3H1Hg891LyKgcRjQSrxX/trdb55FnfchHv91RHBhHBgA\nbgf+Alzv7j7LpotIo7i7LnN8AZ4NeO7yo3k670OAHwGjhfPnL1cS02zZFPWcMcXxk102pGP79vbY\nQhsuzJfJbT8d+AXRySnWMwp8AuitUd99gR9OclwZ+BZwSJ2Pc0tqxyeBm6a5byXgJ8CZddb9X4Xj\nPzOD5/+9hWP/e6rneYavrQsLdZ9b53HdNR6TA2qUy79uNuS2v4Do0BXr2DHNee8DfJn4YjjZc3MH\n8FqgYy8ej1OB309S7zgxduDEVHZ9Yf/5U9Rbd9kax64C3kV8KZvqNbkZ+Bxw0jTPcV2XOt4/6nqt\npGPPBq6Y4nxj6f/TQ2dQ54bc8X257acQX95qvSc48DvgYTM4TzvwOiLvfrrHbQfxnvPXjfj/qYsu\nuszu0vQG7AsX4K8Kb4S7gFVzeD4D3j/Fm3ytywZg9ST1FT/c6qovHdu3t8cW2jDhgzpte2Wd9/GP\n5DrIxGwbg3Uc1wccVsfj/cK9uI8O/F+gdZq6lwHXF457Vh1tekzhsbkDWNvA19iFhTadW+dxe9U5\nJgazfn2Kx7Jm55j4v/BOohNV7/NydT3Pe+4cb6nzdThK5F2vL2w/f4q66y5bOO6pwPYZvh6vmOY5\nrutSx/vHtK8VYmaen87w3BcALXXUvSF3TF/a9gqmDiLkn8Oz6zjH/sTCNzN9/L7bqP+juuiiy95f\nlFYxPy4lIoat6XYv8Hkze67HjBSN9u/A/ylsGyUiH3cSEaWHEAs0VJwOXGxmp7n79jloU0OlOaM/\nnG46EV26iegMPRA4Klf8IcBHgReY2ZnA18hSiq5Pl1FiXukTcscdQX2LnRRz94eAa4ifrfuJDuHh\nwP2JlI+K1xKdtjdNVrG770739fdAV9r8GTP7k7vfVOsYM1sHfIEs/aUEPNfdt05zP+bDIYXbDtTT\nrguIKQ0rx1xO1oG+F3Bk8QAzMyLy/vzCriGi41LJ+z+aeM1UHq/7Ab8xs5PcfcrZYczs1cRMNHkl\n4vm6nUgBeBCR/tFOdDiL/zcbKrXpg+yZ/nQ38UvRFqCHSEE6gYmz6DSdmS0Hfkk8J3nbgT+k64OI\nNIt8219FvKc9b4bnex7wkdymq4lo7wjxPnIi2WPZDlxoZpe7+18mqc+AbxPPe94mYj77LcSXqZWp\n/qNRiqPIwtLs3vm+ciFWtytGCe4kFkQ4gcb93H1O4RxlomOxqlCujfiQ3lko/5UadXYREazK5Y5c\n+d8V9lUu69Kxh6bbxdSS109yXPXYQhsuLBxfiYp9HziqRvmziU5Q/nF4WHrMHfgN8MAax51BdNby\n53rCNI95ZYq996Zz1IwGE19K3gjsLrTrlDqe15cW2vQnavz8T3TUixG3t83B67n4fJxb53F/Xzju\nxknK9eXK5FMhvgAcWqP8+hrb3lQ417b0OHbVKHsk8L1C+f9h6nSjE9gz2vjl4us3PSdnE7nNlXbk\njzl/inOsr7dsKv9YonOeP+aXwMNr3Reic/k3xE/6lxb27Uf2fzJf3zeZ/P9urefhjJm8VoD/LJTv\nB14CtBfKrSR+fSlG7V8yTf0bcmUHyN4nvgMcXaP8ccD/Fs7xtSnqP6tQ9i/EwNOaryXi16EnA18F\nvtHo/6u66KLLzC9Nb8C+ciGiIMOFN838ZSuRl/g24K+BZXtxjl4idy1f72umOeYUJnbWnGny3pgk\nH3SaY2b0AVnj+AtrPGZfYoqfUYklt2t1qH8KdE5x3BPr/SBM5ddNVV+N8g8rvBamrD93XDGt4MM1\nyvxToczPpnqMZvF6Lj4f0z6fxJes6wrH1cyhpnY6zntn0L77MTGV4nZqdNwKxxiRe5s/51lTlP9F\noezH6mhTsWPcsM4xEQ3eVGxTvc8/cOAU+/J1XjjD10rd//eJgcP5soPAqdPU//LCMQNMkiKWym+o\n8Rx8jKm/CB3IxDSV4cnOQYw9qJQbA46cwWO1xxc3XXTRZf4vmsptnngsdPB84k21ljXAE4j8yIuA\n7WZ2iZm9JM02UY9ziGhKxY/dvTh1VrFdvwfeXtj8qjrP10x3EhGiqUbZ/wcRGa+ojNJ/vk+xbLG7\nfx+4IbfpjKka4u53T1VfjfK/BT6e2/QUM6vnp+0XAfkR8680sydXbpjZI4hlvCs2A8+b5jGaF2bW\nRUR9jy3s+nSdVVwBvHUGp/xHsp+qHXim116kpMrdnVjJLz9TSc3/C2Z2Pya+Lv5MpMlMVf81qV1z\n5cVMnIP8F8Ar6n3+3X3TnLRqZl5ZuP0Od//1VAe4+8eIX5AqljGz1JWriSCCT3GOTUSnt6KTSOuo\nJb8S5BXufku9DXH3yT4fRGQeqXM8j9z9G8TPm7+qo3g7McXYp4Cbzey8lMs2lb8t3P7nOpv2EaIj\nVfEEM1tT57HN8hmfJl/b3UeB4gfrV939rjrq/3nu7wNSHm8jfS/3dwd75lfuwd37gWcRP+VX/KeZ\nHW5ma4GvkOW1O/B3dd7XRtjPzNYXLkeb2cPN7B+Ba4FnFI75krtfWmf9F3id072Z2SrgOblNP3D3\n39VzbOqcfCa36Uwz66lRtPh/7f3p9TadzzF3Uzm+uHB7yg7fQmNmy4Cn5DZtJ1LC6lH84jSTvOMP\nuXs987X/sHD7AXUcs/8M2iEiC4Q6x/PM3S9390cCpxGRzSnn4U3WEpHGr6Z5WveQIo/5ZZ1vdvc/\n1NmmMeAb+eqYPCqyUFxUZ7nioLWf1HncjYXbM/6Qs7DczA4udhzZc7BUMaJak7v/ichbrlhNdIov\nJPK7K/7N3X880zbPwr8BtxQufyG+nPwrew6Y+zV7duam8t8zKHsq8eWy4pszOBbgktzfbUTqUdHD\ncn9Xpv6bVorifmPagjNkZvsTaRsVf/TFt6z7SUwcmPaden+RSff12tymE9LAvnrU+//k+sLtyd4T\n8r86HWFm/1Bn/SKyQGiEbJO4+yWkD2Ezuy8RUT6R+IB4IFkEMO9sYqRzrTfb45k4E8LvZ9ik3xE/\nKVecyJ6RkoWk+EE1mf7C7Rtqlpr+uGlTW8ysFXg0MavCSUSHt+aXmRpW11kOd78gzbpRWZL84YUi\nvyNyjxeiIWKWkbfXGa0DuM3dt83gHKcWbm9NX0jqVfy/V+vYB+f+/ovPbCGKP86gbL2KHfhLapZa\n2E4s3N6b97D7pr9biPfR6R6Hfq9/tdLi4j2TvSd8FXhN7vbHzOwpxEDDH/kimA1IZF+nzvEC4O7X\nElGPzwKY2UpintJXs+dPd+eZ2X+4+2WF7cUoRs1phqZQ7DQu9J8D611lbrxBx7XXLJWY2cOI/NkT\npio3hXrzyiteQExndnhh+w7gOe5ebH8zlIjHeyvR1kuAL8+wowsTU37qcWjh9kyizrVMSDFK+dP5\n56vmlHpTKP4q0QjFtJ/r5uAcc60Z72F1r1bp7mOFzLaa7wnu/gcz+wQTgw2PTpeymV1F/HJyMXWs\n4iki809pFQuQu+909wuJeTLfUaNIcdAKZMsUVxQjn9MpfkjUHclshlkMMmv44DQzexwx+GlvO8Yw\nw/+LqYP5nhq7XjfdwLM58gJ3t8Klzd3Xuvu93f1Z7v6xvegYQ8w+MBONzpfvLdxu9P+1RlhbuN3Q\nJZXnSTPew+ZqsOrLiV9vBgvbW4iAx3lEhPkuM/uFmT2jjjElIjJP1DlewDycTyxakffoJjRHakgD\nF7/IxMUI+ohlex9PLFu8ipiiqdpxpMaiFTM871pi2r+i55nZvv7/esoo/15YjJ2WRTMQbylK793v\nIRaoeSPwW/b8NQriM/gMIg/9l2Z20Lw1UkQmpbSKxeGjxCwFFYeYWbe7D+W2FSNFM/2ZfmXhtvLi\n6nMeE6N2XwXOqWPmgnoHC+0ht/JbcbU5iNX83kpMCbivKkan7+vujUwzaPT/tUYo3udiFHYxWHLv\nYWkKuPcD7zezXuBkYi7nM4nc+Pxn8COBH5vZyTOZGlJEGm9fjzAtFrVGnRd/MizmZR49w3Pce5r6\npLazcn/vBF5U55Res5ka7jWF8/6BibOevN3MHjmL+he7Yg7nfjVL7aU03Vv+J/+jJis7iZn+36xH\ncZnr4+bgHHNtSb+HufuAu//c3d/h7mcQS2C/lRikWnF/4IXNaJ+IZNQ5Xhxq5cUV8/GuZuL8tyfP\n8BzFqdvqnX+2Xkv1Z978B/iv3H13ncft1VR5ZnYS8L7cpu3E7Bh/R/YYtwJfTqkX+6LinMa1pmKb\nrfyA2GPS3Mr1OqnRjWHP+7wYvxwV33Nm+rzl/0+ViYVjFix33+Lu72bPKQ3/phntEZGMOseLw30K\ntweKC2Ckn+HyHy5Hm1lxaqSazKyN6GBVq2Pm0yhNp/gzYb1TnC10+Z9y6xpAlNIinjvTE6WVEr/K\nxJzaF7r7be7+P8RcwxWHElNH7Yt+zsQvY2fPwTl+m/u7BXh6PQelfPBnTltwhtx9M/EFueJkM5vN\nANGi/P/fufq/+0cm5uU+dbJ53YvM7P5MnOf5anff1cjGzaGvMfHxXd+kdohIos7xPDCzA83swFlU\nUfyZbcMk5b5cuF1cFnoyL2fisrM/cvetdR5br+JI8kavONcs+TzJ4s+6k3k+dS76UfDvxACfio+6\n+3dzt/+JiV9q/sbMFsNS4A2V8jzzj8tJZtboDumXCrf/sc6O3AupnSveCJ8p3P5gA2dAyP//nZP/\nu+lXl/zKkWuoPad7LcUc+y82pFHzIE27mP/FqZ60LBGZQ+ocz4/jiCWg32dmB0xbOsfMng68rLC5\nOHtFxX8x8UPsSWZ23iRlK/WfRMyskPeRmbSxTjczMSp05hycoxmuyv19opmdPlVhMzuZGGA5I2b2\n90yMgF4OvCFfJn3IPpuJr4H3m1l+wYp9xTuZmI70uememyIzO8jMnlBrn7tfA/wyt+newAenqe++\nxOCsufIfwKbc7UcDH6q3gzzNF/j8HMInpcFlc6H43vOu9B41KTN7GfDk3KbdxGPRFGb2MjOrO8/d\nzB7PxOkH612oSETmiDrH86eHmNLnDjP7jpk9PS35WpOZHWdmnwG+zsQVuy5jzwgxAOlnxNcWNn/U\nzP4tLSySr7/NzF5ALKec/6D7evqJvqFS2kc+qnmGmX3WzB5lZscUlldeTFHl4tLE3zKzJxULmVm3\nmb0G+BkxCn9LvScws+OBC3KbBoBn1RrRnuY4flFuUwex7PhcdWYWJHe/ghjsVNEL/MzMPmJmkw6g\nM7NVZna2mX2NmJLv76Y4zSuA/Cp//2BmXyq+fs2sJUWuNxADaedkDmJ3HyTam/9S8Crifj+s1jFm\n1mlmTzSzbzH1ipgX5/7uBX5gZk9N71PFpdFncx8uBr6Q27QM+ImZ/Z+U/pVv+wozez/wsUI1b9jL\n+bQb5Y3ArWb2+fTYLqtVKL0H/x2x/Hveool6iyxVmspt/rUDT0kXzOxG4Dais1QmPjzvCxxW49g7\ngGdOtQCGu3/OzE4DzkmbWoDXA68ws98CdxHTPJ3EnqP4r2XPKHUjfZSJS/v+n3Qp+iUx9+di8Dli\n9ohj0u21wPfM7Fbii8ww8TP0KcQXJIjR6S8j5jadkpn1EL8UdOc2v9TdJ109zN2/aWafAl6aNh0D\nfAp4Xp33aUlw9/emztrfp02tRIf2FWZ2C7EE+Xbi/+Qq4nFaP4P6rzKzNzIxYvxc4Flm9jvgdqIj\neSIxMwHEryevYY7ywd39IjN7PfB/yeZnPhP4jZndBVxJrFjYTeSl359sju5as+JUfBZ4HdCVbp+W\nLrXMNpXj5cRCGfdPt1em8/+rmf2B+HKxDnhYrj0VX3X3T87y/I3QQ6RPPZ9YFe8G4stW5YvRQcQi\nT8Xp577r7rNd0VFEZkmd4/mxjej81vqp7Wjqm7Lop8CL61z97AXpnK8m+6DqZOoO56+AJ89lxMXd\nv2ZmpxCdgyXB3UdSpPjnZB0ggCPSpWiAGJB1fZ2n+CjxZaniP929mO9ay2uILyKVQVl/a2Y/c/d9\napCeu7/EzK4kBivmv2AcSX0LsUw5V667fyh9gXkX2f+1ViZ+CawYJ74MXlxjX8OkNm0kOpT5+bQP\nYuJrdCZ19pnZuUSnvnua4rPi7v0pBebbTEy/WkssrDOZj1N79dBmayFS66abXu9rZEENEWkipVXM\nA3e/koh0/BURZfoTUKrj0GHiA+KJ7v7X9S4LnFZnei0xtdFF1F6ZqeIa4qfY0+bjp8jUrlOID7I/\nElGsRT0Axd2vBx5M/Bw62WM9AHweuL+7/7iees3sOUwcjHk9Efmsp03DxMIx+eVrP2pmezMQcFFz\n948THeEPABvrOOTPxE/1D3f3aX9JSdNxnUbMN11Lmfh/eKq7f76uRs+Su3+dGLz5ASbmIdeyiRjM\nN2XHzN2/RnTw3kGkiNzFxDl6G8bddwCPIiLxV05RtESkKp3q7i+fxbLyjfRk4J+BX7PnLD1FZaL9\nZ7n7s7X4h8jCYO5LdfrZhS1Fm+6dLgeQRXj6iajvNcC1aZDVbM+1kvjwPoQY+DFAfCD+vt4Ot9Qn\nzS18GhE17iYe543AJSknVJosfUF4APFLziqiA7MDuIn4PzddZ3Kquo8hvpQeRHy53Qj8wd1vn227\nZ9EmI+7v/YD9iVSPgdS2a4DrfIF/EJjZ4cTjeiDxXrkNuJP4f9X0lfAmk2YwuR+RsnMQ8diPE4Nm\nbwQua3J+tIjUoM6xiIiIiEiitAoRERERkUSdYxERERGRRJ1jEREREZFEnWMRERERkUSdYxERERGR\nRJ1jEREREZFEnWMRERERkUSdYxERERGRRJ1jEREREZFEnWMRERERkUSdYxERERGRRJ1jEREREZFE\nnWMRERERkUSdYxERERGRRJ1jEREREZFEnWMRERERkUSdYxERERGRRJ1jEREREZFEnWMRERERkUSd\nYxERERGRRJ1jEREREZFEnWMRERERkUSdYxERERGRRJ3jKZjZcjP7oJndZGajZuZm1tfsdomIiIjI\n3GhrdgMWuG8Dj05/9wPbgM3Na46IiIiIzCVz92a3YUEys/sBVwNjwGnu/rsmN0lERERE5pjSKiZ3\nv3R9pTrGIiIiIvsGdY4n152uB5raChERERGZN+ocF5jZ+WbmwIVp0+lpIF7lckaljJldaGYtZvZy\nM/uDme1I2x9YqPNBZvZFM7vdzEbMbIuZ/Y+ZPX2atrSa2avN7EozGzKzzWb2fTM7Ne2vtGn9HDwU\nIiIiIvscDcjb0wCwiYgcryByjrfl9o/m/jZi0N6TgRKwq1iZmf098EmyLyI7gFXAY4DHmNkXgXPd\nvVQ4rh34HvD4tGmceL7OAh5rZs/e+7soIiIiIrUoclzg7h9w93XAq9Km37j7utzlN7niTwMeB5wH\nrHD31cCBwM0AZvZwso7xN4HDUplVwFsBB54HvLlGU95KdIxLwKtz9a8Hfgx8tnH3WkRERERAnePZ\n6gVe6e6fdPdBAHe/x9370/53EY/xr4Fnu/sdqcyAu78beF8q90YzW1Gp1MyWA69LN9/u7h9296F0\n7K1Ep/zWOb5vIiIiIvscdY5nZyvwuVo7zGwNcGa6+d5i2kTyr8Aw0cl+Qm77Y4Blad9Hige5+xjw\nwb1vtoiIiIjUos7x7PzJ3ccn2fcgIifZgV/WKuDuO4FL080HF44FuMLdJ5st45IZtlVEREREpqHO\n8exMtVre/ul65xQdXIA7CuUB9kvXd01x3J3TtE1EREREZkid49mplSpR1DnnrRARERGRhlDneO5U\nosrdZrb/FOUOLZQH2JKuD5riuKn2iYiIiMheUOd47lxO5BtDNjBvAjNbCZyYbl5WOBbggWbWO0n9\nj5x1C0VERERkAnWO54i7bwN+kW6+0cxqPdZvBLqIhUd+mNt+EbA77fuH4kFm1ga8pqENFhERERF1\njufY24AyMRPFV83sUAAz6zWztwBvSuXel5sbGXffBXwo3fwXM3uFmXWnYw8nFhQ5cp7ug4iIiMg+\nQ53jOZRW0zuP6CA/E7jNzLYRS0i/m5jq7Utki4HkvYuIILcRcx33m9l2YvGPs4AX5cqOzNV9EBER\nEdmXqHM8x9z908BJwJeJqdl6gZ3AT4Bnuvvzai0Q4u6jRCf4dcDVxMwYJeAHwBnAz3LFd8zhXRAR\nERHZZ5i7T19KFhwzexTwU+BWd1/f5OaIiIiILAmKHC9eb0jXP2lqK0RERESWEHWOFygzazWzb5rZ\n49KUb5Xt9zOzbwKPBcaIfGQRERERaQClVSxQabq2sdymfmJwXk+6XQZe5u6fme+2iYiIiCxV6hwv\nUGZmwEuJCPEJwAFAO3A3cDFwgbtfNnkNIiIiIjJT6hyLiIiIiCTKORYRERERSdQ5FhERERFJ1DkW\nEREREUnUORYRERERSdqa3QARkaXIzG4BVgB9TW6KiMhitB7od/cj5/vES7ZzfMRBnQ7Q6q3VbaWx\nUQA62koAlFuzwPngePq7Ja7LZtV94+WY0aOUrlvI9rVUy8W1tWT7urq6AOjs6Yg6W0rVfSOjwwCM\njY1Ut5U99i/ragdgRXdX1oZSOdqZrls6e6r7Opf3AtDaHuceH8nq7O0YB2D1spgyubQrm51k++b4\n+4qrt2eNFpFGWdHd3b3muOOOW9PshoiILDbXXXcdQ0NDTTn3ku0cL+uIjmYpN1Odt0YfcKTSoc11\ngK0cf1c7xZZ1qi11oit96TbLOrmtLRPrKpWyffh4Kh+d3Vy/uXrq9raW3LbY2JFO1JbbR0vckTbi\nurWtXN3VnjrdY6NxvsH+wazO6JfTk6qy8ewp72hvR2ShMbNXEnN8Hwl0Aa9x9wua26q90nfcccet\nufTSS5vdDhGRRefEE0/ksssu62vGuZds51hEFh8zezbwYeBy4AJgBPhdUxslIiL7FHWORWQheWLl\n2t3vbGpLGuDqjTtZ/6YfNLsZIrIA9L3vrGY3Qeq0ZDvH9zogrgdGs/SD0ZQXXG6LXIPhsSzPoX8g\nrodHUopCLh+j5JGT0NISqRZmWZ2tKUe5kibhE9Iq4qrNIne4I5cmUcmFLpVydbVFJW3tlfNlbTCP\ncp0dUaazO6uroyPKDeyOnOry6Fh133g5zjMyGMe1jmd1elmpxrLgHAywFDrGIiKyOGkqNxFpOjM7\n38wcODPd9sold3uDma0zs8+a2UYzK5nZubk6DjKzj5tZn5mNmtlmM/u2mZ04yTlXmtkFZnaHmQ2b\n2fVm9lozu1c634XzcNdFRGSBWbKR42OOjMFmO/qzSO7u4YiallsiCrtzODcjxViK4KYZI2w0q6ul\nVCnXmv7dM6JrFt8z2ltzx1kaPNdSifp25PalWTFys2l0dsbT0doe16Vc5NjHShPO3ZuLHHd1p4h2\nObaNdmR1tqTI8XgarOflLFI9no9yizTXhnR9LnAE8I4aZdYQ+ccDwLeBMrAJwMyOBH5FRJ5/DnwF\nOAx4JnCWmT3d3b9fqcjMulK5BxP5zV8CVgL/BDyyofdMREQWlSXbORaRxcPdNwAbzOwM4Ah3P79G\nsROALwAvdE9TwWQ+RXSM3+ru765sNLNPABcD/2VmR7h7SqDiDUTH+KvAc929EqF+N3DZTNpuZpNN\nR3HsTOoREZGFYcl2jrvWpbl/S/3Vbd0pKtyR8oSX9WRTmbW0x76hkdg3sDuLsA4OVvKQ4/O47FnE\nOQWOaa3BmyXBAAAgAElEQVTM6Nae7SuNR/nx8ZjT2FtyYeW2NGdybjq5ynzIrSn8PDKe5Q7beDmd\nL7aZZ3MZd7TG09jbndqbBagZH64cF/fBLYs4l02RY1lURoHXFzvGZnYo8BjgNuD9+X3u/hsz+wrw\nPOBpwOfTrnOIyPObKx3jVP52M7sA+Jc5uxciIrKgLdnOsYgsOX3ufk+N7Q9K15e4+1iN/T8nOscP\nAj5vZiuAo4Db3b2vRvlfzaRR7j5ZTvOlRHRaREQWEQ3IE5HF4u5Jtq9M13dNsr+yfVW6XpGuN01S\nfrLtIiKyD1iykeNV9z0egI07r6luGxzYAUBrmtItP7BuRU/8vWp5pFqMrcpSLrbviLSI7TsjlSE/\nBVxlJrb2lArR0pJ93xhrqay6F3WP5n4NttbKctO5NIdWT3XFvpb8wL/q9HEpPWI8GzHopfQ0lmOb\nlbOUC0tPcWs6X27FbMbGs9QRkUXAJ9m+M12vm2T/QYVylVyrAycpP9l2ERHZByzZzrGI7DMuT9eP\nMLO2GoP1zkzXlwG4e7+Z3QysN7P1NVIrHtGohh1/yEou1cT/IiKLypLtHN96T0RFt1R/SYWtwxEB\nXjYcaYkd5WxAWktaSKOzO66tNYuqdqZFOTrSo1Wy3FRpKSrc1tVSqai6z0ZjW1tnWgSku7u6rzK9\nG+Wh6ra2NECu1aKd7a3ZvlaizaXRiACP5qZkGybKDZdSGXID7VKbvbWjcuLcPg3Ik8XP3e8ws58A\nfw28GvhAZZ+ZnQI8F9gOfCd32OeB84H3mll+torDUh0iIrKPWrKdYxHZp7wU+DXwb2b2GOBPZPMc\nl4EXuPuuXPn3A08Bng3cx8wuInKXzyamfntKOk5ERPYxGpAnIoueu98MPISY7/g+wOuBxwM/Bk51\n9+8Vyg8R6RYfJXKVX5Nuvwd4byrWj4iI7HOWbOT4hqvuAOCendngtP6dEQjqSKvmtY9maQXLV8QA\nvN5yZcLi7LjRtHpedY7g3Mp1VklTSFcly4JNbWke5e6eHgBWrVqTNbAU9Y8NZumR7SmtwsYircLK\nuUF3o3HO0lCkdIzlpkwe8ig3nAJd7tl3npb0DI+X4zxjpWymq5ExBcZkYXH3MybZbrW2F8psBF42\ng3PtAF6ZLlVm9uL053X11iUiIkuHIscisk8ys4NrbDsceBswDvz3vDdKRESabslGjrvGYhDclltz\nU5+Op+BTGig3NJhFUQdGI5LbMxRR2OUrskCVWXqY0mC7tpYs4tzWuQyAo44+DoBdQ9kvsZu29kWd\naSBeb09WZysR+t0+nIsOV1bES0Gy8ZFscF95uFIm7csNyPM0w9VwWuhrPDfjVXt7/F22dB7L9nl5\nspmxRPYJ3zKzduBSYAewHngi0EOsnHdnE9smIiJNsmQ7xyIi0/gC8Hzg6cRgvAHg98DH3P3bzWyY\niIg0z5LtHO/eEqFWH8i2VXJxx1Kabyl399MaGQyNRVS4ZSgXfU3F2tqiUHtndtyJDz4JgDNOeywA\nt9x2Q3Xf7/6UFh3p6ASgtzv3cKec492tWc7x2EhsGx2OqPDQrizSPD6SMmDKcW2WZcSMj5fSdRw3\n7rmocin2LeuNc69clU0nNzxcnA5WZN/h7p8APtHsdoiIyMKinGMRERERkUSdYxERERGRZMmmVdx1\n1zagmr0AgBNpCi1pYJ1blrbgaQq2yuC2Uinb113Jq0hZCKv2X1vdd/JDIq1ieHfkbwzu2Fnd96Dj\nHhDl91sHwOhY9l3kzjuuBaBtPFvBb9f2OHf/WKx4NzCWDRgsVcbttUZbzLLBel5urfwR9y836M7S\noLu2NKdbZ3t7dV/r0n36RURERPaKIsciIiIiIsmSDR2OpAiw5wautXhEWLPBbLkBb2lBjNYUfW3L\nDbo7fN2BcX3YEQAccPiR1X1HHHY4AEMDMYXb+GA2dery3uXxR1svAMPjWRh7WVtEhe/pzKaF29XV\nnq4HAehqzVa73bJtNwC7R+K4sdw0bOU00LC9Ld2/lvw0b/F3eTTC3kO7sjbkFwsREREREUWORURE\nRESqlmzkuJQiv55bsKOcosPj5dhWKuWWbk7TtLWkhTQOWJ3lAp/5iIcBsP7wowHYMpRFnO/ZdA8A\nKyI4TEdb9pD++apYgOTyq24BoHNF1r4nPenBUd6yueau2Rx1taVlpPdbm+UH9/TGYiNbdkby8Y6B\nLDo8nNaStsp8dGT3Oc3kRjlN8za8Oz9927Qr8oqIiIjsUxQ5FhERERFJ1DkWEREREUmWbFrFQH+s\nkNc2lqUmkMaieUo7aMmlFaSsCro6ovwjHnpydd/hB8Ugu613bwLgpk1ZKkRLT6Q09K6OqdVa6azu\nu3tnTCfXPxQD7MZHspSGP115IwCHHpQ9BZ1dXQBsuTPSK3YPZekRHWl1vbWro/6Vy1ur+4aH4zvO\ntoE0BVxu5TsvTZyarlzKDdbLxvSJiIiICIoci8gCYmbrzczN7MI6y5+byp/bwDackeo8v1F1iojI\n4rFkI8flkYi6drf0ZNsspkErWURWW3P3vtUqi2XE9wUji7DedtttAOxO06Adfugx1X2rD42osvVE\nxHnb9m3VfUPXR3S4pSvONzKURXSvvuFWALZszyLA91q3HwD7Hxzn3t2X1bVrd0Sf29oGU3uztnen\nqeK62iJ6vWM0m66tEjGuTF9n2d2ipMixiIiIyARLtnMsIvuE7wC/A+5qdkNquXrjTta/6QfNbsaC\n0/e+s5rdBBGRSalzLCKLlrvvBHZOW1BERKROS7ZzPF6OFAbrHq1ua2mNdINSOQ3W68hSGspjKa0i\nDXzru6Ovus8OOQyA7o5Y8e72vpuq+zZuvhOA3rWr4xxtWRp3d0fUNbI7Vrq76457qvu6lkU6Rv9g\nNmDw+r7NAJxw7LEAdKzK2n5rOuc9m24HYGxkOLuvI9E36N8d92F4PMudaGmJtIrW7K5WaUCeLGRm\ndizwPuA0oBO4HHinu1+UK3Mu8J/AC9z9wtz2vvTn/YHzgacBhwDvdvfzU5kDgfcATwRWADcAHwJu\nnbM7JSIiC96S7RyLyKJ2JPBb4Crg08BBwLOAH5nZc939a3XU0QH8HFgDXAT0A7cAmNl+wG+AewG/\nSpeDgE+lsnUzs0sn2XXsTOoREZGFYcl2jkfGYkDeNnZVt3V1RFS3vTvCqG1dWfmVPTGobd3+EQH2\nXAT4xjQgb+WyWOJu/7UHVfeN7Y5p3W7bElHhweEsort7ICK/9733vQE44fgHZO1ri8j2wGj2i3Bn\nR0R5Tzjl0QBs3Hhndd/ONMBw45YoP5x76sotESkeGtsNQCk30q4zRcc9BZMnBItNK+TJgnUa8AF3\nf0Nlg5l9jOgwf8rMfuTu/dPUcRBwLXC6u+8u7HsP0TG+wN1fU+McIiKyj9JUbiKyEO0E3pnf4O5/\nAr4ErAKeWmc9ryt2jM2sHfhbYBeRclHrHHVz9xNrXYDrZ1KPiIgsDEs2ctzRE2Fha8tipb1rY1q3\nFb2R59vTlSXirljWDYB7RFNvvDUb/L68OxbeGBmLnOWRkbHqvgMPiNzh3o44nvHs+4Z3xXk2bYqo\nslXKAEfd/zgA1vYcWt1mKa7bsWx/ALb2/6W677Kr4nN2oD8izqNDWV5xZ3ucp70jLUAykuUqV/KK\ny+Uo32K570MKHMvCdZm776qxfQNwDvAg4L+mqWMYuLLG9mOBHuCSNKBvsnOIiMg+SJFjEVmINk2y\n/e50vbKOOu5xrznstHLsdOcQEZF9kDrHIrIQHTjJ9nXpup7p2yabj6Vy7HTnEBGRfdCSTavoSbGh\nlQcsq25rb480itGUddBayr4bDI1HjsG2e7YDMLgjS1Ns74zjxnfH+J9du7K0hS2b45ffro44j7Vn\nqRNr1qXV89JAu7/03VbdN3ZT/H3iQ0+qbtu+bSsAf/jTVQDcfU8WwBpP6R7DI2m6tqHsc79cisF6\naVweLS1Zusj4eCn9lVbKa8vlUrjyKmTBerCZLa+RWnFGur58FnVfDwwCDzSzlTVSK87Y85C9c/wh\nK7lUC16IiCwqihyLyEK0Enh7foOZPYQYSLeTWBlvr7j7GDHobjmFAXm5c4iIyD5qyUaOH/mYowDo\n3X9FdVt5vAOA32+4GoCdWwar+1bF+h7s3BlR4e72juq+8fTr7MhoTNNWzg2GW5YW2Vh1cEzvtnz1\nAdV9A6NxnHVGVPkBJ51a3Wc9MYjuz3/pq27zsdF0Hee5c+Md1X2VgXReShFgz77XWPqO09oST2c5\nN5XbnrO1ZRu8rFVAZMG6GHiRmZ0C/JpsnuMW4CV1TOM2nbcAjwJenTrElXmOnwX8EHjSLOsXEZFF\nSpFjEVmIbgEeDmwHXgqcDVwGPKHOBUCm5O5bgFOJ1fWOBV4NPBB4GbFKnoiI7KOWbOT4pJPvC8D+\nBx1R3bZlU0SK//iLawAYGcxyh7cPp9TGtPRyPh23Mt69spDG9i1Z0GrX+BAAHa2xiEj7ijXVfS1p\narXdQ5G/3LlseXXf6p4ot2VLNmB+17aYPm7zxsh73rwj2zeU8pxLozGNnHkWva7kUnelNaIHS9lU\nczGla9b41pbx6r5WU+RYFhZ372PiJINPnqb8hcCFNbavr+NcdwMvnGS3EvJFRPZRihyLiIiIiCTq\nHIuIiIiIJEs2reKPv7kRgOOO6a1ua2+JgXHLWyO9oT83pqdlPKUblOJ6fCRLW9i1I65Hdkdqw9hA\nqbpvNKVh3HDzzQDctnVLdV/vmpRiYZHusGbr1uq+4zoj5cJGR6rbfCT2r+yJ+u+4LRswOLw7UiVa\nUyZEe0f2q29Xd9S/34qYRq6/LZvKbevOSv1x4NpV2UDDVcs6EREREZGMIsciIiIiIsmSjRzfctNG\nAPo3Z4POOtsiity/Mw2Q68zuflv6njA6HOVLY7nIcX9EjEd2p8U2SllktjJYrzQa5ceHskF+4/0x\nyM9TUHp4VzYYrqOzB4Cu7qx9IwMRoj7hmCMBGNiaRbav33o7AAccHAuLrFidTVG3ayiOW7s2Vj5Z\nsyrbN35LDPIbHowI8n77ZYMCl3VozJGIiIhIniLHIiIiIiKJOsciIiIiIsmSTavYtSvmH96xua+6\nzcfju8DYSKxA12pZmoO3RYpBS3tcl8vZQ1MupZSLsUirKGeZE4yV0vzBKUWjPJ6bO3gk6h9LA/m2\nDu6o7hocjtSOE05YX922rCPSNUoDkU6xfv8sBeLWP0e9K3ojHePoY46p7rvjrpsrJwRg9apsEOKa\nFTHPcX857ld3R9a+8VI24E9EREREFDkWEREREalaspHjkeE9B8+NpWnTvBSR3Ja2bNCdt6TIb5ry\nrKUtm+ZsNEWKR9LxZdqz41Kkua0zpkgbJ6tzxbKYOq69JcqPj2Yh51I5otdb7rmzuu0+R0SkeHBn\nrJDX0ZqdZ8WKaM/wWKoj97XmsEMPAmDjLbHyH8uyp3X/ldGuZS1xfHtr1r7hUhY5FxERERFFjkVE\nREREqpZs5LirI6K2rWSLXpinHNu2NF1bLnl4JOUHV/KLcwFWRtMCIZU4a2t3FlXu6okc4PYU5D3g\nwDXVfStXRRu2bboHgLFS1pbuVXHA8Pju6rbhkS4AOlLucf/ArqztXXHsYFp0ZPO2bdV9B+0X+3p7\n0iIg27Pc5hXdsa91LEXGc4uOmOXupIiIiIgociwiIiIiUqHOsYiIiIhIsmTTKgbTinAdrVn/v5Sm\nXetOg+dGRrK0grFympKtpfKQZMdZGtPX3hX72tN0agA9y2PatP32i1XpurqyVefu2X43AGWLtrSv\nyAYH9qyOtIrW8SzNYfdwpHnYWNSxfSgbMLd1MAYY0hXtvOuezdV95cExAA5cHWkcO3YPV/dVppPb\nf2UM9ts5uLO6q+RKqxCpMLMNwOnurqUjRUT2YUu2cywi0mxXb9zJ+jf9oHq7731nNbE1IiJSjyXb\nOS55DLrrHxiobvNSRFjbO2JAXUdPNrCu3B7lO9ojwtpGts9aY/DbilURTe5YvjI7zuK4oaEYBLd9\ne7awxshwRGlXro6Hee2B3dV9LWnKt7FdWXR4R38Mzts5Gu0cbc+enqHROM/4eKq/nEWHR3fEgiel\nkWjXiu7sPGNp+rjBtBDJWC5aXlJ8TERERGQC5RyLyKJjZieb2dfMbKOZjZjZXWZ2kZmdnStzrpl9\ny8xuNrMhM+s3s1+b2fMKda03MwdOT7c9d9kwv/dMRESabclGjlfuF1HUUm6p566Ua9zTHd8JWjqy\n0OnyNQcCsGzZYQAM7Mgis5vS4ho2EhHkMtlUaaVKznBabKQ1t65GT0dEaZd1R2S3oz3bObwr2jCe\nSw9u74mp3IZSbvSusSzKm1KisVKcb3gga/vOtHT1eDmi5L2dQ9V9+y2LSHhHSqNsLedyqU3fjWTx\nMbMXA58ESsD/A/4CHAA8BDgP+Hoq+kngGuBi4C5gLfAE4Atmdh93f1sqtwN4B3AucET6u6JvDu+K\niIgsQEu2cywiS4+Z3Rf4BNAPPNLdrynsPzR383h3v6mwvwP4EfAmM/uUu2909x3A+WZ2BnCEu58/\nwzZdOsmuY2dSj4iILAwKHYrIYvIy4kv9u4odYwB3vyP390019o8CH091PGoO2ykiIovUko0cL18R\naRXjY6XqtlWrYrq1yspw7R291X33OfYUAA4++N4A7NiapU7c0hPpGLdc/3sA+nfdU923rDdSIVo8\n0ipGh7I8jq60kt6KVZHSUC5nbRkZjNQHG8+t4Ncag+7au2Oat7GdWXkvTZx2bTx3c3fKuRhJG3f0\nZ8dt3xbtWZ3uwwErc4MC8zkgIovDQ9P1j6YraGaHA28kOsGHA92FIoc0okHufuIk578UeHAjziEi\nIvNnyXaORWRJWpWuN05VyMzuBfwBWA1cAlwE7CTylNcD50BuShoREZFkyXaOh1MEt6MrW3jD2uLv\nVavWAbDfmvXVfb1dsW04RXRbW7LFOQ48aDUAW+6JwW1Dvqm6r7MnHsKu9vicbV2dhXTbUmS2tS2i\ny5Tbq/tWLYtIbmt31r6yRfkUhGa8nEV2x8fTvjRFXbpKdyxuWCmyZNrasmj0aLobO3emaeL6s8h2\nzzLN5SaLTuUnnUOA66co91piAN4L3P3C/A4zew7RORYREdnDku0ci8iS9DtiVorHM3Xn+Oh0/a0a\n+06f5JgSgJm1untpkjIzcvwhK7lUC3+IiCwqGpAnIovJJ4Fx4G1p5ooJcrNV9KXrMwr7Hwu8aJK6\nt6brw2fdShERWbSWbOR490CsJNfelY3B6eldBsD+644EYPWKg6v7tm+/E4Du7ph4uLc3Cxxt2n4V\nAOWumEe4fXmWHjGelpnrWR6pE+2t2Qp5o4NR15Z74rqFZdV9h+93AABtubmG79x0FwADo5FCMZJW\nygMwi/OUSqV0neVVtLZFHdYWT6d15MYdtca2kTQf8107svZ17G5IcExk3rj7tWZ2HvAp4HIz+x4x\nz/Fa4CRiirczieneXgB8w8y+CdwJHA88jpgH+Vk1qv8Z8Ezg22b2Q2AIuNXdvzC390pERBaSJds5\nFpGlyd3/3cyuBl5PRIafAmwBrgQ+m8pcaWZnAv8CnEW81/0v8DQib7lW5/izxCIgzwb+MR3zS2Bv\nO8frr7vuOk48seZkFiIiMoXrrrsOYgD1vDOfMLJLREQawcxGgFaiUy6yEFUWqpkqf1+kWR4AlNx9\n3mcWUuRYRGRuXA2Tz4Ms0myV1R31GpWFaIrVR+ecBuSJiIiIiCTqHIuIiIiIJOoci4iIiIgk6hyL\niIiIiCTqHIuIiIiIJJrKTUREREQkUeRYRERERCRR51hEREREJFHnWEREREQkUedYRERERCRR51hE\nREREJFHnWEREREQkUedYRERERCRR51hEREREJFHnWESkDmZ2qJl9zszuNLMRM+szswvMbHUz6hEp\nasRrKx3jk1zunsv2y9JmZs8ws4+a2SVm1p9eU1/cy7rm9H1UK+SJiEzDzI4CfgMcAHwPuB44GTgT\nuAE41d23zlc9IkUNfI32AauAC2rsHnD3DzSqzbJvMbMrgAcAA8AdwLHAl9z9eTOsZ87fR9tmc7CI\nyD7iE8Qb8Svd/aOVjWb2QeA1wLuBl85jPSJFjXxt7XD38xveQtnXvYboFN8InA78Yi/rmfP3UUWO\nRUSmkKIUNwJ9wFHuXs7tWw7cBRhwgLvvnut6RIoa+dpKkWPcff0cNVcEMzuD6BzPKHI8X++jyjkW\nEZnamen6ovwbMYC77wJ+DfQAD52nekSKGv3a6jSz55nZW8zsVWZ2ppm1NrC9IntrXt5H1TkWEZna\nfdL1nyfZ/5d0fe95qkekqNGvrXXAF4ifpy8Afg78xcxO3+sWijTGvLyPqnMsIjK1lel65yT7K9tX\nzVM9IkWNfG39J/AoooO8DDgB+DSwHviRmT1g75spMmvz8j6qAXkiIiICgLu/o7DpauClZjYAvA44\nH3jqfLdLZD4pciwiMrVKJGLlJPsr23fMUz0iRfPx2vpUuj5tFnWIzNa8vI+qcywiMrUb0vVkOWzH\npOvJcuAaXY9I0Xy8tjan62WzqENktublfVSdYxGRqVXm4nyMmU14z0xTB50KDAK/m6d6RIrm47VV\nGf1/8yzqEJmteXkfVedYRGQK7n4TcBExIOkfCrvfQUTSvlCZU9PM2s3s2DQf517XI1KvRr1Gzew4\nM9sjMmxm64GPpZt7tdyvyEw0+31Ui4CIiEyjxnKl1wGnEHNu/hl4eGW50tSRuAW4tbiQwkzqEZmJ\nRrxGzex8YtDdxcCtwC7gKOAsoAv4IfBUdx+dh7skS4yZPQV4Srq5Dngs8UvEJWnbFnd/fSq7nia+\nj6pzLCJSBzM7DHgn8DhgLbES03eAd7j79ly59Uzypj6TekRmarav0TSP8UuBB5FN5bYDuIKY9/gL\nrk6D7KX05eufpyhSfT02+31UnWMRERERkUQ5xyIiIiIiiTrHIiIiIiKJOsdLkJltMDM3s3P34thz\n07EbGlmviIiIyGKwpJePNrNXE+trX+jufU1ujoiIiIgscEu6cwy8GjgC2AD0NbUli8dOYgWa25rd\nEBEREZH5ttQ7xzJD7v4dYjoUERERkX2Oco5FRERERJJ56xyb2X5mdp6Zfc/MrjezXWa228yuNbMP\nmtnBNY45Iw0A65ui3j0GkJnZ+WbmREoFwC9SGZ9isNlRZvZpM7vZzIbNbLuZXWxmLzKz1knOXR2g\nZmYrzOz9ZnaTmQ2let5pZl258o8ys/8xsy3pvl9sZo+c5nGbcbsKx682sw/ljr/DzD5jZgfV+3jW\ny8xazOz5ZvYTM9tsZqNmdqeZfc3MTplpfSIiIiLzbT7TKt5ELEsJMA70AyuB49LleWb2aHe/sgHn\nGgA2AfsTXwC2A/nlLrflC5vZE4FvEMtjQuTdLgMemS7PMrOnTLFW92rgD8B9gN1AK3Ak8DbggcCT\nzOw8Ym16T+3rSXX/1Mz+yt1/Xay0Ae1aC/yRWP5ziHjcDwFeDDzFzE539+smOXZGzGw58G3g0WmT\nE0uPHgScDTzDzF7l7h9rxPlERERE5sJ8plXcBrwFuD/Q7e5rgU7gIcD/EB3ZL5uZzfZE7v4Bd18H\n3J42Pc3d1+UuT6uUTWt0f5XogP4SONbdVwHLgZcAI0SH78NTnLKyHOIj3b0X6CU6oOPA35jZ24AL\ngPcBa919JbAe+C3QAXyoWGGD2vW2VP5vgN7UtjOIJRn3B75hZu1THD8Tn0/tuYxYL70n3c81wFuB\nEvBhMzu1QecTERERabh56xy7+0fc/b3ufpW7j6dtJXe/FHgycC1wP+C0+WpT8hYiGnsT8AR3vyG1\nbcTdPwO8MpV7oZkdPUkdy4Anuvuv0rGj7v5ZosMIsf73F939Le6+I5W5FXgOEWE9ycwOn4N2rQCe\n7u7fd/dyOv6XwOOJSPr9gGdN8/hMy8weDTyFmOXir9z9IncfTufb7u7vBt5OvN7ePNvziYiIiMyV\nBTEgz91HgJ+km/MWWUxR6qenmx9y98EaxT4LbAQMeMYkVX3D3W+ssf2nub/fW9yZOsiV446fg3Zd\nUumwF857A/DNdHOyY2finHT97+6+c5IyX0rXZ9aTKy0iIiLSDPPaOTazY83sY2Z2pZn1m1m5MkgO\neFUqtsfAvDl0LyLvGeAXtQqkiOuGdPPBk9Rz1STb70nXw2Sd4KJN6Xr1HLRrwyTbIVI1pjp2Jh6e\nrt9qZnfXuhC5zxC51msbcE4RERGRhpu3AXlm9mwizaCS41omBpiNpNu9RBrBsvlqE5F3W7FxinJ3\n1Cifd9ck20vpepO7+zRl8rm/jWrXVMdW9k127ExUZr5YVWf5ngacU0RERKTh5iVybGb7A/9OdAC/\nRgzC63L31ZVBcmSD0mY9IG8vdU1fpCkWarvyKq+jp7q71XHpa2ZjRURERCYzX2kVjyciw9cCz3X3\nS919rFDmwBrHjafrqTqIK6fYN53Nub+LA+LyDq1Rfi41ql1TpahU9jXiPlVSQ6Zqq4iIiMiCN1+d\n40on7srKrAl5aQDaX9U4bke6PsDMOiap+6Qpzls512TR6Jtz5zizVgEzayGmP4OYpmw+NKpdp09x\njsq+Rtyn36brxzegLhEREZGmma/OcWUGg+Mnmcf4xcRCFUV/JnKSjZird4I0hdnTi9tz+tN1zVzY\nlAf87XTzVWZWKxf2RcTCGU4syDHnGtiu083s4cWNZnYM2SwVjbhPF6brx5rZ46YqaGarp9ovIiIi\n0kzz1Tn+KdGJOx74iJmtAkhLLr8B+DiwtXiQu48C30s3P2Rmj0hLFLeY2WOI6d+GpjjvNen6Ofll\nnAveQ6xqdzDwAzO7T2pbp5m9GPhIKvcf7n5Tnfe3ERrRrn7g22b2hMqXkrRc9Y+IBViuAb4+24a6\n+4+JzrwB3zGzN6Q8c9I59zOzZ5jZD4APzvZ8IiIiInNlXjrHaV7dC9LNlwPbzWw7sazz+4GfAZ+a\n5DrgEeoAACAASURBVPA3Ex3nw4BLiCWJdxOr6u0Azp/i1P+Rrp8J7DSz282sz8y+mmvbTcRiHMNE\nmsL1qW27gM8QncifAa+u/x7PXoPa9S5iqeofALvNbBdwMRGl3wycXSP3e2/9HfBdIj/8/cAmM9ue\nzrmZiFA/oUHnEhEREZkT87lC3muBvwcuJ1IlWtPfrwbOIht8VzzuZuAU4CtEJ6uVmMLs3cSCIf21\njkvH/hx4KjGn7xCRhnAEsK5Q7r+BE4gZNfqIqcYGgV+lNj/W3XfP+E7PUgPatRU4mfhisolYqvrO\nVN8D3f3aBrZ1t7s/FXgiEUW+M7W3jZjj+evAC4BXNOqcIiIiIo1mk0+/KyIiIiKyb1kQy0eLiIiI\niCwE6hyLiIiIiCTqHIuIiIiIJOoci4iIiIgk6hyLiIiIiCTqHIuIiIiIJOoci4iIiIgk6hyLiIiI\niCTqHIuIiIiIJG3NboCIyFJkZrcAK4il30VEZGbWA/3ufuR8n3jJdo633H2LA2zetrW6bcfAIACX\n/e9VAHz7a1+v7hsfLQEwOj4OwNjYsuq+7lVnAHDPwFEADA5tru4rDd8IQG/3bQCURwaq+8rjOwHo\n6jAA3MvVfR1dHVF3d2d1286d0dYWYknvttb2rC5G4zzLlgPQ3t5V3de/ayBta0/nyR6Hzq5uAHYP\nRpmBXbuq+9asXgPAH377a0NEGm1Fd3f3muOOO25NsxsiIrLYXHfddQwNDTXl3Eu2c+y0AjA+nnVI\nx0ajg9mSOqkduaQSa4ke5TDROR4c3ZHtHLk7/bEagPauddVdZds/ivhw1GlZ57i1JR7ecnk0NWq4\num98LDrjg6WsfT2dvbFtKDrV5ZZsX0uqq60tOtUduc5xb3fqDVv0ccdL49V9o6NxzuGRuO7u6c7a\nUCohInOm77jjjltz6aWXNrsdIiKLzoknnshll13W14xzK+dYRPZJZrbezNzMLmx2W0REZOFQ51hE\n5ow6oCIistgs3bQKi1SDfP5tuRxpCu2tkX6wprenum8o5SPTEvvKpZHqvnYiraI95SMPjx1e3dfR\ndlj8MZZyiFMuMcDwUNRZyWNutbHqPiulFIixLHWirTVSHtrbIg+5rS17elpaIk3Ey/F9Zngkq8ur\nKRdt6b5nx5XGUrpHR6RhtObqdFeqschcunrjTta/6QfNbobIrPS976xmN0FkXilyLCIiIiKSLNnI\ncf/gPQC4ZSMdrTUiuCkIy7LObFCbjcSguVIapDbekg1WGx65HYDWctTZ49kMGCNDVwIwOnhLXHdn\nEd21BxwNwI6d2wAY2HFT1sA0OLC9rTVr867dsa01os9j41lkt7MjoskjoxEKb2nLItTtHd2pfOwz\ny+q09P0nBdIZGsoi4p0d2eA8kUYzs/OBf043zzGzc3K7X0BMcfYL4B3AD1PZhxEjX4909z4zc+CX\n7n5GjfovBM6plC3sOxl4HfAIYD9gG3AV8Fl3/zpTMLMW4EPAK4HvAH/r7s0ZMi0iIvNuyXaORaTp\nNgCrgFcB/wt8N7fvirQPokP8ZuBXwOeIzuzo3p7UzF4MfBIoAf8P+AtwAPAQ4Dxg0s6xmXUBXwKe\nBnwceKXn52Csfcxk01EcO+PGi4hI0y3ZzvH1N/8ZgBuuvby6be3a+CxuG4uI7NrebI7hdmJe491j\n8Zk8NJpFWEvpc3p8LKZYGxvbVN03uCvyiiu5ve7Lq/se9JAnAtDSc3C06Refru7bfGd8no6ODla3\ntVayXNojzFuyLGF6LE3P1p1yope1ZJHjcilFvcut6TqLXpetnM4T2zwXEW/tWInIXHH3DWbWR3SO\nr3D38/P7zeyM9OdjgJe6+6eZJTO7L/AJoB94pLtfU9h/6BTHriE60w8H3uTu/zrb9oiIyOKzZDvH\nIrJoXNGIjnHyMuJ97V3FjjGAu99R6yAzOwL4MXAU8Pz/z96dh8l1lPce/769zCaNdtmSF1m28YaN\nbTCLgQTLIbFZAiFkYQtgyA0hkEBIeBLWYGeDJAR8Q1iyAL4YEyDhEsIWDAbbmCVwDbaxLa+yvMva\npZnRbN393j/e6nOOWj2j0Wg0I/X8Ps8zz+mpOqdO9ajVU/3OW1XuftVUb+ju503Q5o3Ak6bajoiI\nHB40OBaRufajGWzr/HT8+gFccxrwA2AB8Fx3v2YG+yMiIkeYjh0cDw9GSsK3v/E/WdniBZF28NST\nYim21YvyCW+LemJyXlc5dsHbPpjvkDdaj3SHatrNbqSRp0I0GpF+0ZwD1yjnqRoDfUcBcPwxETxa\nefYLs7ptuyJFozZcWMqtEv2pltL21PU8PaJOTJ7bMxyT9iqWT6brTku/WZppaJ6nTniaaFjtirSR\nYlpF94qjETkMbNr/KVPWzGN++ACuORVYRuRB/2QG+yIiIkcgLeUmInPN91M30Yf4JW3Kmp9qjz2A\n+38ZeAdwLnCNmS0/gGtFRKTDdGzk2JvR00Y+cW3Htois3lbaDcDSnjwy250+Jizpjwhrb3c1qxve\nU09txu/w7nJe1+iJCG5zybSuBQuyutE9AwBs3/woAOX+FVldZWWkKQ4OrsrKRohJfaMD8VfmWim/\nz5lr4nnU0mTAsVo+8W9hVzMaHH1YflQevT7zrFMAuOa6x9JzySPVI4MDiBxizRdnedKzJrYDOL61\n0GK9wnPbnP9DYlWK5wJ3TPUm7v5eMxsmlnC71sx+0d0f2991+3PWsYu5URsoiIgcURQ5FpFDaQcR\n/V2zvxMn8CNgjZld1FL+LuCENud/FKgB704rV+xlstUq3P1yYkLfmcB1ZnbMNPssIiJHsI6NHIvI\n3HP3QTP7H+Dnzewq4C7y9Yen4v3AxcCXzOxzxGYezwBOJNZRXtdyv9vN7A3Ax4CfmtmXiHWOlwNP\nIZZ4u3CS/n7MzEaAjwPXm9kvuPsDU+yriIh0gI4dHNfqkQLR8DydcddQTILbNRxpFYv78qdfTmsF\n9/bFBLtaaVlWd/qZp8b5S/sAWNSfT4ZbsngRAAv6omzRgjwNctWa2CGv2h0pEQN78jTIXU++AICh\nwbwPO3fHRL8tWyM1Y+fO7Vnd8v5IAdldisl9A9t3Z3WNnZG20dM3CICV8828HhmMiYalJREE87F8\n7tPKpUchMgteSaQrPAd4GWDAQ8QOeZNy92vM7EXAnwEvBYaAbwIvIXbWa3fNv5jZrcBbicHzi4Ct\nwC3Av07hnleY2SjwKfIB8ob9XSciIp2hYwfHInJ4cPd7gBdMUG0TlBev/y/aR5ovSV/trvkB8Gv7\naXfjRPd3938D/m1/fRMRkc7TsYPj0Vpzx7p8p7tdAxE5HvFItV62KJ8Md+zyiNY+sD2it4P1/Eez\n9pS1APQsioluY418Z9tdaYe7oT1xP7rz37U9W38GwJlrVwPwlNNX5nWVaPP+Tduyslvuifk/Ph7R\n3cXVoaxux2DskLdz1yMA9Pf3ZXVei4l7u7dFpLmWz+Nj9yPRfrnc3D1vMKs75qSnICIiIiI5TcgT\nEREREUk6NnJMI3J0V6WcYICtj0We7uhYrC5l5MuanX1OTGyvPBDRZe/N84obFtdt3hrnWyVfHm7b\nlojyjuyJCPUDy3Zldf2pjXvvjXTF1704nwdUrUabWwfyKPT/3L4DgFtvuQeAY9fkk+WPXxN5z1t2\nxB4Ft/z0Z1ndIov+9FhErfd05dHr4cGIRm/fvjXuuyjPib77p82NwN6JiIiIiChyLCIiIiKS0eBY\nRERERCTp2LSKhWmnurPOPicru/eRSC3YuT12hlu47OisrntlLLO2IM2BGy7saLsr7XS3tH9xKilM\ncO+PpdKGLc7ftWtHVlVpxGePTWmy3p49+QS7Rf0xa+7xa/Il47actRaAu279IQAPPJgvr1rqi8mA\njzvtNAAe2ZLfZ0uaiNfVFf+ctd21rM7HIr2kUY9Ukl2FJeB2jI8gIiIiIjlFjkVEREREko6NHPel\niXhLjl+dlfUs7gegsWUnAKVyvubZ9sGYULfx4ZjA1r8ynwznHhPx6iMx2W7pyuVZ3ZKVEX1eviK+\n792aL802vCuitL2LYmLeyGgeqfW+WFqtOp5vynHhk6OR/t5fAeDL3/x2VrfhgTsBGFoS9ztqdb6B\nx65dETkeGYhl2vqW9Gd1Zz/p7Hiuw/EcxskNj9YQERERkZwixyIiIiIiScdGjkvVWN5sxQn5ls2n\nPuGMKFsUucOvefnzsrqVR0fu76knHBfnrD4+q1vYG211lSLXuFopZ3XNx9VmHrLly8NV0tJq9UZE\naJcuyK+z9NBH92RlO354EwBrapFf/NbnPTer2zQW0e4t6fvhoTwKPXB+LEO3azBymqsLurO6Rf0R\nRX70zohQ12p5vvTASJ5XLSIiIiKKHIuIiIiIZDQ4FhERERFJOjetohHpA97I0xzOfPzjADjjF58F\nwAmrFmZ1ewY3A3DqqpikVy1vyepKo/XUVnxfKefpEb3dcX5XSquwal5XSRP+ymlHPR/LUxqaD+/4\n2veysg1XpQl4y1YCsGrJ0vz8aizdduwLz4+60/N0kcFaTPjbPtwHwEM78l36BofieQyPxOTAkeF8\ndz+3/PmLiIiIiCLHInKYMjM3s2sP4Px16ZpLW8qvNTMl2IuIyJR0bOTYUiS3VM9/Jy7uiajuIw9u\nAGBF34lZXS0t01aqR3h4rD6aN1aLCXX1FI0u/p7tJs6vpDLLA8eU0wS+kkW0tlSYyFcpxY++XCtE\neZfEcdfDDwHws82bs7qB7bEhyLHb4rjutRfl91kYEeodaam4BzcP5PfpiiXtuo4+BQAfzzcdoV5c\n2E2OdGkAeJ27r5vrvoiIiBypOnZwLCLzzo+AM4Ctc92Rplsf3sXat311rrsh89DG9z1/rrsgcsTS\n4FhEOoK77wHumOt+iIjIka1jc46rVKhSobfSnX0NDQwzNDDMPfc8wD33PMCWRx7KvrpLRnfJMIsv\nyL+cBk4DsxpmNdzr2dd4bYzx2hij46PxNVbLv2owWoNyTzflnm66e/qzr7obdTeWnLU6+7rgdy7i\ngt+5iNPPPprTzz6a+rb7s69aby+13l72bBtmz7ZhNj34SPY11BhnqDFOzWvUvMaK5Quzr+6+Lrr7\nuqBvCfQtYfPY0uzr/qFu7h/q3s9PUmaKmV1iZl8wsw1mNmxmu83se2b2W23O3WhmGydo59KUW7uu\n0G4z1+eCVOcT5N/+ppldb2a7Uh9+ZmZvN7N9XgjNPpjZQjP7oJk9mK65ycxelM6pmNk7zexuMxsx\ns3vN7Pcn6HfJzF5vZj82s0EzG0qPf8/MJnwvMrNjzOxKM9uc7n+jmb28zXltc44nY2YXm9nXzGyr\nmY2m/v+dmS2ZahsiItJZFDkWmT0fBW4DrgceBZYDzwOuNLPT3P3d02z3JuAy4D3A/cAVhbprmw/M\n7K+BtxNpB58BBoHnAn8NXGxmF7n7WEvbVeCbwDLgS0AX8DLgC2Z2EfAG4GnA14FR4DeAD5nZFnf/\nXEtbVwIvBx4E/hVw4FeBjwA/B7yizXNbCnwf2Al8ElgC/CZwlZkd6+5/t9+fzgTM7D3ApcB24CvA\nZuBs4K3A88zs6e6+e7rti4jIkaljB8eLlsQueGPWl5Utr60B4KGHHovjpseyuhXLY0e8ejkCWPVG\nHshqNDe/S2u5Fee9N9LjWprI15wICLCsP5ZiW7Z8FQDd1Tw4N5p2xtu+/eG8rf6YsLfmF88C4BeW\nV7O6kWULov3+eD6VFT153Xhaai4F37rLed9rtbHU520ADA/nP4+a9yOz6ix3v7dYYGZdxMDybWb2\nMXd/uP2lE3P3m4Cb0mBvo7tf2nqOmT2dGBg/CDzV3Tel8rcDXwR+mRgU/nXLpccAPwHWuftouuZK\nYoD/78C96XntTHUfIFIb3gZkg2MzexkxMP4p8Cx3H0zl7wKuA15uZl9198+03P/sdJ+Xusd/QDN7\nH3Aj8Fdm9gV333BgPzEwswuJgfEPgOc1+5/qLiEG4pcBb5lCWzdOUHX6gfZLRETmXsemVYgcbloH\nxqlsDPgw8UH12Yfw9q9Nx79sDozT/WvAHwMN4H9NcO0fNgfG6ZrvAvcRUd0/LQ4s00D1e8BZZsW1\nW7L7v605ME7nDwF/mr5td/96ukejcM19wD8QUe1XTviMJ/emdPydYv9T+1cQ0fh2kWwREelwHRs5\n3t0T4/5Sb29WVh6O6OvusVjy7JGt+QYhJ+2ISK6n5dZq9cJfl2ux5Fk5RYdL+e9pzFOkONX19Obj\ngbpHWPmmW+4EYOWyPFJ7wprVACxeenRW9uiDsUybL46l39Y+90lZnZdjOblaNerGGvWsbnSsudRc\nlI0UNj4ZsxQ5thiP1MeG8v5RQ2aPma0hBoLPBtYAvS2nHLvPRTOn+WL6dmuFu99lZg8BJ5rZYnff\nVaje2W5QDzwCnEhEcFs9TLy3rEqPm/dvUEjzKLiOGAQ/sU3dA2kw3OpaIo2k3TVT8XRgHPgNM/uN\nNvVdwEozW+6e/uwyAXc/r115iig/qV2diIgcvjp2cCxyODGzk4ilxpYC3wWuBnYRg8K1wKuBQzk7\ncnE6PjpB/aPEgH1J6lfTrvanxyerloH0XnVEZLd4/+1tcppx95qZbQWOatPWY23KAJrR78UT1O/P\ncuL97z37OW8hMOngWEREOosGxyKz44+IAdlr0p/tMykf99Ut5zeI6GU701lJoTmIXUXkCbda3XLe\nTNsFLDOzqrvvtfuMmVWAFUC7yW9HtymDeB7Ndqfbn5K7L9vvmSIiMq907OC4Xo10h62b8v0Atj4Q\nwabFC2Ki3P333Z3VnbQ6glbHHrccgAXdhR/NaEqdGI/f6bVanrZQr0UqQ7YRXyNPq7jmWz8E4Ac/\nXg/A6pX5mOaXn/0UAJ75pCdkZf29CwHYtHPz3m0CC/ojqNjd3FnP8rSKeilSSMZTOkWtlF9YWhwT\n8HwggniDu7N0U2qF1Aw55B6Xjl9oU3dBm7IdwNntBpPAkye4RwMoT1D3U+JP/OtoGRyb2eOA44D7\nWvNvZ9BPiXSSZwHXtNQ9i+j3T9pct8bM1rr7xpbydYV2p+OHwPPN7Ex3v22abezXWccu5kZtxiAi\nckTRhDyR2bExHdcVC83sYtpPRPsR8eH1NS3nXwI8c4J7bAOOn6DuE+n4LjNbWWivDLyfeC/4+ESd\nnwHN+7/XLF9CJj1+X/q23f3LwN8U10E2sxOJCXU14NPT7M8H0/FfzOyY1kozW2Bm50+zbREROYJ1\nbOR4650xuW1490hWNvRY/NV2bCQm3t/7QB5F3bJ5OwBPe/KZADz+tHyMsWJBWkatFNd1VfNAXrkR\n6ZXu8aPcvHNPVvejW2KFqb6VsYTcSDlPwfzqdyJItnxRPklv7THxF97mJL89I9kCAQyMpwmD1bhP\nrZxHh0fS2nKDaQLgaFeeujo2HucPDEWq54LuPOo9MpL3VQ65jxAD3X83s/8gJrSdBTwH+Dzwkpbz\nP5TO/6iZPZtYgu1cYiLZV4il11pdA7zUzL5MRGHHgevd/Xp3/76Z/S3wJ8CtqQ9DxDrHZwE3ANNe\nM3h/3P0zZvYrxBrFt5nZfxLrHL+ImNj3OXe/qs2ltxDrKN9oZleTr3O8BPiTCSYLTqU/15jZ24D3\nAneb2deIFTgWAicQ0fwbiH8fERGZRzp2cCxyOHH3W9Laun8JPJ/4v3cz8GJig4uXtJx/u5n9IrHu\n8AuIKOl3icHxi2k/OH4zMeB8NrG5SIlYq/f61OafmtlPgd8HXkVMmLsXeBfw9+0my82wlxErU7wW\n+N1Uth74e2KDlHZ2EAP4vyU+LCwCbgfe32ZN5APi7n9jZt8jotA/B/wKkYv8MPDPxEYpIiIyz3Ts\n4Hh8Z0R3vZZnjtRrEbkd2B3R09178ujrvRvuAeDWOyLae8Lx+V9az3/y2QCcefpJACxZuCirK9ci\nuttTija3bMtznJcsi7lEo82deSt55PixLRFxvu7HN2dlKy6OPOTFC2KFr+Hh4axupB75wQPpOOj5\nZiNDaSeSel/0a7QwgX9kYAcAtZFIRV2+bEVWt2foUM29knbc/fvAL0xQba0F7n4DkY/b6hZiA4vW\n8zcTG21M1ofPAp/dX1/TuWsnqVs3Sd0lwCVtyhtEBP0jU7x/8Weyzxbbbc6/lvY/x3WTXHMDESEW\nEREBlHMsIiIiIpLR4FhEREREJOnYtIpGSqcYG893gStVYpL82pPPAKB7Qb7E6dBgTNbb+tiDwN7L\nvH3ui98A4KhlsRTbGaefmNU9/tRItVi7OtIV6pZvenbM6tjwbPPuAQDuvmdDVrc4pWbc/eCOrOy+\nR2IJtxULYwLg4GieArplINJE7tseO9xVlvRkdQsWxz0XdEfahu3JJyE29vSk+8UCBcOlfKWvRi2f\n8CciIiIiihyLiIiIiGQ6NnI8PBrR00o1j7AuXBCbbJjFnJ3jKguyukopNiMbPvF0ANacdFpWd/+G\n2MRjwx23AvDfV1+X1V1/w48AOPXEEwA4ee2xWd1IIybiPbTpEQBGR/JI8Ennnhx1d9+Rld15X0SO\n7YTYrGznSB4BvmdzRLZvS+c84aw8el0b2QLAA/fGsX/hCVlduRqTAusW/9SlUr4MXV9v/rMRERER\nEUWORUREREQyGhyLiIiIiCQdm1ZRLsVTq5bz8X85pRaUS5FOUPF8Qpp5rFPcVYmJcj0LHp/VrVoV\nO9yd+LizALh/w+1Z3YYNkRbx49vieOPP1md1Z59zbtyvGpPgFizIJ+vdfdedANQKu+BteDgm5x1/\nTKRVjOUZEKxYFv06f2mkhtxzzwNZ3be+dSMAgyPx/M485+ys7uSTT4nn1R3Xl6rZzr1YOX8sIiIi\nIooci4iIiIhkOjZy7J52javn4ddGbC5HtRqfCRb15TvWlYjI8WgtTur1rqyu1hMT9xYviuXQVh+1\nJqtbsyaWcrv3nlsA2HD3nVldtTsixqedEpP8tm3dltV1pbr1d+SR5nsfimXnVh4V5w3s2ZPVbd2+\nE4BNW2LS3W133J/Vbd8RE/26+yISvGHDvVld2eLncNIJMUnPCpHjSm++W56IiIiIKHIsIiIiIpLp\n2MixpUhwSiWOMm8eI9JareSfDboq8aPoqkfZyGh+4dh4RJ/Noqx/YX9Wt2ZN5CEvXrwKgOXLjsnq\nHnkwIrjbU9S3pyvPOT766NiA5Ge33paV3XbPwwDcfMdGAMbH6lndSFoGrpYi29VKHvXu6Y12e3uj\nrL8/X6KtlPpcqw0DsGxpvvFJb9qIRERERESCIsciIiIiIokGxyIiIiIiScemVZRI6QeFpdysFJPg\nyimdwvCsrpEm7tXHUzpFvZCPkWbylTy1Wcp/bKWU0lApxU50C/vyXfdWrohUi02PbARgZGhnVrf+\nu7Hb3iObHsvKdg4MAVCrxb3LpcIydOXoe3dXTBTs6crTKhb2Rx9WrV4e9125PKvrSjsEeil266t2\nLcnqzPJJhyJHCjPbCODua+e2JyIi0okUORYRERERSTo2ctyVNt6oVvOn6I34LOBuANQK0eFaIx6P\nDI/EOVhWV06T9cyb1+f3KRET5bwSy7A1NxgBWHPCqQAcffSxADz08MasbudQXHfU0flSc0uWxNJt\n42NRh+WfXaopYtzXF1HiBQvyCHVWtjCWaevrKdT1x3Jti5cdnxrKJxPuHNqNiIiIiOQUORYRERER\nSTo2clxJObqNRiE6XEtRWm9GgvOnb2mdN7fm5iH5MmqlFGkupfzlUmF9OEvnNa8r3q+SllvrXhqb\nh5y1bHVWd8JJsT311q0PZ2W7tz8KwOjQrujvWL619HgjLT9XjQiylQt5z5XmUm6RT7ygP88r7utf\nGv0j+jI4OJDV7RnOH4scTszMgDcCvwecDGwDvgi8c4Lzu4G3AK9I59eAm4EPufvnJ2j/TcDvAie1\ntH8zKKdZRGS+6tjBsYgc0S4nBq+PAv8MjAO/AjwN6IKUzwRYzCz9BnABcAfwYaAP+HXgc2Z2rru/\no6X9DxMD70dS+2PAC4GnAtV0PxERmYc0OBaRw4qZPYMYGN8LPNXdt6fydwLfAVYD9xcu+WNiYPx1\n4IXuXkvnXwb8CHi7mX3F3b+fyn+eGBjfBTzN3Xem8ncA3wKOaWl/f/29cYKq06fahoiIHD46dnA8\nPhYT6xqep1V7WrrN0jJvxQl5lUqawJeWSCvV8jpPM/Bqaac86rWsrmTpupTG0fweoJ7m9DXTObyc\nT/KrVBYCsHTZCVnZokWxHFwj9X1kZCirGx7dk55P9KtUzpdhq1ZjAl5XT1pWrjt/zmOprYFdsYzc\n+GieqtHdo6Xc5LD0mnT8q+bAGMDdR8zs7cQAuei1gAN/1BwYp/M3m9lfAP8K/C/g+6nq1YX2dxbO\nH0vt3zCjz0ZERI4oHTs4FpEj1pPS8bo2dTcA2YQAM+sHHgc87O53tDn/2+n4xEJZ83G7QfAPiXzl\nKXP389qVp4jyk9rViYjI4atjB8dj48MA1OtWKI2IaiVNauvqypddq5QjYjw+HpHVRiP//dicY9fc\nNKRUWMvN0+/pUlr6rVRYfq2eLmzU9z4CNFITJStEqNMmJXRFJLi70pf3r68Z7U5LxzUK68mlh/Xm\nRibDebrk2Nhw6ntcXyn8izfqY4gchhan42OtFe5eM7Otbc59dIK2muVLCmWTtV83s20H0FcREekw\nWspNRA43u9Lx6NYKM6sAK9qcu2qCtla3nAfQXOC7XftlYHlruYiIzB8aHIvI4eYn6XhBm7qfA7LE\nfncfICbuHWtmp7Q5/8KWNgF+Wmir1fl08F/URERk/zr2l8Bomsw2Nl5c5ziOPV2RrlAt5U+/L+1A\nV2tO2it8bChbSs1Ik/tKlqdqNNc1Hk+NNzyv8/Q73BrNtZPzVA1LaRyVwk58pfRZZTylPDYa+eQ5\nmpP6UtqHe5460VXde+e+amEN5L4F8VyHLCbmDQ/n6zc3PH8schi5gphA904z+1JhtYoe4L1tvuBT\n6gAAIABJREFUzv8E8FfA35nZr7nHC9vMVgDvLpzT9CliEl+z/V3p/C7grw/B8xERkSNIxw6OReTI\n5O7fM7MPAX8A3Gpm/0G+zvEO9s0vfj/w3FR/s5l9jVjn+DeAo4C/dfcbCu1fZ2b/DLwOuM3MvpDa\nfwGRfvEI0ODgrV2/fj3nndd2vp6IiExi/fr1AGvn4t7mhcllIiKHg8IOeW9k7x3s3kGbHexSVPmP\ngJez9w55H3b3f2vTfgl4M7FD3okt7T8E3Ovu5x7kcxglUkBuPph2RA6h5lrc7VZ6EZlr5wB1d++e\n7RtrcCwikqS85buAz7r7yw6yrRth4qXeROaaXqNyOJvL16cm5InIvGNmq1L0uFjWR2xbDRFFFhGR\neUg5xyIyH/0h8DIzu5bIYV4FPBs4jtiG+t/nrmsiIjKXNDgWkfnom0Q+20XAMiJH+S7gH4DLXflm\nIiLzlgbHIjLvuPs1wDVz3Q8RETn8KOdYRERERCTRahUiIiIiIokixyIiIiIiiQbHIiIiIiKJBsci\nIiIiIokGxyIiIiIiiQbHIiIiIiKJBsciIiIiIokGxyIiIiIiiQbHIiIiIiKJBsciIlNgZseZ2SfM\n7BEzGzWzjWZ2uZktnYt2RFrNxGsrXeMTfG06lP2XzmZmv25mHzKz75rZ7vSa+vQ02zqk76PaIU9E\nZD/M7GTg+8BRwJeAO4CnAhcCdwLPdPdts9WOSKsZfI1uBJYAl7epHnT3989Un2V+MbObgHOAQeAh\n4HTgKnf/rQNs55C/j1YO5mIRkXniI8Qb8Zvc/UPNQjP7APAW4K+A189iOyKtZvK1tdPdL53xHsp8\n9xZiUHwPcAHwnWm2c8jfRxU5FhGZRIpS3ANsBE5290ahrh94FDDgKHcfOtTtiLSayddWihzj7msP\nUXdFMLN1xOD4gCLHs/U+qpxjEZHJXZiOVxffiAHcfQD4HtAHnD9L7Yi0munXVreZ/ZaZvcPM3mxm\nF5pZeQb7KzJds/I+qsGxiMjkTkvHuyaovzsdT52ldkRazfRraxVwJfHn6cuBbwN3m9kF0+6hyMyY\nlfdRDY5FRCa3OB13TVDfLF8yS+2ItJrJ19YngWcTA+QFwBOAfwLWAl83s3Om302RgzYr76OakCci\nIiIAuPtlLUW3Aq83s0Hgj4FLgV+d7X6JzCZFjkVEJteMRCyeoL5ZvnOW2hFpNRuvrY+l47MOog2R\ngzUr76MaHIuITO7OdJwoh+2UdJwoB26m2xFpNRuvrS3puOAg2hA5WLPyPqrBsYjI5JprcV5kZnu9\nZ6alg54J7AF+OEvtiLSajddWc/b/hoNoQ+Rgzcr7qAbHIiKTcPd7gauJCUlvbKm+jIikXdlcU9PM\nqmZ2elqPc9rtiEzVTL1GzewMM9snMmxma4F/TN9Oa7tfkQMx1++j2gRERGQ/2mxXuh54GrHm5l3A\nM5rblaaBxH3A/a0bKRxIOyIHYiZeo2Z2KTHp7nrgfmAAOBl4PtADfA34VXcfm4WnJB3GzF4EvCh9\nuwq4mPhLxHdT2VZ3f2s6dy1z+D6qwbGIyBSY2fHAnwPPAZYTOzF9EbjM3XcUzlvLBG/qB9KOyIE6\n2NdoWsf49cATyZdy2wncRKx7fKVr0CDTlD58vWeSU7LX41y/j2pwLCIiIiKSKOdYRERERCTR4FhE\nREREJNHgWEREREQk0eD4IJnZJWbmZnbtNK5dm65V4reIiIjIYUCDYxERERGRpDLXHZjnxsm3QhQR\nERGROabB8Rxy94eB0+e6HyIiIiISlFYhIiIiIpJocNyGmXWZ2ZvN7PtmttPMxs3sMTO72cw+bGZP\nn+TaF5jZd9J1g2b2QzN72QTnTjghz8yuSHWXmlmPmV1mZneY2bCZbTazfzOzU2fyeYuIiIjMd0qr\naGFmFeBq4IJU5MAuYnvCo4Cz0+MftLn23cR2hg1iT/oFxH7fnzGzo9398ml0qRv4DnA+MAaMACuB\nlwIvNLPnuvv102hXRERERFoocryvlxMD4z3AK4E+d19KDFJPAH4fuLnNdecSe4a/G1ju7kuIven/\nI9W/18yWTaM/v0cMyF8FLHT3xcS+9z8B+oDPm9nSabQrIiIiIi00ON7X+en4KXf/tLuPALh73d0f\ncPcPu/t721y3GHiPu/+lu+9M1zxGDGq3AD3AL0+jP4uB17n7le4+ntq9CbgY2AYcDbxxGu2KiIiI\nSAsNjve1Ox1XH+B1I8A+aRPuPgx8I3171jT6cz/wmTbtbgX+KX3769NoV0RERERaaHC8r6+n46+Y\n2X+Z2YvNbPkUrrvd3YcmqHs4HaeT/nCdu0+0g9516XiWmXVNo20RERERKdDguIW7Xwf8GVADXgB8\nAdhqZuvN7P1mdsoElw5M0uxIOlan0aWHp1BXZnoDbxEREREp0OC4DXf/C+BU4O1ESsRuYrOOPwZu\nN7NXzWH3REREROQQ0eB4Au5+n7u/z92fAywDLgSuJ5a/+4iZHTVLXTlmCnV1YMcs9EVERESko2lw\nPAVppYpridUmxon1i588S7e/YAp1t7r72Gx0RkRERKSTaXDcYj8T28aIKC3EusezYW27HfbSmsmv\nS9/++yz1RURERKSjaXC8r0+Z2SfN7GIz628Wmtla4P8Q6xUPA9+dpf7sAv7FzF6Rdu/DzM4mcqFX\nApuBj8xSX0REREQ6mraP3lcP8BLgEsDNbBfQRexGBxE5/t20zvBs+CiR7/xp4ONmNgosSnV7gN9w\nd+Ubi4iIiMwARY739TbgT4D/BjYQA+MycC/wSeBJ7n7lLPZnFFgH/DmxIUgXsePeZ1Nfrp/FvoiI\niIh0NJt4fwmZS2Z2BfBq4DJ3v3RueyMiIiIyPyhyLCIiIiKSaHAsIiIiIpJocCwiIiIikmhwLCIi\nIiKSaEKeiIiIiEiiyLGIiIiISKLBsYiIiIhIosGxiIiIiEiiwbGIiIiISFKZ6w6IiHQiM7sPWARs\nnOOuiIgcidYCu939xNm+cccOjt/82VsdoFqtZmXVnjIA3V1x7KrkT79cjbJSOYLp5UoeVG+eVk51\n1bLlbabK5tmlUuG6Un4egO31bXzj5KuFeCMeN1JZsa7hlo5RVqvndbV681gDYGy8kdeNp/PTSWNj\ned3YWJS997kn7N1REZkJi3p7e5edccYZy+a6IyIiR5r169czPDw8J/fu2MGxiHQWM7sWuMDdp/xh\nzswcuM7d1x2qfk1i4xlnnLHsxhtvnINbi4gc2c477zx+8pOfbJyLe3fs4HhBTzcA1a48ctzVHdHh\nandEdyuFqHKlEnXNaO9ekeNqOj9FjCuVQuS4HD9CS4HcUiFaPJXIMcXIcYoKN6PDjSlGjuspcjxe\nT8+hXIgcl+O80Vot9aGe96CklHMRERGRoo4dHIuIAGcAe+bq5rc+vIu1b/vqXN1eRGRObXzf8+e6\nC9OiwbGIdCx3v2Ou+yAiIkeWjh0c9/VGykSlMOmumVaRpVcU6irNiXjZMc+BKJfZq6x5TrSRzk8p\nFMUJeWXb/9bce6VapG/qKSui4e3SKuL7eq2QOlGKx5V0fYVyVjduUefNGxXSNa2Unycyl8zshcCb\ngccDy4BtwN3A59z9Iy3nVoA/AV4DrAE2A58B3u3uYy3n7pNzbGaXAu8BLgROAP4QOB0YAL4CvMPd\nN834kxQRkSOCkk5FZE6Z2euALxED4y8Dfw98DeglBsCtPgP8AfBd4KPAMDFY/qcDvPVbgI8BNwOX\nA3em+33fzFYe8BMREZGO0LGR457u5uS0PFLa1RWfBXq69l2SrVzZOypc2StyHOHaZlS4EDim2nJd\ncUJe83FWslcgOb6x0r4T77PocKNRKNs7qly3vBP11MR4arPQdZrzCj1FicuWt9lV3vfeInPgd4Ex\n4Bx331ysMLMVbc4/GTjT3benc95JDHBfZWZvP4Co73OBp7n7Twv3+yARSX4f8NtTacTMJlqO4vQp\n9kNERA4jihyLyOGgBoy3Frr71jbn/mlzYJzOGQKuIt7PnnwA97yyODBOLgV2AS83s+4DaEtERDpE\nx0aOe7tS/m0xcpx+1fV0xbG4JFszn7iZMlxIR84izM284mLAtbkanKW831IhibgZYc5Sj9sEaq1Y\nmK5tLuFWCBwXoslpKbfCx5paMypcirpKvZCPXN/7PtVCznFdgWM5PFxFpFLcbmafBa4DvufuWyY4\n//+1KXswHZcewH2vay1w911mdhNwAbHSxU37a8Tdz2tXniLKTzqA/oiIyGFAkWMRmVPu/gHg1cD9\nwJuALwKPmdl3zGyfSLC772zTTC0dD2SW6WMTlDfTMhYfQFsiItIhNDgWkTnn7p9y9/OB5cDzgY8D\nzwK+cQgnxx09QfmqdNx1iO4rIiKHsY5Nq+jr3ndJtq60013zuHdaRfMYqQnFyXrZznjNlItC6kQz\n/aJZVNx0rmx7T8hzK+6Gl84v9LmZ8eDNtIryvku5NXfDK6zkRi1dV0mtjZfyyvF0T0/pGKVG3vdC\nEyKHhRQV/hrwNTMrAa8lBslfOAS3uwD4VLHAzBYD5wIjwPqDvcFZxy7mxiN0EXwRkflKkWMRmVNm\ndqGZtcuAPyodD9UOd680sye2lF1KpFP8m7uPHqL7iojIYaxjI8c96ZkVo8PNDTuq2XJthQ07UpS2\n0nKMx83IcToWfo03myiVmsu9FaLRLb/v947UpmXXiiWprUYWQs5r6yn+XEtLsZULk+4qKQxdb0a/\nC/fNl5FLS80VlpOrWR2Rw8AXgUEz+yGwkXjZ/jzwFOBG4FuH6L5fB75nZp8HHgV+Ln1tBN52iO4p\nIiKHOUWORWSuvQ34MbGywxuIjTiqwJ8CF7r7Pku8zZAPpvudS75L3hXAM1rXWxYRkfmjYyPH3dWU\nO1wIlXaV0zbLWeS4EH1tRoWzjT5sn7psubfiJhuprLknR/Gvw824b1ZSqKuNx+T60T35X4z7+vuB\nfKvncj2P7GYbfaQb1Qsfa8abEWOake28spQeV4i2KoWc41HXZyOZe+7+MWKnuv2dt26SuiuIgW1r\n+aQLFk50nYiIzF8aHYmIiIiIJBoci4iIiIgknZtWkZ5ZVyGtolnWTKcozMfLUi2aE/OKS8BVmpPt\n0rJoxessqyPVFWa8NafgpaJqKZ9gN9KINIf7HnggKzv5cScD0LegD4A9A9uyulIltvfr6VsCwJgX\npvc1J/Kl5doaxSXj0s2tWVbKUzUaB7JdgoiIiMg8oMixiMwr7n6pu5u7XzvXfRERkcNP50aOUyi3\nWhj+dzWjwqW9jwCV5hJpzQhwYRqPpbZKqbBKcY5PTKxrbsBRKnzeaNTG4oFHtLZU7cvqelIYe3Ff\nV1a2c9PDAAx2R1l/T96/kYHYMben2hP3Kxf+6RrR9+Yyb8XuVVLkuNlScSOSerbjroiIiIiAIsci\nIiIiIpmOjRx3pQ0u9trquZkz3CZ3uPm4wt4R5HgcybnWiOVWfXwsq6v29sb90vf1wvJo41vvBKA2\nNADAkpOfvs/9jl7UnZUNbn0QgJ1btwLQ3ZfX1WsR5S0tXhoFvUuyuoanupSH7IXPPOX0fBrpWKG4\neYg2AREREREpUuRYRERERCTR4FhEREREJOngtIqUalAY/1c80iOySXeNPMWg3FzyLC23VmrkP5pK\npQrA2JZ7ANix8bas7oRnvhSARmMkCgorudUevRGAXTuGgZa0inTi0sX5fWzL/XGfbZFWMbJ5KKtb\ncsxRAGx98C4AVp70xKyupxptjKQd9bxe2G03PddmWsVYbTSvqimtQkRERKRIkWMRERERkaRjI8fl\ntMmGWR4dNU8bdtQjElyp5hPeSqVm1DUizo2BLVndeCU+Qww9uh6A+3/2g6xu5SlPjvvVYtJdudKT\n1Y1t3wTAju0xXe+kQlTZRwcBePQ7X8jKhjZF+6uf+cLUVr5LR7k3+vztb/0YgDNLi7K6pUevSn1P\nS85V8+Xhxkcjol0fjYhxY8+erK7h+XkiIiIiosixiIiIiEimYyPHPp42uChs9NHcAKO5SttjD+S5\nwzYekWJPucYDg3nE+bTTz0gNxCYeO/fknylGB3cA0F9KS6bV8jXgrBrLrZlFznFtfCSra4xF5Hhw\n22NZWY2IFC9evRqASndhmbfBOH9gd0R+h4eGs7ru3bsB2LrhXgC6+hZmdQuPORGAsT2Rh1wvRI7r\npeJmJiIiIiKiyLGI7MXMrjUrbKV46O6z1szczK441PcSERGZKg2ORURERESSjk2rqI9FGoEVhv+V\nUjxdb0QqxMDtn8/qlvpDAGzYtQCA6+7rz+pe0L0cgEWVSEPYPpo36r0xGa5n+cq4X2Ey3KM/+ykA\nt//sVgBO+oXBrG5J2v3uxHUXZ2XdC6J/1WpMvuuq5vfZnZZn27xpGwA/uP57eR/SP+OtN1wXfWjk\nO/j1nxQpIQO7Y1m4x599TlZ3yrnnI9LGq4C+ue6EiIjIXOjYwbGITI+7PzDXfRAREZkrHTs4Ht0R\nkeDxkZ1Z2f0DsZzZ5o03AbD7/luyuiXdEZm99b6IsN5wy0BWd8ePbgagktIwN23dlV933NkAPOms\niNCWyvnya7d/7ydx/MmdAJzwPzdndUsXR4S5u/Zg3uehRwCo1WIyYWXxMVndrXc+DMDn/+Mr0YdN\n+fOiHhHm8bSph3thc4/6DQCM1WPS3gte8casqrT0ccj8YGaXAC8AngisBsaBnwEfdfdPt5x7LXCB\nu1uhbB3wHeAy4GvAe4CnA0uBE919o5ltTKefA/wV8KvAcmAD8DHgQ+6+31xmMzsVeC3wi8AJwCJg\nE/AN4M/d05952vftP9O9nwl0AT8G3u7u329znwrwOiJS/nji/fBO4OPAR9y90XqNiIh0vo4dHIvI\nXj4K3AZcDzxKDFqfB1xpZqe5+7un2M7TgbcDNwCfAFYAY4X6LuBbwBLgs+n7XwP+N3Aa8Eb278XA\n64kB7/dT+2cC/wt4gZk92d0fbnPdk4E/AX4A/CuwJt37GjM7193vbJ5oZlXgy8DFxID4M8AIcCHw\nIeBpwCun0FfM7MYJqk6fyvUiInJ46djB8Rc/F8GwkYfy31s33BbR4FopllSrjeXbLDfSVtKj46X0\nff6j2bHzPgCaMa/iCmhX/uMHAPjPhXF+OW01DeC7twMwPBZtb/zbfPzRSJuUeGFc0WXRr0o52toz\nnre1a3cs3VYfiKh1f6WWt5Uee29sQOL1PHpdSnnSx528DoCTTjkjqxsYyLenlo53lrvfWywwsy7g\n68DbzOxjEww4W10EvN7d/2mC+tVEpPgsdx9N93kPEcF9g5l9zt2v3889rgQ+2Ly+0N+LUn/fBfxe\nm+ueD7zG3a8oXPO7RNT6zcAbCue+kxgY/yPwh57+3GJmZeCfgdea2X+4+5f201cREekwWq1CZB5o\nHRinsjHgw8SH5GdPsambJhkYN729OLB19+3AX6RvXzOFvj7cOjBO5VcT0e+L970KgO8VB8bJJ4Aa\n8NRmgZmVgD8gUjXe4oU8pPT4jwEHXrG/vqZrzmv3BdwxletFROTw0rGRYxHJmdka4E+JQfAaoLfl\nlGOn2NSP9lNfI1IhWl2bjk/c3w3MzIiB6SVE/vJSoFw4ZazNZQD/r7XA3cfN7LHURtOpwDLgbuBd\ncbt9DANntKsQEZHO1rGD4wGL34W7h/LgeH0wJqV1dcUvw0ohraK/N8r60+Zyixbl84b6FkS6Qnd3\nTKLr6c3THbrKkQoxnnbkq1byH2nfynSfcpxfLeW707lH2fBoPuenuyeWkSuX497jo/kYoFaP84dG\nVwCwdSCfdPfYYNxnVy3GDyOFf9YTT38KAOdc8EIAevuX5W2OTjTGkE5iZicRg9qlwHeBq4FdQB1Y\nC7wa6J7o+hab9lO/1feaEbrPdYuncI8PAH9I5EZ/A3iYGKxCDJhPmOC6nROU19h7cL08HU8hJhZO\nZOEkdSIi0qE6dnAsIpk/IgaEr2lNOzCzlxGD46na32oTK8ys3GaAvCodd7Ve0NKfo4A3AbcCz3D3\ngZb6lx1AXyfS7MMX3f3FM9CeiIh0kI4dHC9YHcuUVUa2Z2WraksAGN8TEdPu4d1Z3dJmjKg7Is2V\nBflfnXsWLgLALKK8jd58o4/+404EoGQR2S2V8kh1bWcszTaelmZbfEy+dFpXWvJtxXA+B6rqEVku\npyaGh/K0y8E0yW7b1mhrtPCX4GpvBP160iTC+ng+Lhnvjr5v3x6bh6zqzp9Xd/dUg4VyhGu+8L7Q\npu6CGb5XBXgGEaEuWpeOP93P9ScRcyGubjMwPi7VH6w7iCjz+WZWdffx/V0gIiLzhybkiXS+jem4\nrlhoZhcTy6PNtPeaWfbJy8yWEStMAHxyP9duTMefSytHNNtYCPwLM/CB3t1rxHJtq4F/MLPW/GvM\nbLWZPf5g7yUiIkeejo0ci0jmI8QqEf9uZv8BPAKcBTwH+Dzwkhm816NE/vKtZvZfQBX4dWIg+pH9\nLePm7pvM7LPAS4GbzOxqIk/5l4h1iG8Czp2Bfv4FMdnv9cTayd8mcpuPInKRn0ks93b7DNxLRESO\nIB07OB4b2gFAY/GarKzrlOMB6E0LFffU8wlyvaVIV9g5GimV260nq6stXw2A1SPNodHI1xgur4gJ\n7dU06a6rlKdkDo+vB2B0zyAAS459RlZXSmsa29Y8taFai/lEXd0RMCv153/trQ/HPTc/Fm0N9i3I\nr6vEHwAspYuUR/L+PbY1fg57arfFud15Sshxxx6HdD53v8XMLgT+klgLuALcTGy2sZOZHRyPETvb\n/TUxwF1BrHv8PiJaOxW/na55CbFpyBbgv4A/o31qyAFLq1i8CPgtYpLfLxMT8LYA9wHvBq6aiXuJ\niMiRpWMHxyKSS9sn/8IE1dZy7ro211/bet4k99pFDGon3Q3P3Te2a9Pd9xBR23e2ueyA++buayco\nd2LDkSsn66eIiMwvnTs47oslz7ywk9ziakyoc4tIaxd5XVcpJrH1DUdEt6eSR45XrjgagDJxTt3z\n6/oXxnnlFI2uki/NVloUy8lVuyI6vGRpX1a3sDsiv0v7VuZtpXl0zfMrXXkftu2ICfY33h/R6/KC\no7K67t5ImbTdseNd13Aece5eGJMQxywi2kOjebR8vKZ5SCIiIiJFmpAnIiIiIpJ0bOT4/s2Rv9uo\nFyK55ci37e6Kp23lvK6R9giw3tijoFzON/oYHouQrjWXbi3nnyl2p+XWunojKlz2vE3vjqhtuTci\nyFuGsyqG09Jsw7U8Atxbi3suKEX/qoV9GYbK/QAsPzH2L6iU8g2/PC0929WI5+zlPDrc0x99WNwV\n9+vvzp9XQ5FjERERkb107OBYRGbXRLm9IiIiRxKlVYiIiIiIJB0bOR5NE+uqXfnSZZWUDlFNWwvY\nXjvhxmNrznkvzn23mIDXTKuwRl5ZThekjfXorub387GYRDc6libRlY/Jm0xpG+P1vC0bTfdJ/auP\n5Z9dBkfjcaMa6RsNz//p6s2JfD2RelHuyif+9aR0j95q6mchraJemtLiAyIiIiLzhiLHIiIiIiJJ\nx0aOa80obCEEXBtPS7GlKGy5EDktl9NSbF0RQe7uy3aupbc7RZVrntoZy+q6q1FWsWi7VMuXeaun\nyXn1RtSNDucz8qw+vlc/ARq1OL82kjYbsbx/O9Mcu4E9cb/d40NZXVd3TNxrRolHRvL+DQ/H492D\n0eZYLY8q20B+noiIiIgociwiIiIikunYyPH4SOQcj46NZGXlasq3Tdsz9y/szeq6qykfOUWCrbDR\nR300fkyNepQNF5ZAq+/aDUBfb+T7VgpLuZUacZ9GJaK1g0N55HhsJO5THc3znsc8+tPVTCL2PD94\naLyR2oqj1fPrRtJzHU+R8ZHCJiBDQxFyHkvR7m1bBgp9KKwtJyIiIiKKHIuIiIiINGlwLCIiIiKS\ndGxaRf/iHgBq9eIueCllIh29kJpQI1IShtMEuZqPZnU7S5F+4B7nFyfK9YwNAjAyEvcpTvKrNCKV\nwVJZ13j+WSRlcVCuDWZlpXqkQDRTPPA8PWKgFikatZSG4bW8rdGx6HO9Hv0cH8+fc63RrEtpGWN5\nuojX88ciIiIiosixiMxTZrbWzNzMrpjrvoiIyOGjYyPHCxfEJLh6IXI8npZZK6Xl3cbH8sjseAr4\nptXUaFj+o6lUorLeiMpSOa9rLr82MBAT3UqFyHEpm5yXlocrTL7r7YpIcHcpj94uKDeXfqukvufP\np5Si0JVyLNtmni8119UVn3H27BlO1+UXeqP5hOK5er0wmbCmpdzk0DKztcB9wP9x90vmtDMiIiJT\noMixiIiIiEjSsZHjbZs2A1D3PFrrLee0fg+Q9vnAS/kyauVyM0obUWEv5Bzv6Yo84WY+crWaX9c8\nzdKD6p48j3lhT2wzvbS/Jysba0arKwuAvaPQCy3tAuLd6X75MnSN1OeenihrbvwBMLwnLeWWtr4e\nL+QZl0r6bCQiIiJSpNGRiBwSZnYpkVIB8OqU39v8usTM1qXHl5rZU83sq2a2PZWtTW24mV07QftX\nFM9tqXuqmX3OzB42s1Eze9TMrjaz35xCv0tm9r9T2//XzHr3d42IiHSOjo0ci8icuxZYArwZuBn4\nz0LdTakO4OnA24EbgE8AK4BpJ8Sb2e8AHwXqwH8BdwNHAU8G3gB8fpJre4CrgBcDHwbe5F7Y2UdE\nRDpexw6Od27bCkBXTyH9IE1Oq6U8hEYh5cJSisF4msDnlgfVzcp7nVOpdmV145WxdJ9q8yZ5J3zv\n+46V8kl0tdGYPNdMewDoTSkZSxfH9129ecqFWzQ2nBodbuST7sZHI12jORGvVsvrRvYMATA6FEcr\n1I2Naoc8OXTc/Voz20gMjm9y90uL9Wa2Lj28CHi9u//Twd7TzB4PfATYDfy8u9/WUn/cJNcuIwbT\nzwDe5u5/M8V73jhB1elT6rSIiBxWOnZwLCJHjJtmYmCc/B7xvvYXrQNjAHd/qN1FZnY7CHu2AAAg\nAElEQVQC8N/AycAr3f2qGeqPiIgcYTp2cNwYj2jqnvH8r7O1FFltru5WquRPvxkdbsaSS+U8yttI\nUeRSivxaYSk3r8XSaKPDMdFtvBBxbi7z1tTTk0eczWOynZEvrWZpo4/RUvR9ZDif3DcyHn0fScu8\njZK31Uh9GB9PbRUi4qNDEZkeTRHkcmEWYqOmTUDksPCjGWzr/HT8+gFccxrwA2AB8Fx3v+ZAbuju\n57UrTxHlJx1IWyIiMvc0IU9E5tqmGWyrmcf88AFccyqwGtgA/GQG+yIiIkegjo0cDw/uBsALy5U1\nI7+k6G5jNI/aeooc08w9LmzY0dz0o5wizSOF5dCaeb5WjihvuRBVtnS/rq6o8/pIVjdej8hxpfBP\nMJKWj9s6mpaHK+V1A4NRVkvXUc3zkUvl9HxSbrMVosOeosmWtpGmEMwuU9hlRGTutFtVsVg30fvU\nkjZlO9PxWOCOKd7/y8CdwF8D15jZL7n7tileKyIiHUaRYxE5lJqfwMqTnjWxHcDxrYUWeVDntjn/\nh+n43AO5ibu/F3gL8ETgWjM7+gD7KSIiHUKDYxE5lHYQ0d8107z+R8AaM7uopfxdwAltzv8oUAPe\nnVau2Mtkq1W4++XEhL4zgevM7Jhp9llERI5gHZtW0ZV2l6sXliht1OOvt/W0lJt7vgOdp93vmrvN\nFea0UapEukMjLbVm5TytwrC9j3mT2c565VRYLyyjZqlfo/U8taNcibKBNImud0F3VjeWUkAaqc/l\nQgebrdbTTMPm80uFqQ/ZunJ5nSutQg4tdx80s/8Bft7MrgLuIl9/eCreD1wMfMnMPgdsJ5ZaO5FY\nR3ldy/1uN7M3AB8DfmpmXyLWOV4OPIVY4u3CSfr7MTMbAT4OXG9mv+DuD0yxryIi0gE6dnAsIoeN\nVwIfBJ4DvIzYh/0hYOP+LnT3a8zsRcCfAS8FhoBvAi8BLpvgmn8xs1uBtxKD5xcBW4FbgH+dwj2v\nMLNR4FPkA+QN+7uujbXr16/nvPPaLmYhIiKTWL9+PcDaubi3uU82F0ZERKYjDbDLxO6AInOhuRHN\nVCenisykg339rQV2u/uJM9OdqVPkWETk0LgVJl4HWeRQa+7eqNegzIUj+fWnCXkiIiIiIokGxyIi\nIiIiiQbHIiIiIiKJBsciIiIiIokGxyIiIiIiiZZyExERERFJFDkWEREREUk0OBYRERERSTQ4FhER\nERFJNDgWEREREUk0OBYRERERSTQ4FhERERFJNDgWEREREUk0OBYRERERSTQ4FhGZAjM7zsw+YWaP\nmNmomW00s8vNbOlctCPzz0y8dtI1PsHXpkPZfzmymdmvm9mHzOy7ZrY7vWY+Pc22Duv3Qe2QJyKy\nH2Z2MvB94CjgS8AdwFOBC4E7gWe6+7bZakfmnxl8DW4ElgCXt6kedPf3z1SfpbOY2U3AOcAg8BBw\nOnCVu//WAbZz2L8PVuby5iIiR4iPEG/kb3L3DzULzewDwFuAvwJeP4vtyPwzk6+dne5+6Yz3UDrd\nW4hB8T3ABcB3ptnOYf8+qMixiMgkUpTjHmAjcLK7Nwp1/cCjgAFHufvQoW5H5p+ZfO2kyDHuvvYQ\ndVfmATNbRwyODyhyfKS8DyrnWERkchem49XFN3IAdx8Avgf0AefPUjsy/8z0a6fbzH7LzN5hZm82\nswvNrDyD/RWZyBHxPqjBsYjI5E5Lx7smqL87HU+dpXZk/pnp184q4Eriz9eXA98G7jazC6bdQ5Gp\nOSLeBzU4FhGZ3OJ03DVBfbN8ySy1I/PPTL52Pgk8mxggLwCeAPwTsBb4upmdM/1uiuzXEfE+qAl5\nIiIi84S7X9ZSdCvwejMbBP4YuBT41dnul8jhRJFjEZHJNSMZiyeob5bvnKV2ZP6ZjdfOx9LxWQfR\nhsj+HBHvgxoci4hM7s50nCgH7pR0nCiHbqbbkflnNl47W9JxwUG0IbI/R8T7oAbHIiKTa67leZGZ\n7fWemZYeeiawB/jhLLUj889svHaaqwNsOIg2RPbniHgf1OBYRGQS7n4vcDUxYemNLdWXEZG2K5tr\ncppZ1cxOT+t5TrsdkaaZeg2a2Rlmtk9k2MzWAv+Yvp3WdsAiRUf6+6A2ARER2Y82252uB55GrNl5\nF/CM5nanaaBxH3B/60YLB9KOSNFMvAbN7FJi0t31wP3AAHAy8HygB/ga8KvuPjYLT0mOMGb2IuBF\n6dtVwMXEXxq+m8q2uvtb07lrOYLfBzU4FhGZAjM7Hvhz4DnAcmInpy8Cl7n7jsJ5a5ngl8KBtCPS\n6mBfg2kd49cDTyRfym0ncBOx7vGVrkGBTCB9uHrPJKdkr7cj/X1Qg2MRERERkUQ5xyIiIiIiiQbH\nIiIiIiKJBsdHIDNba2ZuZsqJEREREZlB83r7aDO7hFhO5D/d/aa57Y2IiIiIzLV5PTgGLgEuADYS\ns3VFREREZB5TWoWIiIiISKLBsYiIiIhIMi8Hx2Z2SZrMdkEq+mRzglv62lg8z8yuTd+/wsyuM7Nt\nqfxFqfyK9P2lk9zz2nTOJRPUV83sdWZ2jZltMbNRM7vfzK5O5fts+TnJvc4xs8fS/T5tZvM9fUZE\nRERkSubroGkYeAxYBlSB3amsaUvrBWb2D8AfAA1gVzrOCDM7FvgKcG4qahC7Fq0C1gC/RGypeO0U\n2noG8FVgCfBR4I3a8UhERERkauZl5NjdP+fuq4i9vQHe7O6rCl9PabnkPOD3iW0Tl7v7MmBp4fpp\nM7Nu4MvEwHgr8GpgkbsvB/rSvS9n78H7RG1dBHyTGBj/jbu/QQNjERERkambr5HjA7UQeK+7/3mz\nwN13ExHng/XbxD73o8Cz3f2Wwj3qwE/S16TM7MXAvwFdwNvd/X0z0DcRERGReUWD46mpAx84RG2/\nKh0/WRwYHwgzew3wL8RfAt7g7h+dqc6JiIiIzCfzMq1iGu5x960z3aiZVYm0CYCvTbONPwQ+Djjw\nKg2MRURERKZPkeOp2WeC3gxZRv5v8MA02/hgOv65u3/64LskIiIiMn8pcjw19bnuwCQ+m45vNbOn\nzmlPRERERI5wGhzPjFo69kxyzuI2ZdsL154wzXu/Evi/wCLgG2b2xGm2IyIiIjLvzffBcXOtYjvI\ndnam43HtKtMGHme0lrv7OHBj+vZ507mxu9eAlxLLwS0BvmlmT5hOWyIiIiLz3XwfHDeXYltykO38\nLB0vMrN20eO3AN0TXPupdLzEzM6ezs3TIPs3gP8GlgPfMrN9BuMiIiIiMrn5Pji+LR1fbGbt0h6m\n6svEJh0rgU+Z2VEAZrbYzN4JXErsqtfOx4GbiMHzNWb2SjPrS9eXzezJ9v/bu/M4O8v67uOf35xl\n9jUhJGRhkhBIWMqmIGAluIBV26LVulfs8iraPljbPhWf6gNWq7a11dYWtbaW56FYl9oWlVqpSFil\nYCBalrBmIGRPZsvs29U/fte578PkzJLJJDM5832/XrzOyX3d93VfZ+Zw5je/ua7fZfZlM7twsgGE\nEAaBNwK3A0tiX+uO4DWJiIiILDgLPTi+CRgCXg7sN7MdZtZmZvccTichhHbg2vjPtwB7zKwDn1P8\nCeCP8AC41LWDwC8AjwCL8Uxyt5ntB/qAB4FfB6qnMY6B2NedwDLgh2a2+nBei4iIiMhCtqCD4xDC\nVuA1+HSELmApvjCu5NzhKfr6K+CtwP14UFsB3Au8sXhnvQmu3Q68BLgGuAc4iO/Ktwv4Ph4cPzDN\ncfQBb4j3XgHcYWarDvf1iIiIiCxEFkKY6zGIiIiIiMwLCzpzLCIiIiJSTMGxiIiIiEik4FhERERE\nJFJwLCIiIiISKTgWEREREYkUHIuIiIiIRAqORUREREQiBcciIiIiIpGCYxERERGRSMGxiIiIiEiU\nnesBiIiUIzPbBjQAbXM8FBGR41Er0B1CWH2sb1zOwXGY6wEcR2yuByBShhqqq6tbNmzY0DLXAxER\nOd48/vjj9Pf3z8m9yzk4BqCnfyB5ftsP/wuAoYFhABob65O2qqpKAKqr8wDU19ckbfV1/rymxs+p\nqcwnbdlMBoCMeXyZyWbSm9tMZ60U4vqJY9YQ0ti/cFYocV16bCy2HDomm/E4RY5fZtYKbAP+Xwjh\nqqNwi7YNGza0bN68+Sh0LSJS3s4//3weeuihtrm4t6IiETlqzKzVzIKZ3TjXYxEREZmOss8ci4jM\nlUd2dNF67a1zPQwRkTnR9unXz/UQZqTsg+OBwaHk+Y8eeBSAp598HoCxMJa0jYz49IOxMT9WU51O\nnWhpaQRg8eImAJob65K2+qoqAKqr/EtZVV2VtsXpGLW11d5nfASojOfl87nkWL7K75mLUzUqK9Nv\nT67Kz8tm/TGfTduy5ufHmR1kKtJpFZZMsdC0YhEREZGpaFqFiBwVZnY9PqcX4D1xekXhv6vMbGN8\nfr2ZXWBmt5pZezzWGvsIZrZpgv5vLD53XNsFZvZ1M9thZoNmtsvMbjOzX57GuCvM7C9j3/9iZtVT\nXSMiIuWj7DPHFRVp/P/Od78BgJHBEQB6DvYlbQe7ewDYt68DgF279idtBw50A/DE1ucA6OroStpy\nsX/L+uPixYuTtq5O77O7yx9Hw2jS1rrIf96ee1L6Laiu9qxwRabWz69Ks8oVlX5+VY1nrfN1afa6\nstafV8dFhZVF11XXel81df5Y11CbtOUrPXu9atkJiBwFm4Am4APAT4B/K2rbEtsALgI+DNwDfAVY\nDAwxQ2b2G8AXgFHg28BTwBLgJcD7gW9Mcm0VcDPwJuBvgGtCKPoTU+lrJlpxt/6wBy8iInOu7INj\nEZkbIYRNZtaGB8dbQgjXF7eb2cb49HLg6hDCl470nmZ2OnAD0A38bAjh0XHtKya5tgUPpi8Grg0h\n/MmRjkdERI4/ZR8cjxaVPGuI2dOGZZ6FDSXm4e7d4xnje+9Lf6a2rjsFgEs2vgwAKy6jZp4NzuZi\nCbi6NDPbc9Dr821/bicAmx9K+8xsfwyAxphdBhg56NnnbEWcV5xJs97VeX+ey8cxV6b3Ga3we/cF\ni4/pfOmuFX4sxPHR35iOIRczx++7GpE5tGU2AuPoffjn2sfHB8YAIYQXSl1kZicD/wGsBd4dQrh5\nujcMIZw/QZ+bgfOm24+IiMwPZR8ci8i898As9vWy+Pi9w7jmNOBHQC3wcyGE22dxPCIicpzRgjwR\nmWu7Z7GvwjzmHYdxzanAMuBZ4KFZHIuIiByHyj5zPDaWToEIYz7FYGT00PU1FXEKw6Y7fG3NLbfc\nlbSdsNQXrC1dtgyANaetSdrq632KxshB34mvo2skaauu9AVyq0/189ecsTZp2/7gUgAeu3dTcmwo\n62PNxZkTnX0NSdupzT7m+jiloyqT7uBX2J3vhEpvO7E6fc0VS3oBGMv4tzrsS19zyKQLBEXm0GRb\nvQcm/pxqKnGsMz4uB7ZO8/7fAZ4APgncbmavCSEcmOa1IiJSZso+OBaROVX4DSwz6VkT6wBWjj9o\nZhngnBLn349Xpfg5ph8cE0L4lJn1A58FNpnZq0MIe2Y25NSZyxvZfJwWwRcRWajKPjgeHUszuYXF\nc4VElRXNKhkZ9fN27PCfhz1dnUlbZcwqt+9pB2Dv7jT9+pILz/Ue44/+kcE0K11Ih2Wz3lhbk24Q\nUrnUs8iVK9O/KPdv/6mfV+sZ55Mb04Raa40/r8sPx06H0xdpPr7KMX99I2PptzUzGjPG8cswlq7V\nozek2WeRo6QD/19h1QyvfwB4rZldHkK4rej4R4CTS5z/BeBq4KNm9v0QwmPFjWa2YqJFeSGEz5nZ\nAF7t4k4ze2UIYecMxy0iIsepsg+ORWTuhBB6zOy/gJ81s5uBJ0nrD0/HZ4ArgFvM7OtAO15qbTVe\nR3njuPs9ZmbvB74IPGxmt+B1jhcBL8VLvF02yXi/GAPkvwfuigHy89Mcq4iIlAEtyBORo+3dwK3A\na4HrgI8zzRJnsXLElcCjwNuA9wBtwAXAcxNc82Xg5cB38eD5fwO/AOzDN/aY6p43Au/CM9N3mdma\nya8QEZFyUvaZY6somupY4VMTRkf9saIinQLRP+gbcnV0+G54uVw6/6ChqRmAnp6DAHS2dyRtHfv2\nAnDKeq+F3NGV1i3u6/U6x72D/tjXM5C0ZfM+rqoTVifHqvf6X3v3DXhba11l0nZSg+/KVxMPhUw6\nrcJG/fzRIX8MRbsCFjbly8RFfqGoRnP1UDsiR1sI4Wng5ydoPrTY+KHXf5vSmear4n+lrvkR8EtT\n9Ns20f1DCP8E/NNUYxMRkfKjzLGIiIiISFT2meOxgb7keU/MCvdlfQc6rChz3O8r1to7/Pyqquqk\nbbDfs8FVtV456uTWZUlboZTb2Jj3la2sS9qa8ExxRczeWkiTVNmc/15StSJdU9Re52Noe8zXADXU\npIsJhyo9KzyS/DqTlmHLx6V/lYX+izLiFYWFeLmYVe5PM+LZirR/EREREVHmWEREREQkUb6Z415f\nq2O77kkO1XR6RjYz7PN3+/NLk7bsoGdiz6r7bz+QT7OqWeKcYRoBqO6qT9qqq5YDsLLhcQC6K9Os\n8q5YnrV32PsOo0XzhIe8/+xI0a4cOc86r1q/wf/dtT1p+u92/1bVVXkf1Zl0/nI+zqGuGYnl3kbT\necXD7XHzkJjQzoylWeXRCv1uJCIiIlJM0ZGIiIiISKTgWEREREQkKttpFWPDXnaN4bTsWmXwXe/C\nUJzKENId64jTHM5u8dJs2Xy6cK13wKcyZMz73L4//Z3i4DPbANi319u2djQkbd9/2su0HezzaRnF\nZdSIz3OZtC8zX1CXq/Z6beuWNydtS1t8CsjiAT+nrujXmt5Rfx0hlqpbXzuUtO094AsG1+PHCgsB\nAcZsyipaIiIiIguKMsciIiIiIlHZZo6p902tdlfsTQ4drPCNOuqWekY2V51uENLd4dnd/9jpGeBc\nUZmzvlg/bbDfz9n6RLoxV2ODZ2bD2IkAvLDzQNI2mvHnp67xRXqLW9Ks8o59XlZu7540s53J+7dj\n6SIf31hINwHJ5X0R4InVPq7+oaLNTczHVx0XDuZG0oxwTXzed8DL140VytgBI9l0cZ6IiIiIKHMs\nIiIiIpIo28xxRaYGgDt/nG6RfPsP7geg9WQvv7Zs+YlJW3WNz9tta/eMbG9vWiqttXUFAP3DhZJu\nabZ3bMivG41bOI/kW9I+a33eck2jbx5SmEsM0NDg84NDSH8/qch5X6ev9bnK1WPp3OGaUd+IpL7S\nM8jZmMUGqBseBMCCZ4J7BtP7ZC0Tj/m/h/NpxjmXJpFFREREBGWORUREREQSCo5FRERERKKynVZR\nqJrWsb8zObZr+y4A9u7YA8DQSLrorrHRt5CrrPKpEPW16ZyDRc3etm+3X9e66oSkrbLS27Zt2xHb\nTkrasnmf3tAz4Pc50HkwaauI0x2aF6WL9JoW+/QLMy8d17xscdLW3u3TKh7c5Yv8zsyl37pM8EV3\nFcGPjVSmY29f5H00d/rXYbguXazXVKFSbjJ/mVkA7gwhbJzm+RuBO4CPhRCuLzq+Cbg0hKA3vIiI\nTEmZY5EyYWYhBoIiIiIyQ2WbOR4Z88VpfQPpwrqKjGdr83GDj4ps+vItZnJra2sBWL5iadKWieXP\nKir8d4nRNOFM+wFf8NcVM7NNTY1J29p1a30so54JHhocTNoWxXJtlVXp4rnRsVEAxmJ+q2nt2qRt\nWa2XjNv5yKMAVMcsOEChIttYhT/pzaeva6jOFyaODnrmeSiXDr6+tqgcnMjx7wFgA7B/rgciIiLH\nL2WORaQshBD6QghbQwjzJjh+ZEcXrdfeOtfDEBGRw6DgWOQYMbOrzOxbZvasmfWbWbeZ3Wtm7ypx\nbpuZtU3Qz/VxCsXGon4Le5NfGtsK/10/7tpfNrO7zKwrjuG/zezDZlY57jbJGMyszsw+a2bb4zVb\nzOzKeE7WzP7QzJ4yswEze8bMfnuCcVeY2dVm9qCZ9ZhZb3z+PjOb8LPIzE4ys5vMbG+8/2Yze0eJ\n8zaWes2TMbMrzOzfzWy/mQ3G8f+ZmTVNtw8RESkvZTutYmjYawT39PQlx2wavwtksz7VoKkx/dlY\nmE6Ri4WBKyvT6QiLFntd4927PVnV1ZUuANy+4wUATlnnO/Odfd45SVtDY2FnvXSXutERf57P5+I5\nNUlbrtK/Vaecfaa/rqLpIgf3+L1HzOdj9JP22dnhNZmf37cPgHXLq5O2qsWLSnwF5Cj6AvAocBew\nC1gEvA64ycxOCyF8dIb9bgE+BlwHPAfcWNS2qfDEzD4JfBifdvBVoAf4OeCTwBVmdnkIYYgXywH/\nCbQAtwB54O3At8zscuD9wIXA94BB4C3A581sXwjh6+P6ugl4B7Ad+DsgAG8EbgBeDryzxGtrBu4D\nOoF/AJqAXwZuNrPlIYQ/m/KrMwEzuw64HmgHvgvsBX4G+H3gdWZ2UQihe6b9i4jI8alsg2OReejM\nEMIzxQfMLI8Hltea2RdDCDsOt9MQwhZgSwz22oorNRTd5yI8MN4OXBBC2B2Pfxj4V+ANeFD4yXGX\nngQ8BGwMIQzGa27CA/xvAs/E19UZ2/4C2ApcCyTBsZm9HQ+MHwZeEULoicc/AtwJvMPMbg0hfHXc\n/X8m3udtIfguN2b2aWAz8Mdm9q0QwrOH9xUDM7sMD4x/BLyuMP7YdhUeiH8M+OA0+to8QdP6wx2X\niIjMvbINjoeGfeHZ6Ohocmw0ZmkH+gvJsbSyU8j7X6UHB33xXCjKvuZjebdczOgODfQmbetW+S57\nzz35HADd/emiu4P7uwDYOrgVgL37DiRtp5/hPzdPOikt15ar9PuMxIV5BzvTLHQ+7q6XyfmCwbB2\nXdKWIS4GzPm4Ht3XlbRtuuN5AKprvGRcfa4+aXvpWauQY2d8YByPDZnZ3wCvBF4F/P+jdPtfjY+f\nKATG8f4jZvZ7eAb71zk0OAb4nUJgHK+528y2AauBDxUHliGEZ83sXuDlZpYJIRT+Byzc/9pCYBzP\n7zWzDwE/iPcfHxyPxnuMFV2zzcz+Cs+UvxsPYg/XNfHxN4rHH/u/0cw+gGeypwyORUSkvJRtcCwy\n35jZKuBDeBC8Cqged8ryo3j78+LjD8c3hBCeNLMXgNVm1hhC6Cpq7iwV1AM78eC4VNZ0B/7ZsjQ+\nL9x/jKJpHkXuxIPgc0u0PR9C2Fbi+CY8OC51zXRcBAwDbzGzt5RozwMnmNmiEMKBEu2JEML5pY7H\njPJ5pdpERGT+KtvguKbG4473vucNybGLL/D5utvjJiBtbXuStu5uz7oODfpc3kxRlbNM1ucc1zV4\n1nasJm0866xWAH7yU48f9j+T/hzPDntfjWM+lhfank/aDnb6VMbzzt2QHFtzisdGo7FWXN/BdNMQ\nBmI5uFh+bqxoA5NVLd5/Mx7T5PvT7PApp54GwIq4cUnVcBr3ZBpPRI4NM1uDlxprBu4GbgO68KCw\nFXgPcMiiuFlUqDG4a4L2XXjA3hTHVdBV+nRGAMYF0i9qw+crF9+/vcSc5kL2ej+wpERfe0ocAyhk\nvxsnaJ/KIvzz77opzqsDJg2ORUSkvJRtcCwyz/wuHpC9N4RwY3FDnI/7nnHnj+HZy1JmUkmhEMQu\nxecJj7ds3HmzrQtoMbNcCGG4uMHMssBioNTit4l+gysUIp/peLuAihBCywyvFxGRMqVSbiLHxinx\n8Vsl2i4tcawDONHMciXaXjLBPcaAiXZ2eTg+bhzfYGanACuAbePn386ih/HPm1eUaHsFPu6HSrSt\nMrPWEsc3FvU7E/cDzWZ2xgyvFxGRMlW2mePKOC/i4peelRx76Xk+heHZbTsB2Ls3/Wvprj1e8uw7\n370DgM7OdNFdrLBGY5NPq8jm07/+9lR4Em+0sgqAutq6pC1X5893dXpyq7MvLSs31NcPwP4TG5Jj\nB3b6tIuObl+vVBHSxYQtI/57zHPdHrsMZ9OY6fwzTvbXt9wX97UsSxOLa2t88A11PvbFi05O2k5c\nq8X0x1BbfNwIfKdw0MyuwBeijfcAPl/1vcDfFp1/FXDJBPc4AKycoO0rwK8BHzGzb4cQ9sX+MsBn\n8MD176f1SmbmK/hc60+Z2cYQQl+8fw3w6XhOqftngD8xs7cXVatYjS+oGwH+cYbj+SzweuDLZvbm\nEMLO4kYzqwXOCiHcP8P+AThzeSObP/36I+lCRESOsbINjkXmmRvwQPebZvbP+IK2M4HXAt8A3jru\n/M/H879gZq/CS7Cdgy8k+y5eem2824G3mdl38CzsMHBXCOGuEMJ9ZvanwB8Aj8Qx9OJ1js8E7gFm\nXDN4KiGEr5rZL+I1ih81s3/D6xxfiS/s+3oI4eYSl/4Ur6O82cxuI61z3AT8wQSLBaczntvN7Frg\nU8BTZvbvwDZ8jvHJeDb/Hvz7IyIiC0jZB8d9RZtl3Hn/TwD4+y99E4AlS9JNMMaCl3WrzPvitt7e\nNHNcqPhWOLaoIZ2NcvdtnmkeHfFplIuWpKXZGhY1A7DuHJ8e+cJz6YK855/20m+Dw2l2+KmnvFzr\ngVgCrnhRYE0s8zYw7BW1RkNahu7EFs8+NwY/p7cqve6Z5z0jfuYZXvpt9eo0sdjcMtO1THK4Qgg/\njbV1P4FnLLPAT4A34RtcvHXc+Y+Z2avx0mo/j2dJ78aD4zdROjj+AB5wvgovzVaBlzm7K/b5ITN7\nGPht4FfwBXPPAB8B/rzUYrlZ9na8MsWvAr8Zjz0O/Dm+QUopHXgA/6f4LwsNwGPAZ0rURD4sIYQ/\niWXnrsE3IflFfC7yDjxbf0T9i4jI8ansg2OR+SKEcB9ez7gUG38ghHAPpefo/hTfwGL8+XvxjTYm\nG8PXgK9NNdZ4buskbRsnabsKuKrE8TE8g37DNO9f/DU5ZIvtEudvovTXceMk19yDZ4hFRESABRAc\n7z/QkTzv6fWsa/Min5O74Yx0I4377tsCQFODZ1MP9qRl1A60twNQHTfiqKlPt1ppP1sAAA4uSURB\nVHVu27EXgNqYcd63P53H3Nvrc4cbar1tw7rWpG14wOcfD4+kybqhIc8+F7arHkv3PeBgzIBnYtI6\nn02/dZ293vbA8359dU163ZITPJO9foO/1pNXLkvacrmJ1m6JiIiILEyqViEiIiIiEik4FhERERGJ\nyn5aRVVVuulYtsKnEaxc6fsKtLam+ws8uNl/T1i63Mu0nbfinKTt+W0veF+V/uU6/fQ1SdvyuKjv\nln/5TwDqatIvaUNTLOs24Av5XngmLSE7OuCl3Hp706kNAV+cNzo6HMeb/u4yFqdSjo4EALwClztp\nsd/nkovPBqCiMi0Pt2KlLwZctKgxfj3S1XqZjKZViIiIiBRT5lhEREREJCr7zHEul26WUVfjWdOY\nmOVgd7opRy7j5/XEDTgGYmYXoCYuqBuJC+a2xUwyQHuHl10bjYvnrnzjq4vu7ZnZpc1xAV/R4vtH\nfrQZgEd3p2NYvNgXz1VV+RisIs3sZjOFb5Xfp662NmnL57yEW1+fj+/8c1YnbVV5z5zXxgx6Pp9+\ny80OWdgvIiIisqApcywiIiIiEik4FhERERGJyn5aRXV1ugCtJS5K6+zsBqC7O5060RF3pXvykScB\nGB5OpzvU1tbH633x3XDRRmI7d3kN5IYGP2fD6emUhoF42le/eisA/QfTBXlDPb5Ib//B9D6nrj8F\ngJUrfVHg4EB6n+ERX6w3NOS1mkMISduDDz3hY9nntZkvuvSSpK2x0V9zZd6naBRPMymxX4KIiIjI\ngqbMsYiIiIhIVPaZ41wmjf+XL/OM7GWvfhkAu3ftS9oq835eS7OXRVu5rCVp6+3xrG1Xh+9+t+aU\n1qTtUZ4CYGzMzwlFi+gqKnzxXGeXZ4d37mhP2toPeF8jw2l2eNduP5bL+bfFijK7gRDbPPNbXV2d\ntNXU+phXrFwBQH1dXdJWXe2L9WKXZIrKwylxLCIiIvJiyhyLiIiIiERlnzkuzr4uavLyZ6955YUA\ndLQfTNouOO9MAPr7fB7yUFFG99m2XQA8/ewOADb/+NGkrVDyranJN97IZPJJW22zP69v9HnP9d1p\n+bWGOi/v1tXVnRzri/cuDDlbtEmHxYxvZSzbls2m37rGZp/vvOaU5QDU1BVt9JGz2FdF7Cf9eqiS\nm4iIiMiLKXMsIiIiIhIpOBaRFzGzTWYWpj7ziO/TambBzG482vcSERGZrgU1rSIbn1rWf+6fuKQh\naTthkT8fHvZFdP2Dg0nbqtW+0G312pMBeOKJbUlbdY3vPFdY3PfY1ieStvpYAm44lmQzG0vaaqt9\nWsXQQG9yLIz67yojo6Nx7CNpW/C2/gHfBa/1pNak7dLLLgDggovOACCfLX7N/rwiTqconkqhWRUi\nIiIiL1b2wbGIHLZfAWrmehAiIiJzofyDYzv0HxX4QrdAmsktLFSryPuXJJ9PZ5w01PsCtxNamgBY\nu2ZZ0rZnz3oA9u7xMm3793ckbU9ufd6fxNucuLgxaRvpHwBgSXNadi00ezxSYX7vbDZdkNc76Bnj\nUfPxnXv2+qTtwnM3+PgaPVM9NppmnCuylUWvXNlimVoI4fm5HoOIiMhc0ZxjkQXAzK4ys2+Z2bNm\n1m9m3WZ2r5m9q8S5h8w5NrONcX7w9WZ2gZndambt8VhrPKct/tdoZn9tZjvMbMDMHjOza8ymVx/F\nzE41s0+b2Y/NbJ+ZDZrZc2b2t2a2osT5xWM7J46t08z6zOxOM7t4gvtkzez9ZnZ//Hr0mdnDZvbb\nZqbPRhGRBar8M8clpD+j059/yY/CQlNxaBD8YKbKN+CorG5OmpYu8c1CRjZ4tra/fzhp27XHs8j7\n9vl85OKybYO9njkeHUnPD8FTzJlYwi2fS8vCVcRdPOpidri5KZ0v3dLk2ef6em+rzKfXFZdukwXt\nC8CjwF3ALmAR8DrgJjM7LYTw0Wn2cxHwYeAe4CvAYmCoqD0P/ABoAr4W//1LwF8CpwG/NY17vAm4\nGrgDuC/2fwbw68DPm9lLQgg7Slz3EuAPgB8Bfwesive+3czOCSEkCwLMLAd8B7gCeAL4KjAAXAZ8\nHrgQePc0xioiImVmQQbHIgvQmSGEZ4oPmFke+B5wrZl9cYKAc7zLgatDCF+aoH0Z8Gy832C8z3XA\ng8D7zezrIYS7prjHTcBnC9cXjffyON6PAO8rcd3rgfeGEG4suuY3gS8CHwDeX3TuH+KB8V8DvxNC\nGI3nZ4C/BX7VzP45hHDLFGPFzDZP0LR+guMiIjKP6U+HIgvA+MA4HhsC/gb/JflV0+xqyySBccGH\niwPbEEI78PH4z/dOY6w7xgfG8fhtePb7igkuvbc4MI6+AowAFxQOxCkT/wvYDXywEBjHe4wCv4f/\n7eidU41VRETKT9lnjieb5lhc5u2QlWpFUw4LMywKMxRC8bmxMZfzqRC5fLqIrrHJp0eeus4fQzj0\nOguHlpNNxmWHnJ4cK54RWSgRV1FYcFiiQu00p3tKmTKzVcCH8CB4FVA97pTl0+zqgSnaR/CpEONt\nio/nTnWDODf5ncBVwNlAM5ApOmWoxGUAPx5/IIQwbGZ7Yh8FpwItwFPARyb4f6Mf2DDVWOM9zi91\nPGaUz5tOHyIiMn+UfXAsstCZ2Ro8qG0G7gZuA7qAUaAVeA9QOc3udk/Rvr84E1viusYSbeP9BfA7\n+Nzo7wM78GAVPGA+eYLrOic4PsKLg+tF8XEdcN0k46ibpE1ERMpU2QfHoSgzezjZ0xIJ3SSRmy2e\njRIX9YdSRdLGvC1Z61d8SkWp+0xnU7JwyKnjy7QpSyzj/C4eEL53/LQDM3s7HhxP11Rv0sVmlikR\nIC+Nj12TXWxmS4BrgEeAi0MIB0uM90gVxvCvIYQ3zUJ/IiJSRjTnWKT8nRIfv1Wi7dJZvlcWKFU6\nbWN8fHiK69fgn0u3lQiMV8T2I7UVzzK/LFatEBERSSg4Fil/bfFxY/FBM7sCL4822z5lZsk0DTNr\nwStMAPzDFNe2xceXx8oRhT7qgC8zC3/tCiGM4OXalgF/ZWbj519jZsvM7PQjvZeIiBx/yn5axUyn\nGEz/OovnT9g0nctneoHIdNyAV4n4ppn9M7ATOBN4LfAN4K2zeK9d+PzlR8zs20AOeDMeiN4wVRm3\nEMJuM/sa8DZgi5ndhs9Tfg1eh3gLcM4sjPPj+GK/q/HayT/E5zYvweciX4KXe3tsFu4lIiLHkbIP\njkUWuhDCT83sMuATeC3gLPATfLONTmY3OB4CXg18Eg9wF+N1jz+NZ2un49fiNW/FNw3ZB3wb+L+U\nnhpy2GIViyuBd+GL/N6AL8DbB2wDPgrcfIS3aX388cc5//ySxSxERGQSjz/+OPii8WPOQqmVZyIi\nh8nM2gBCCK1zO5L5wcwG8SoZP5nrsciCVtiMZuucjkIWspm+B1uB7hDC6tkdztSUORYROToegYnr\nIIscC4UdHPU+lLlyPL4HtSBPRERERCRScCwiIiIiEmlahYjMCs01FhGRcqDMsYiIiIhIpOBYRERE\nRCRSKTcRERERkUiZYxERERGRSMGxiIiIiEik4FhEREREJFJwLCIiIiISKTgWEREREYkUHIuIiIiI\nRAqORUREREQiBcciItNgZivM7CtmttPMBs2szcw+Z2bNc9GPLEyz8f6J14QJ/tt9NMcvxz8ze7OZ\nfd7M7jaz7vi++ccZ9jUvPw+1CYiIyBTMbC1wH7AEuAXYClwAXAY8AVwSQjhwrPqRhWkW34dtQBPw\nuRLNPSGEz8zWmKX8mNkW4GygB3gBWA/cHEJ412H2M28/D7NzcVMRkePMDfgH+DUhhM8XDprZXwAf\nBP4YuPoY9iML02y+fzpDCNfP+ghlIfggHhQ/DVwK3DHDfubt56EyxyIik4jZjaeBNmBtCGGsqK0e\n2AUYsCSE0Hu0+5GFaTbfPzFzTAih9SgNVxYIM9uIB8eHlTme75+HmnMsIjK5y+LjbcUf4AAhhIPA\nvUAN8LJj1I8sTLP9/qk0s3eZ2f8xsw+Y2WVmlpnF8YpMZl5/Hio4FhGZ3Gnx8ckJ2p+Kj6ceo35k\nYZrt989S4Cb8T9efA34IPGVml854hCLTN68/DxUci4hMrjE+dk3QXjjedIz6kYVpNt8//wC8Cg+Q\na4GzgC8BrcD3zOzsmQ9TZFrm9eehFuSJiIgsICGEj4079AhwtZn1AL8HXA+88ViPS2S+UOZYRGRy\nhQxG4wTtheOdx6gfWZiOxfvni/HxFUfQh8h0zOvPQwXHIiKTeyI+TjT3bV18nGju3Gz3IwvTsXj/\n7IuPtUfQh8h0zOvPQwXHIiKTK9TwvNzMXvSZGUsOXQL0Afcfo35kYToW759CZYBnj6APkemY15+H\nCo5FRCYRQngGuA1frPRb45o/hmfZbirU4jSznJmtj3U8Z9yPSLHZeh+a2QYzOyQzbGatwF/Hf85o\nK2CR8Y7Xz0NtAiIiMoUS25w+DlyI1+p8Eri4sM1pDDK2Ac+N32ThcPoRGW823odmdj2+6O4u4Dng\nILAWeD1QBfw78MYQwtAxeElyHDKzK4Er4z+XAlfgf224Ox7bH0L4/XhuK8fh56GCYxGRaTCzlcAf\nAa8FFuE7OP0r8LEQQkfRea1M8MPgcPoRKeVI34exjvHVwLmkpdw6gS143eObggIDmUT8Beu6SU5J\n3nPH6+ehgmMRERERkUhzjkVEREREIgXHIiIiIiKRgmMRERERkUjBsYiIiIhIpOBYRERERCRScCwi\nIiIiEik4FhERERGJFByLiIiIiEQKjkVEREREIgXHIiIiIiKRgmMRERERkUjBsYiIiIhIpOBYRERE\nRCRScCwiIiIiEik4FhERERGJFByLiIiIiEQKjkVEREREov8Bj2cHouJ+J20AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4a4839df98>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为何准确率只有50-80%？\n",
    "\n",
    "你可能想问，为何准确率不能更高了？首先，对于简单的 CNN 网络来说，50% 已经不低了。纯粹猜测的准确率为10%。但是，你可能注意到有人的准确率[远远超过 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)。这是因为我们还没有介绍所有的神经网络知识。我们还需要掌握一些其他技巧。\n",
    "\n",
    "## 提交项目\n",
    "\n",
    "提交项目时，确保先运行所有单元，然后再保存记事本。将 notebook 文件另存为“dlnd_image_classification.ipynb”，再在目录 \"File\" -> \"Download as\" 另存为 HTML 格式。请在提交的项目中包含 “helper.py” 和 “problem_unittests.py” 文件。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
